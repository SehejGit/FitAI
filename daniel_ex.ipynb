{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_russian_twist(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    twist_count = 0\n",
    "    twist_direction = None  # \"left\" or \"right\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    shoulder_rotations = []  # Track degree of rotation\n",
    "    hip_stability = []  # Check if hips remain stable\n",
    "    back_angles = []  # Check if back maintains proper angle\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate shoulder line (horizontal in rest position)\n",
    "            shoulder_angle = math.degrees(math.atan2(\n",
    "                right_shoulder[1] - left_shoulder[1],\n",
    "                right_shoulder[0] - left_shoulder[0]\n",
    "            ))\n",
    "            \n",
    "            # Store rotation angle\n",
    "            shoulder_rotations.append(shoulder_angle)\n",
    "            \n",
    "            # Calculate back angle (should maintain ~45 degrees)\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Assuming vertical is 0 degrees, calculate angle of back\n",
    "            back_angle = math.degrees(math.atan2(\n",
    "                mid_shoulder[1] - mid_hip[1],\n",
    "                mid_shoulder[0] - mid_hip[0]\n",
    "            ))\n",
    "            back_angles.append(abs(back_angle))\n",
    "            \n",
    "            # Check hip stability (hips shouldn't move much)\n",
    "            hip_pos = [mid_hip[0], mid_hip[1]]\n",
    "            hip_stability.append(hip_pos)\n",
    "            \n",
    "            # Visualize angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Rotation: {shoulder_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Detect twist direction based on shoulder rotation\n",
    "            # Threshold values would need tuning based on testing\n",
    "            if shoulder_angle > 15 and (twist_direction == \"left\" or twist_direction is None):\n",
    "                twist_direction = \"right\"\n",
    "                # Draw twist direction\n",
    "                cv2.putText(annotated_image, 'RIGHT', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif shoulder_angle < -15 and (twist_direction == \"right\" or twist_direction is None):\n",
    "                twist_direction = \"left\"\n",
    "                if twist_direction == \"right\":  # Complete cycle\n",
    "                    twist_count += 1\n",
    "                cv2.putText(annotated_image, 'LEFT', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display twist count\n",
    "        cv2.putText(annotated_image, f'Twists: {twist_count}', (10, 120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"twist_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    max_rotation = max([abs(angle) for angle in shoulder_rotations])\n",
    "    avg_back_angle = np.mean(back_angles)\n",
    "    hip_stability_score = 100 - (np.std([pos[0] for pos in hip_stability]) + \n",
    "                                np.std([pos[1] for pos in hip_stability])) * 100\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"twist_count\": twist_count,\n",
    "        \"form_analysis\": {\n",
    "            \"rotation_range\": max_rotation,\n",
    "            \"back_angle\": avg_back_angle,\n",
    "            \"hip_stability\": hip_stability_score,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if max_rotation < 30:\n",
    "        feedback[\"feedback\"].append(\"Try to rotate further to each side for a full range of motion.\")\n",
    "    \n",
    "    if avg_back_angle < 30 or avg_back_angle > 60:\n",
    "        feedback[\"feedback\"].append(\"Maintain a back angle of about 45 degrees throughout the exercise.\")\n",
    "    \n",
    "    if hip_stability_score < 80:\n",
    "        feedback[\"feedback\"].append(\"Keep your hips more stable. Twist from your core, not your hips.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your Russian twists show good rotation and stable positioning.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_situp(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    situp_count = 0\n",
    "    situp_stage = None  # \"up\" or \"down\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    torso_angles = []  # Track the angle of the torso relative to ground\n",
    "    neck_angles = []   # Track neck position to ensure proper form\n",
    "    hip_knee_angles = []  # Check if legs maintain proper position\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ear = [landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate torso angle (shoulder-hip to horizontal)\n",
    "            # Use a reference horizontal point at the same y as the hip\n",
    "            hip_horizontal = [left_hip[0] + 0.1, left_hip[1]]  # Point to the right of hip\n",
    "            torso_angle = calculate_angle(left_shoulder, left_hip, hip_horizontal)\n",
    "            \n",
    "            # Adjust angle based on which side of hip the shoulder is\n",
    "            if left_shoulder[0] < left_hip[0]:  # Shoulder is to the left of hip\n",
    "                torso_angle = 180 - torso_angle\n",
    "            \n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Calculate neck angle (check if neck is neutral)\n",
    "            neck_angle = calculate_angle(left_shoulder, left_ear, [left_ear[0] + 0.1, left_ear[1]])\n",
    "            neck_angles.append(neck_angle)\n",
    "            \n",
    "            # Calculate hip-knee angle\n",
    "            hip_knee_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            hip_knee_angles.append(hip_knee_angle)\n",
    "            \n",
    "            # Visualize angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Detect situp stage based on torso angle\n",
    "            if torso_angle > 70 and (situp_stage == \"up\" or situp_stage is None):\n",
    "                situp_stage = \"down\"\n",
    "                # Draw situp stage\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif torso_angle < 30 and situp_stage == \"down\":\n",
    "                situp_stage = \"up\"\n",
    "                situp_count += 1\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Situp #{situp_count} detected at frame with torso angle {torso_angle:.1f}°\")\n",
    "                \n",
    "        # Display situp count\n",
    "        cv2.putText(annotated_image, f'Situps: {situp_count}', (10, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"situp_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    min_torso_angle = min(torso_angles)\n",
    "    avg_neck_angle = np.mean(neck_angles)\n",
    "    avg_hip_knee_angle = np.mean(hip_knee_angles)\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"situp_count\": situp_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_torso_angle\": min_torso_angle,\n",
    "            \"neck_position\": avg_neck_angle,\n",
    "            \"leg_position\": avg_hip_knee_angle,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if min_torso_angle > 25:\n",
    "        feedback[\"feedback\"].append(\"Try to come up higher in each situp for a full range of motion.\")\n",
    "    \n",
    "    if avg_neck_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Keep your neck neutral throughout the movement. Avoid pulling with your neck.\")\n",
    "    \n",
    "    if avg_hip_knee_angle < 70 or avg_hip_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Maintain a consistent knee bend (about 90 degrees) throughout the exercise.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your situps show good full-range motion with proper neck position.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_side_bend(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    bend_count = 0\n",
    "    bend_direction = None  # \"left\" or \"right\" or \"center\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    lateral_bends = []  # Track degree of side bend\n",
    "    forward_leans = []  # Ensure bending is lateral, not forward\n",
    "    hip_positions = []  # Check if hips remain stable\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate lateral bend angle\n",
    "            # Vertical line from mid hip going up\n",
    "            vertical_ref = [mid_hip[0], mid_hip[1] - 0.1]\n",
    "            \n",
    "            # Calculate angle between hip-shoulder line and vertical\n",
    "            dx = mid_shoulder[0] - mid_hip[0]\n",
    "            dy = mid_shoulder[1] - mid_hip[1]\n",
    "            lateral_angle = math.degrees(math.atan2(dx, -dy))  # Negative dy because y increases downward\n",
    "            lateral_bends.append(lateral_angle)\n",
    "            \n",
    "            # Calculate forward/backward lean\n",
    "            # Need a side view reference for this, using shoulder depth\n",
    "            shoulder_depth = right_shoulder[0] - left_shoulder[0]  # This works if person faces camera\n",
    "            forward_leans.append(shoulder_depth)\n",
    "            \n",
    "            # Track hip stability\n",
    "            hip_positions.append(mid_hip)\n",
    "            \n",
    "            # Visualize the bend angle\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Bend: {lateral_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine bend state based on lateral angle\n",
    "            if lateral_angle > 15 and (bend_direction != \"right\"):\n",
    "                bend_direction = \"right\"\n",
    "                cv2.putText(annotated_image, 'RIGHT', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif lateral_angle < -15 and (bend_direction != \"left\"):\n",
    "                bend_direction = \"left\"\n",
    "                cv2.putText(annotated_image, 'LEFT', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif abs(lateral_angle) < 5 and (bend_direction == \"right\" or bend_direction == \"left\"):\n",
    "                if bend_direction == \"right\" or bend_direction == \"left\":\n",
    "                    # Only count when returning to center from a defined side\n",
    "                    bend_count += 0.5  # Half a rep for each direction\n",
    "                    bend_direction = \"center\"\n",
    "                cv2.putText(annotated_image, 'CENTER', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display bend count\n",
    "        cv2.putText(annotated_image, f'Bends: {int(bend_count)}', (10, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"bend_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    max_left_bend = min(lateral_bends)  # Most negative angle\n",
    "    max_right_bend = max(lateral_bends)  # Most positive angle\n",
    "    bend_symmetry = abs(abs(max_left_bend) - max_right_bend) / max(abs(max_left_bend), max_right_bend) * 100\n",
    "    forward_lean_variation = np.std(forward_leans) * 100  # Higher means more forward/backward motion\n",
    "    hip_stability = 100 - np.std([p[0] for p in hip_positions] + [p[1] for p in hip_positions]) * 100\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"bend_count\": int(bend_count),\n",
    "        \"form_analysis\": {\n",
    "            \"max_left_bend\": abs(max_left_bend),\n",
    "            \"max_right_bend\": max_right_bend,\n",
    "            \"bend_symmetry\": 100 - bend_symmetry,  # Higher is better\n",
    "            \"hip_stability\": hip_stability,\n",
    "            \"forward_motion\": forward_lean_variation,  # Lower is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if max(abs(max_left_bend), max_right_bend) < 15:\n",
    "        feedback[\"feedback\"].append(\"Try to bend further to each side for a better stretch.\")\n",
    "    \n",
    "    if bend_symmetry > 20:\n",
    "        feedback[\"feedback\"].append(\"Work on balanced bends to both sides. You're bending more to one side.\")\n",
    "    \n",
    "    if forward_lean_variation > 10:\n",
    "        feedback[\"feedback\"].append(\"Focus on pure side bends. Avoid leaning forward or backward during the movement.\")\n",
    "    \n",
    "    if hip_stability < 80:\n",
    "        feedback[\"feedback\"].append(\"Keep your hips more stable. The movement should come from your waist, not shifting your hips.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your side bends show good range and balance on both sides.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bench_press(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" or \"down\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    elbow_angles = []  # Track elbow angle during movement\n",
    "    wrist_positions = []  # Track bar path (using wrists as proxy)\n",
    "    shoulder_stability = []  # Check if shoulders remain on bench\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # For bench press from side view, we'd use one arm's angle\n",
    "            # From front view, we can use the average of both arms\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elbow_angles.append(avg_elbow_angle)\n",
    "            \n",
    "            # Track wrist positions to analyze bar path\n",
    "            mid_wrist = [(left_wrist[0] + right_wrist[0])/2, (left_wrist[1] + right_wrist[1])/2]\n",
    "            wrist_positions.append(mid_wrist)\n",
    "            \n",
    "            # Track shoulder stability\n",
    "            shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "            shoulder_stability.append(shoulder_y)\n",
    "            \n",
    "            # Visualize the elbow angle\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {avg_elbow_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on elbow angle\n",
    "            if avg_elbow_angle > 160 and (press_stage == \"down\" or press_stage is None):\n",
    "                press_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif avg_elbow_angle < 90 and press_stage == \"up\":\n",
    "                press_stage = \"down\"\n",
    "                rep_count += 1\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Bench press rep #{rep_count} detected at frame with elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "# Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    min_elbow_angle = min(elbow_angles)\n",
    "    max_elbow_angle = max(elbow_angles)\n",
    "    \n",
    "    # Analyze bar path (using wrist positions as proxy)\n",
    "    wrist_x_positions = [pos[0] for pos in wrist_positions]\n",
    "    wrist_y_positions = [pos[1] for pos in wrist_positions]\n",
    "    \n",
    "    # Calculate horizontal deviation in bar path\n",
    "    bar_path_deviation = np.std(wrist_x_positions) * 100  # Scaled for readability\n",
    "    \n",
    "    # Check shoulder stability\n",
    "    shoulder_movement = np.std(shoulder_stability) * 100\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_elbow_angle\": min_elbow_angle,\n",
    "            \"max_elbow_angle\": max_elbow_angle,\n",
    "            \"bar_path_stability\": 100 - bar_path_deviation,  # Higher is better\n",
    "            \"shoulder_stability\": 100 - shoulder_movement,   # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if min_elbow_angle > 100:\n",
    "        feedback[\"feedback\"].append(\"Try to lower the bar more for full range of motion. Aim for at least 90° elbow angle at the bottom.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the movement.\")\n",
    "    \n",
    "    if bar_path_deviation > 5:\n",
    "        feedback[\"feedback\"].append(\"Work on a more consistent bar path. Try to keep the bar moving in a straight vertical line.\")\n",
    "    \n",
    "    if shoulder_movement > 10:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders stable and in contact with the bench throughout the movement.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bench press shows good range of motion and stability.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lat_pulldown(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    rep_count = 0\n",
    "    pulldown_stage = None  # \"up\" or \"down\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    elbow_angles = []  # Track elbow flexion\n",
    "    shoulder_positions = []  # Track if shoulders stay down\n",
    "    torso_angles = []  # Check for excessive leaning back\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate average elbow angle\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elbow_angles.append(avg_elbow_angle)\n",
    "            \n",
    "            # Track shoulder positions (y coordinate - lower is higher up on screen)\n",
    "            avg_shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "            shoulder_positions.append(avg_shoulder_y)\n",
    "            \n",
    "            # Calculate torso angle (mid shoulder to mid hip relative to vertical)\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Reference point directly below mid_hip (creating a vertical line)\n",
    "            vertical_ref = [mid_hip[0], mid_hip[1] + 0.1]\n",
    "            \n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_ref)\n",
    "            if mid_shoulder[0] < mid_hip[0]:  # Leaning left\n",
    "                torso_angle = 360 - torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Visualize the angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {avg_elbow_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine pulldown stage based on elbow angle\n",
    "            if avg_elbow_angle > 150 and (pulldown_stage == \"down\" or pulldown_stage is None):\n",
    "                pulldown_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif avg_elbow_angle < 80 and pulldown_stage == \"up\":\n",
    "                pulldown_stage = \"down\"\n",
    "                rep_count += 1\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Lat pulldown rep #{rep_count} detected at frame with elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    min_elbow_angle = min(elbow_angles)\n",
    "    max_elbow_angle = max(elbow_angles)\n",
    "    \n",
    "    # Analyze shoulder movement - we want minimal vertical movement\n",
    "    shoulder_movement = np.max(shoulder_positions) - np.min(shoulder_positions)\n",
    "    \n",
    "    # Analyze torso angle - check for excessive leaning back\n",
    "    max_torso_angle = max(torso_angles)\n",
    "    avg_torso_angle = np.mean(torso_angles)\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_elbow_angle\": min_elbow_angle,  # Lower is better (deeper pulldown)\n",
    "            \"max_elbow_angle\": max_elbow_angle,  # Higher is better (full extension)\n",
    "            \"shoulder_stability\": 100 - (shoulder_movement * 100),  # Higher is better\n",
    "            \"torso_angle\": avg_torso_angle,  # Closer to vertical (0) is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if min_elbow_angle > 70:\n",
    "        feedback[\"feedback\"].append(\"Try to pull the bar down more completely. Aim to bring it close to your chest.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Allow your arms to fully extend at the top of the movement.\")\n",
    "    \n",
    "    if shoulder_movement > 0.1:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders down and back. Avoid shrugging during the exercise.\")\n",
    "    \n",
    "    if avg_torso_angle > 100 or max_torso_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Maintain a more upright posture. Avoid leaning back excessively during the pulldown.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your lat pulldowns show good range of motion with stable shoulders and torso.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cable_row(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    rep_count = 0\n",
    "    row_stage = None  # \"extended\" or \"retracted\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    elbow_angles = []  # Track elbow angle\n",
    "    back_angles = []   # Track back angle to ensure upright posture\n",
    "    shoulder_retraction = []  # Track how far shoulders pull back\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate average elbow angle\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elbow_angles.append(avg_elbow_angle)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Reference point directly below mid_hip (creating a vertical line)\n",
    "            vertical_ref = [mid_hip[0], mid_hip[1] + 0.1]\n",
    "            \n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_ref)\n",
    "            if mid_shoulder[0] < mid_hip[0]:  # Leaning left\n",
    "                back_angle = 360 - back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Measure shoulder retraction (x-distance from wrists to shoulders)\n",
    "            # Lower values mean more retraction (shoulders pulling back relative to wrists)\n",
    "            left_retraction = abs(left_wrist[0] - left_shoulder[0])\n",
    "            right_retraction = abs(right_wrist[0] - right_shoulder[0])\n",
    "            avg_retraction = (left_retraction + right_retraction) / 2\n",
    "            shoulder_retraction.append(avg_retraction)\n",
    "            \n",
    "            # Visualize the angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {avg_elbow_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine row stage based on elbow angle and shoulder position\n",
    "            if avg_elbow_angle > 150 and (row_stage == \"retracted\" or row_stage is None):\n",
    "                row_stage = \"extended\"\n",
    "                cv2.putText(annotated_image, 'EXTENDED', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif avg_elbow_angle < 80 and row_stage == \"extended\":\n",
    "                row_stage = \"retracted\"\n",
    "                rep_count += 1\n",
    "                cv2.putText(annotated_image, 'RETRACTED', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Cable row rep #{rep_count} detected at frame with elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    min_elbow_angle = min(elbow_angles)\n",
    "    max_elbow_angle = max(elbow_angles)\n",
    "    \n",
    "    # Range of retraction (higher is better)\n",
    "    retraction_range = max(shoulder_retraction) - min(shoulder_retraction)\n",
    "    \n",
    "    # Back angle - should remain consistent and upright\n",
    "    avg_back_angle = np.mean(back_angles)\n",
    "    back_angle_variation = np.std(back_angles)\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_elbow_angle\": min_elbow_angle,  # Lower is better (more bend)\n",
    "            \"max_elbow_angle\": max_elbow_angle,  # Higher is better (full extension)\n",
    "            \"retraction_range\": retraction_range * 100,  # Higher is better (scaled for readability)\n",
    "            \"back_angle\": avg_back_angle,  # Should be close to 0 (upright)\n",
    "            \"back_stability\": 100 - (back_angle_variation * 10),  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if min_elbow_angle > 70:\n",
    "        feedback[\"feedback\"].append(\"Pull the handle closer to your torso for a more complete row motion.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the start of each rep.\")\n",
    "    \n",
    "    if retraction_range < 0.2:\n",
    "        feedback[\"feedback\"].append(\"Focus on retracting your shoulder blades at the end of each row for better back engagement.\")\n",
    "    \n",
    "    if avg_back_angle > 30:\n",
    "        feedback[\"feedback\"].append(\"Try to maintain a more upright torso position. You're leaning forward too much.\")\n",
    "    \n",
    "    if back_angle_variation > 10:\n",
    "        feedback[\"feedback\"].append(\"Keep your back angle more consistent throughout the exercise.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your cable rows show good range of motion with proper back positioning.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_shoulder_press(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" or \"down\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    arm_extensions = []  # Track how much arms extend\n",
    "    shoulder_heights = []  # Track shoulder positioning\n",
    "    elbow_angles = []  # Track elbow angles for symmetry\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elbow_angles.append((left_elbow_angle, right_elbow_angle))\n",
    "            \n",
    "            # Track vertical position of wrists relative to shoulders\n",
    "            # (for measuring arm extension in a press)\n",
    "            left_extension = left_shoulder[1] - left_wrist[1]  # Positive when wrist is above shoulder\n",
    "            right_extension = right_shoulder[1] - right_wrist[1]\n",
    "            avg_extension = (left_extension + right_extension) / 2\n",
    "            arm_extensions.append(avg_extension)\n",
    "            \n",
    "            # Track shoulder height (should stay down, not shrugging)\n",
    "            avg_shoulder_height = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "            shoulder_heights.append(avg_shoulder_height)\n",
    "            \n",
    "            # Visualize the angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L Elbow: {left_elbow_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R Elbow: {right_elbow_angle:.1f}°\",\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on arm extension\n",
    "            if avg_extension > 0.15 and (press_stage == \"down\" or press_stage is None):\n",
    "                press_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif avg_extension < 0.05 and press_stage == \"up\":\n",
    "                press_stage = \"down\"\n",
    "                rep_count += 1\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Shoulder press rep #{rep_count} detected with arm extension {avg_extension:.3f}\")\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    max_extension = max(arm_extensions)\n",
    "    \n",
    "    # Calculate arm symmetry (difference between left and right elbow angles)\n",
    "    angle_diffs = [abs(angles[0] - angles[1]) for angles in elbow_angles]\n",
    "    avg_asymmetry = np.mean(angle_diffs)\n",
    "    \n",
    "    # Shoulder movement (shrugging) - lower variation is better\n",
    "    shoulder_movement = np.std(shoulder_heights) * 100\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"max_extension\": max_extension * 100,  # Higher is better (scaled for readability)\n",
    "            \"arm_symmetry\": 100 - avg_asymmetry,  # Higher is better\n",
    "            \"shoulder_stability\": 100 - shoulder_movement,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if max_extension < 0.15:\n",
    "        feedback[\"feedback\"].append(\"Try to press higher for a full range of motion. Extend your arms more fully overhead.\")\n",
    "    \n",
    "    if avg_asymmetry > 15:\n",
    "        feedback[\"feedback\"].append(\"Work on more balanced pushing. Your arms are pressing unevenly.\")\n",
    "    \n",
    "    if shoulder_movement > 5:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders down and stable. Avoid shrugging during the press.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your shoulder press shows good extension with balanced, stable movement.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chest_fly(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track exercise state\n",
    "    rep_count = 0\n",
    "    fly_stage = None  # \"open\" or \"closed\" or None\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store metrics for analysis\n",
    "    arm_openings = []  # Track how wide arms open\n",
    "    elbow_angles = []  # Track elbow angles (should remain consistent)\n",
    "    shoulder_positions = []  # Check for shoulder stability\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (should remain relatively constant in a fly)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elbow_angles.append(avg_elbow_angle)\n",
    "            \n",
    "            # Measure arm opening angle\n",
    "            # Use shoulders as reference for the chest plane\n",
    "            # Calculate the angle between shoulder-wrist lines\n",
    "            \n",
    "            # First create vectors from shoulder to wrist\n",
    "            left_arm_vector = [left_wrist[0] - left_shoulder[0], left_wrist[1] - left_shoulder[1]]\n",
    "            right_arm_vector = [right_wrist[0] - right_shoulder[0], right_wrist[1] - right_shoulder[1]]\n",
    "            \n",
    "            # Calculate the angle between these vectors\n",
    "            dot_product = left_arm_vector[0] * right_arm_vector[0] + left_arm_vector[1] * right_arm_vector[1]\n",
    "            left_magnitude = math.sqrt(left_arm_vector[0]**2 + left_arm_vector[1]**2)\n",
    "            right_magnitude = math.sqrt(right_arm_vector[0]**2 + right_arm_vector[1]**2)\n",
    "            \n",
    "            if left_magnitude > 0 and right_magnitude > 0:  # Avoid division by zero\n",
    "                cos_angle = dot_product / (left_magnitude * right_magnitude)\n",
    "                # Clamp cos_angle to [-1, 1] to avoid errors due to precision\n",
    "                cos_angle = max(min(cos_angle, 1.0), -1.0)\n",
    "                opening_angle = math.degrees(math.acos(cos_angle))\n",
    "                arm_openings.append(opening_angle)\n",
    "            \n",
    "            # Track shoulder stability (y positions)\n",
    "            shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "            shoulder_positions.append(shoulder_y)\n",
    "            \n",
    "            # Visualize the angles\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Opening: {opening_angle:.1f}°\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {avg_elbow_angle:.1f}°\",\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine fly stage based on opening angle\n",
    "            if opening_angle > 80 and (fly_stage == \"closed\" or fly_stage is None):\n",
    "                fly_stage = \"open\"\n",
    "                cv2.putText(annotated_image, 'OPEN', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            elif opening_angle < 30 and fly_stage == \"open\":\n",
    "                fly_stage = \"closed\"\n",
    "                rep_count += 1\n",
    "                cv2.putText(annotated_image, 'CLOSED', (50, 90), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Chest fly rep #{rep_count} detected with opening angle {opening_angle:.1f}°\")\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "    \n",
    "    # Calculate metrics for analysis\n",
    "    max_opening = max(arm_openings)\n",
    "    min_opening = min(arm_openings)\n",
    "    opening_range = max_opening - min_opening\n",
    "    \n",
    "    # Elbow angle consistency (should stay relatively constant in a fly)\n",
    "    elbow_variation = np.std(elbow_angles)\n",
    "    \n",
    "    # Shoulder stability\n",
    "    shoulder_movement = np.std(shoulder_positions) * 100\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"max_opening\": max_opening,  # Higher is better\n",
    "            \"min_opening\": min_opening,  # Lower is better\n",
    "            \"range_of_motion\": opening_range,  # Higher is better\n",
    "            \"elbow_consistency\": 100 - (elbow_variation * 2),  # Higher is better\n",
    "            \"shoulder_stability\": 100 - shoulder_movement,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if max_opening < 70:\n",
    "        feedback[\"feedback\"].append(\"Try to open your arms wider at the start of the movement for a better chest stretch.\")\n",
    "    \n",
    "    if min_opening > 40:\n",
    "        feedback[\"feedback\"].append(\"Bring your arms closer together at the end of the movement for a full contraction.\")\n",
    "    \n",
    "    if elbow_variation > 15:\n",
    "        feedback[\"feedback\"].append(\"Keep your elbows at a more consistent angle throughout the movement (around 90°).\")\n",
    "    \n",
    "    if shoulder_movement > 5:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders pressed against the back pad. Avoid lifting them during the exercise.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your chest fly shows good range of motion with stable shoulders and consistent elbow position.\")\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746077225.668793 1305940 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746077225.768652 1312502 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746077225.781739 1312507 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746077225.800212 1312504 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_russian_twist with video: clips/russian_twist.mov\n",
      "Video dimensions: 1152x1160, FPS: 60\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Rotation Range: 173.7\n",
      "Back Angle: 100.1\n",
      "Hip Stability: 98.7\n",
      "Frames Analyzed: 601\n",
      "\n",
      "Feedback:\n",
      "- Maintain a back angle of about 45 degrees throughout the exercise.\n"
     ]
    }
   ],
   "source": [
    "# Import common libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "# Define exercise analysis functions\n",
    "# [Your exercise functions go here]\n",
    "\n",
    "# Testing function\n",
    "def test_exercise(exercise_function, video_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Test an exercise analysis function and display results\n",
    "    \n",
    "    Args:\n",
    "        exercise_function: The analysis function to test\n",
    "        video_path: Path to the test video\n",
    "        output_path: Optional path for the annotated output video\n",
    "    \"\"\"\n",
    "    print(f\"Testing {exercise_function.__name__} with video: {video_path}\")\n",
    "    \n",
    "    # Verify the video exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file {video_path} not found\")\n",
    "        return\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = exercise_function(video_path, output_path)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "        return\n",
    "    \n",
    "    # Print rep count\n",
    "    count_key = next((k for k in result.keys() if k.endswith('_count')), None)\n",
    "    if count_key:\n",
    "        print(f\"Counted {result[count_key]} reps\")\n",
    "    \n",
    "    # Print form analysis metrics\n",
    "    if \"form_analysis\" in result:\n",
    "        for key, value in result[\"form_analysis\"].items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value:.1f}\")\n",
    "            else:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    # Print feedback\n",
    "    if \"feedback\" in result:\n",
    "        print(\"\\nFeedback:\")\n",
    "        for item in result[\"feedback\"]:\n",
    "            print(f\"- {item}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test each exercise\n",
    "# Each of these cells can be run independently to test a specific exercise\n",
    "\n",
    "# Test Russian Twists\n",
    "russian_twist_result = test_exercise(\n",
    "    analyze_russian_twist, \n",
    "    \"data_da/russian_twist.mov\", \n",
    "    \"data_da/analyzed_russian_twist.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_situp with video: clips/situp.MOV\n",
      "Video dimensions: 1936x1198, FPS: 60\n",
      "Situp #1 detected at frame with torso angle 27.7°\n",
      "Situp #2 detected at frame with torso angle 27.1°\n",
      "Situp #3 detected at frame with torso angle 28.2°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 3 reps\n",
      "Min Torso Angle: 0.3\n",
      "Neck Position: 108.8\n",
      "Leg Position: 78.6\n",
      "Frames Analyzed: 1027\n",
      "\n",
      "Feedback:\n",
      "- Keep your neck neutral throughout the movement. Avoid pulling with your neck.\n"
     ]
    }
   ],
   "source": [
    "# Test Sit-ups\n",
    "situp_result = test_exercise(\n",
    "    analyze_situp, \n",
    "    \"data_da/situp.MOV\", \n",
    "    \"data_da/analyzed_situp.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_side_bend with video: clips/side_bend.MOV\n",
      "Video dimensions: 1226x1176, FPS: 60\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 reps\n",
      "Max Left Bend: 33.0\n",
      "Max Right Bend: 27.7\n",
      "Bend Symmetry: 83.9\n",
      "Hip Stability: 85.5\n",
      "Forward Motion: 3.7\n",
      "Frames Analyzed: 850\n",
      "\n",
      "Feedback:\n",
      "- Great form! Your side bends show good range and balance on both sides.\n"
     ]
    }
   ],
   "source": [
    "# Test Side Bends\n",
    "side_bend_result = test_exercise(\n",
    "    analyze_side_bend, \n",
    "    \"data_da/side_bend.MOV\", \n",
    "    \"data_da/analyzed_side_bend.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_bench_press with video: clips/bench_press.MOV\n",
      "Video dimensions: 1734x1142, FPS: 60\n",
      "Bench press rep #1 detected at frame with elbow angle 61.3°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 reps\n",
      "Min Elbow Angle: 16.0\n",
      "Max Elbow Angle: 163.2\n",
      "Bar Path Stability: 86.9\n",
      "Shoulder Stability: 93.3\n",
      "Frames Analyzed: 404\n",
      "\n",
      "Feedback:\n",
      "- Work on a more consistent bar path. Try to keep the bar moving in a straight vertical line.\n"
     ]
    }
   ],
   "source": [
    "# Test Bench Press\n",
    "bench_press_result = test_exercise(\n",
    "    analyze_bench_press, \n",
    "    \"data_da/bench_press.MOV\", \n",
    "    \"data_da/analyzed_bench_press.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_lat_pulldown with video: clips/lat_pulldown.MOV\n",
      "Video dimensions: 952x1148, FPS: 60\n",
      "Lat pulldown rep #1 detected at frame with elbow angle 77.0°\n",
      "Lat pulldown rep #2 detected at frame with elbow angle 79.5°\n",
      "Lat pulldown rep #3 detected at frame with elbow angle 78.6°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 3 reps\n",
      "Min Elbow Angle: 22.3\n",
      "Max Elbow Angle: 177.8\n",
      "Shoulder Stability: 80.0\n",
      "Torso Angle: 153.5\n",
      "Frames Analyzed: 551\n",
      "\n",
      "Feedback:\n",
      "- Keep your shoulders down and back. Avoid shrugging during the exercise.\n",
      "- Maintain a more upright posture. Avoid leaning back excessively during the pulldown.\n"
     ]
    }
   ],
   "source": [
    "# Test Lat Pulldowns\n",
    "lat_pulldown_result = test_exercise(\n",
    "    analyze_lat_pulldown, \n",
    "    \"data_da/lat_pulldown.MOV\", \n",
    "    \"data_da/analyzed_lat_pulldown.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_cable_row with video: clips/cable_row.MOV\n",
      "Video dimensions: 1606x1148, FPS: 60\n",
      "Cable row rep #1 detected at frame with elbow angle 77.9°\n",
      "Cable row rep #2 detected at frame with elbow angle 71.4°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 2 reps\n",
      "Min Elbow Angle: 68.5\n",
      "Max Elbow Angle: 160.1\n",
      "Retraction Range: 18.8\n",
      "Back Angle: 187.2\n",
      "Back Stability: -33.2\n",
      "Frames Analyzed: 468\n",
      "\n",
      "Feedback:\n",
      "- Focus on retracting your shoulder blades at the end of each row for better back engagement.\n",
      "- Try to maintain a more upright torso position. You're leaning forward too much.\n",
      "- Keep your back angle more consistent throughout the exercise.\n"
     ]
    }
   ],
   "source": [
    "# Test Cable Rows\n",
    "cable_row_result = test_exercise(\n",
    "    analyze_cable_row, \n",
    "    \"data_da/cable_row.MOV\", \n",
    "    \"data_da/analyzed_cable_row.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_shoulder_press with video: clips/shoulder_press.MOV\n",
      "Video dimensions: 1120x1148, FPS: 60\n",
      "Shoulder press rep #1 detected with arm extension 0.047\n",
      "Shoulder press rep #2 detected with arm extension 0.050\n",
      "Shoulder press rep #3 detected with arm extension 0.048\n",
      "Shoulder press rep #4 detected with arm extension 0.042\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 4 reps\n",
      "Max Extension: 30.6\n",
      "Arm Symmetry: 71.5\n",
      "Shoulder Stability: 98.9\n",
      "Frames Analyzed: 743\n",
      "\n",
      "Feedback:\n",
      "- Work on more balanced pushing. Your arms are pressing unevenly.\n"
     ]
    }
   ],
   "source": [
    "# Test Shoulder Press\n",
    "shoulder_press_result = test_exercise(\n",
    "    analyze_shoulder_press, \n",
    "    \"data_da/shoulder_press.MOV\", \n",
    "    \"data_da/analyzed_shoulder_press.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing analyze_chest_fly with video: clips/chest_fly.MOV\n",
      "Video dimensions: 2284x1076, FPS: 60\n",
      "Chest fly rep #1 detected with opening angle 28.0°\n",
      "Chest fly rep #2 detected with opening angle 22.3°\n",
      "Chest fly rep #3 detected with opening angle 29.9°\n",
      "Chest fly rep #4 detected with opening angle 8.1°\n",
      "Chest fly rep #5 detected with opening angle 27.5°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 5 reps\n",
      "Max Opening: 163.9\n",
      "Min Opening: 0.0\n",
      "Range Of Motion: 163.9\n",
      "Elbow Consistency: 30.6\n",
      "Shoulder Stability: 99.1\n",
      "Frames Analyzed: 1409\n",
      "\n",
      "Feedback:\n",
      "- Keep your elbows at a more consistent angle throughout the movement (around 90°).\n"
     ]
    }
   ],
   "source": [
    "# Test Chest Fly\n",
    "chest_fly_result = test_exercise(\n",
    "    analyze_chest_fly, \n",
    "    \"data_da/chest_fly.MOV\", \n",
    "    \"data_da/analyzed_chest_fly.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
