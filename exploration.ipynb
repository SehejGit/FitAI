{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (0.10.21)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: absl-py in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: jaxlib in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: matplotlib in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (3.10.1)\n",
      "Requirement already satisfied: numpy<2 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (4.25.7)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: opt_einsum in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from jax->mediapipe) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.24.3\n",
      "\u001b[2K    Uninstalling numpy-1.24.3:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.24.3\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [opencv-python]0m [opencv-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-1.26.4 opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745947321.250408 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "OpenCV: Couldn't read video stream from file \"pushup.MOV\"\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1745947321.329038 6322255 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947321.343162 6322261 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feedback\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_pushup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpushup.MOV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpushup_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pushups\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody alignment score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mform_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_alignment_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 98\u001b[0m, in \u001b[0;36manalyze_pushup\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Analyze the data collected\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m avg_elbow_angle_bottom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melbow_angles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m avg_elbow_angle_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(elbow_angles)\n\u001b[1;32m    100\u001b[0m avg_alignment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(body_alignment_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(body_alignment_scores)\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_pushup(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Variables to track pushup state\n",
    "    pushup_count = 0\n",
    "    pushup_stage = None  # \"up\" or \"down\"\n",
    "    \n",
    "    # Lists to store angles for analysis\n",
    "    elbow_angles = []\n",
    "    body_alignment_scores = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points for pushup analysis\n",
    "            # Shoulders, elbows, wrists\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate elbow angle (important for pushup depth)\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get right elbow angle (shoulder-elbow-wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            elbow_angles.append(right_elbow_angle)\n",
    "            \n",
    "            # Check body alignment (straight back)\n",
    "            # Get hip, shoulder, and ankle points\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # Calculate body alignment score (how straight the body is)\n",
    "            # Higher score means better alignment\n",
    "            hip_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            hip_ankle_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "            \n",
    "            # Ideally both angles should be close to 180 degrees in a proper pushup\n",
    "            alignment_score = (180 - abs(hip_shoulder_angle - 180) - abs(hip_ankle_angle - 180))/180\n",
    "            body_alignment_scores.append(alignment_score)\n",
    "            \n",
    "            # Determine pushup stage based on elbow angle\n",
    "            if right_elbow_angle > 150:\n",
    "                pushup_stage = \"up\"\n",
    "            \n",
    "            # If we were in \"up\" position and now angle is < 90, we're in \"down\" position\n",
    "            elif right_elbow_angle < 90 and pushup_stage == \"up\":\n",
    "                pushup_stage = \"down\"\n",
    "                pushup_count += 1\n",
    "                \n",
    "    cap.release()\n",
    "    \n",
    "    # Analyze the data collected\n",
    "    avg_elbow_angle_bottom = min(elbow_angles)\n",
    "    avg_elbow_angle_top = max(elbow_angles)\n",
    "    avg_alignment = sum(body_alignment_scores) / len(body_alignment_scores)\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"pushup_count\": pushup_count,\n",
    "        \"form_analysis\": {\n",
    "            \"elbow_angle_at_bottom\": avg_elbow_angle_bottom,\n",
    "            \"elbow_angle_at_top\": avg_elbow_angle_top,\n",
    "            \"body_alignment_score\": avg_alignment * 100  # Convert to percentage\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_elbow_angle_bottom > 90:\n",
    "        feedback[\"feedback\"].append(\"You're not going deep enough. Try to lower your body until your elbows are at 90 degrees.\")\n",
    "    \n",
    "    if avg_elbow_angle_top < 150:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arms at the top of the pushup.\")\n",
    "    \n",
    "    if avg_alignment < 0.8:\n",
    "        feedback[\"feedback\"].append(\"Keep your body straighter throughout the movement. Your hips are sagging or piking.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your pushups have good depth and body alignment.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_pushup(\"pushup.MOV\")\n",
    "print(f\"Counted {result['pushup_count']} pushups\")\n",
    "print(f\"Body alignment score: {result['form_analysis']['body_alignment_score']:.1f}%\")\n",
    "print(\"\\nFeedback:\")\n",
    "for item in result[\"feedback\"]:\n",
    "    print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743722914.783497 14958205 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1743722914.855040 14971231 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743722914.866219 14971231 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29\n",
      "Detected 33 landmarks\n",
      "Pushup #1 detected at frame with elbow angle 97.1\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 pushups\n",
      "Body alignment score: 10.5%\n",
      "Lowest elbow angle: 6.9°\n",
      "Highest elbow angle: 126.2°\n",
      "Frames analyzed: 86\n",
      "\n",
      "Feedback:\n",
      "- You're not fully extending your arms at the top of the pushup.\n",
      "- Keep your body straighter throughout the movement. Your hips are sagging or piking.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_pushup(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track pushup state\n",
    "    pushup_count = 0\n",
    "    pushup_stage = None  # \"up\" or \"down\"\n",
    "    frames_without_detection = 0\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles for analysis\n",
    "    elbow_angles = []\n",
    "    body_alignment_scores = []\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            frames_without_detection = 0\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for pushup analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get right elbow angle (shoulder-elbow-wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            elbow_angles.append(right_elbow_angle)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize elbow angle\n",
    "            r_shoulder_px = normalized_to_pixel_coordinates(right_shoulder[0], right_shoulder[1], frame_width, frame_height)\n",
    "            r_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            r_wrist_px = normalized_to_pixel_coordinates(right_wrist[0], right_wrist[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {right_elbow_angle:.1f}°\",\n",
    "                        (r_elbow_px[0] - 50, r_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Body alignment check\n",
    "            # Get hip, shoulder, and ankle points\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # Calculate body alignment\n",
    "            hip_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            hip_ankle_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "            \n",
    "            # Better alignment calculation\n",
    "            # Perfect alignment would have both angles close to 180\n",
    "            alignment_score = (180 - abs(hip_shoulder_angle - 180) - abs(hip_ankle_angle - 180))/180\n",
    "            body_alignment_scores.append(alignment_score)\n",
    "            \n",
    "            # Visualize body alignment\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Alignment: {alignment_score*100:.1f}%\",\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine pushup stage based on elbow angle\n",
    "            if right_elbow_angle > 150 and pushup_stage == \"down\":\n",
    "                pushup_stage = \"up\"\n",
    "                # Draw pushup count\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"up\" position and now angle is < 90, we're in \"down\" position\n",
    "            elif right_elbow_angle < 100 and (pushup_stage == \"up\" or pushup_stage is None):\n",
    "                pushup_stage = \"down\"\n",
    "                pushup_count += 1\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Pushup #{pushup_count} detected at frame with elbow angle {right_elbow_angle:.1f}\")\n",
    "        else:\n",
    "            frames_without_detection += 1\n",
    "            if frames_without_detection % 30 == 0:\n",
    "                print(f\"No pose detection for {frames_without_detection} frames\")\n",
    "                \n",
    "        # Display pushup count\n",
    "        cv2.putText(annotated_image, f'Pushups: {pushup_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"pushup_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Analyze the data collected\n",
    "    if elbow_angles:\n",
    "        avg_elbow_angle_bottom = min(elbow_angles)\n",
    "        avg_elbow_angle_top = max(elbow_angles)\n",
    "    else:\n",
    "        avg_elbow_angle_bottom = 0\n",
    "        avg_elbow_angle_top = 0\n",
    "        \n",
    "    avg_alignment = sum(body_alignment_scores) / max(len(body_alignment_scores), 1)\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"pushup_count\": pushup_count,\n",
    "        \"form_analysis\": {\n",
    "            \"elbow_angle_at_bottom\": avg_elbow_angle_bottom,\n",
    "            \"elbow_angle_at_top\": avg_elbow_angle_top,\n",
    "            \"body_alignment_score\": avg_alignment * 100,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_elbow_angle_bottom > 100:\n",
    "        feedback[\"feedback\"].append(\"You're not going deep enough. Try to lower your body until your elbows are at 90 degrees.\")\n",
    "    \n",
    "    if avg_elbow_angle_top < 150:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arms at the top of the pushup.\")\n",
    "    \n",
    "    if avg_alignment < 0.8:\n",
    "        feedback[\"feedback\"].append(\"Keep your body straighter throughout the movement. Your hips are sagging or piking.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your pushups have good depth and body alignment.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_pushup(\"pushup.MOV\", \"analyzed_pushup.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('pushup_count', 0)} pushups\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Body alignment score: {result['form_analysis']['body_alignment_score']:.1f}%\")\n",
    "    print(f\"Lowest elbow angle: {result['form_analysis']['elbow_angle_at_bottom']:.1f}°\")\n",
    "    print(f\"Highest elbow angle: {result['form_analysis']['elbow_angle_at_top']:.1f}°\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 0x0, FPS: 0\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 curls\n",
      "Error: Not enough valid pose detections. Check video quality and positioning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745945055.400436 6263613 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "OpenCV: Couldn't read video stream from file \"curl.MOV\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1745945055.469340 6266840 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745945055.481120 6266840 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_bicep_curl(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track bicep curl state\n",
    "    curl_count = 0\n",
    "    curl_stage = None  # \"up\" or \"down\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles = []\n",
    "    shoulder_stability = []\n",
    "    hip_stability = []\n",
    "    wrist_angles = []\n",
    "    rep_depths = []  # To track curl depth\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for curl analysis\n",
    "            # We'll focus on right arm for simplicity, but you could analyze both\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get elbow angle (shoulder-elbow-wrist)\n",
    "            elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            elbow_angles.append(elbow_angle)\n",
    "            \n",
    "            # Track shoulder stability - shoulder should remain still relative to hip\n",
    "            shoulder_hip_distance = np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "            shoulder_stability.append(shoulder_hip_distance)\n",
    "            \n",
    "            # Measure wrist angle relative to forearm (to detect wrist curling/improper form)\n",
    "            # For simplicity, we'll estimate this as deviation from straight line\n",
    "            wrist_deviation = abs(elbow_angle - 180) if elbow_angle > 90 else elbow_angle\n",
    "            wrist_angles.append(wrist_deviation)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize elbow angle\n",
    "            shoulder_px = normalized_to_pixel_coordinates(shoulder[0], shoulder[1], frame_width, frame_height)\n",
    "            elbow_px = normalized_to_pixel_coordinates(elbow[0], elbow[1], frame_width, frame_height)\n",
    "            wrist_px = normalized_to_pixel_coordinates(wrist[0], wrist[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {elbow_angle:.1f}°\",\n",
    "                        (elbow_px[0] - 50, elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine curl stage based on elbow angle\n",
    "            if elbow_angle > 160 and curl_stage == \"up\":\n",
    "                curl_stage = \"down\"\n",
    "                # Draw curl stage\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"down\" position and now angle is < 60, we're in \"up\" position\n",
    "            elif elbow_angle < 60 and (curl_stage == \"down\" or curl_stage is None):\n",
    "                curl_stage = \"up\"\n",
    "                curl_count += 1\n",
    "                rep_depths.append(elbow_angle)  # Store depth of curl\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Curl #{curl_count} detected at frame with elbow angle {elbow_angle:.1f}\")\n",
    "                \n",
    "        # Display curl count\n",
    "        cv2.putText(annotated_image, f'Curls: {curl_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"curl_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_shoulder_stability = np.std(shoulder_stability) * 100  # Convert to percentage variation\n",
    "    avg_wrist_deviation = np.mean(wrist_angles)\n",
    "    avg_curl_depth = np.mean(rep_depths) if rep_depths else 0\n",
    "    full_extension = np.max(elbow_angles) > 150\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"curl_count\": curl_count,\n",
    "        \"form_analysis\": {\n",
    "            \"curl_depth\": avg_curl_depth,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"shoulder_stability\": 100 - avg_shoulder_stability,  # Higher is better\n",
    "            \"wrist_stability\": 100 - avg_wrist_deviation,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_curl_depth > 45:\n",
    "        feedback[\"feedback\"].append(\"You're not curling the weight fully to your shoulder. Try to bring the weight closer to your shoulder.\")\n",
    "    \n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arm at the bottom of the curl. Straighten your arm more for full range of motion.\")\n",
    "    \n",
    "    if avg_shoulder_stability > 10:  # If shoulder position varies too much\n",
    "        feedback[\"feedback\"].append(\"Keep your upper arm and shoulder more stable during the curl. Avoid swinging.\")\n",
    "    \n",
    "    if avg_wrist_deviation > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrist straight throughout the movement. Avoid bending your wrist.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bicep curls show good depth, stable shoulders, and proper wrist position.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_bicep_curl(\"curl.MOV\", \"analyzed_curl.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('curl_count', 0)} curls\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Curl depth (lower is better): {result['form_analysis']['curl_depth']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist stability: {result['form_analysis']['wrist_stability']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp310-cp310-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (25.3.0)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Downloading jaxlib-0.6.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (3.10.1)\n",
      "Requirement already satisfied: numpy<2 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from mediapipe) (1.26.4)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Downloading protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from jax->mediapipe) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tylergallup/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Downloading mediapipe-0.10.21-cp310-cp310-macosx_11_0_universal2.whl (49.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.6.0-cp310-cp310-macosx_11_0_arm64.whl (53.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.5/671.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, flatbuffers, protobuf, opt_einsum, opencv-contrib-python, ml_dtypes, absl-py, sounddevice, jaxlib, jax, mediapipe\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.0rc1\n",
      "\u001b[2K    Uninstalling protobuf-6.31.0rc1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.0rc1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [mediapipe]11\u001b[0m [mediapipe]trib-python]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.72.0rc1 requires protobuf<7.0dev,>=6.30.0, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.2.2 flatbuffers-25.2.10 jax-0.6.0 jaxlib-0.6.0 mediapipe-0.10.21 ml_dtypes-0.5.1 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 protobuf-4.25.7 sentencepiece-0.2.0 sounddevice-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948767.804237 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948767.894514 6365419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948767.909731 6365419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29\n",
      "Detected 33 landmarks\n",
      "Curl #1 detected at frame with elbow angle 54.8\n",
      "Curl #2 detected at frame with elbow angle 57.3\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 2 curls\n",
      "Curl depth (lower is better): 56.0°\n",
      "Full arm extension: Yes\n",
      "Shoulder stability: 99.7%\n",
      "Wrist stability: 72.8%\n",
      "Frames analyzed: 388\n",
      "\n",
      "Feedback:\n",
      "- You're not curling the weight fully to your shoulder. Try to bring the weight closer to your shoulder.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_bicep_curl(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track bicep curl state\n",
    "    curl_count = 0\n",
    "    curl_stage = None  # \"up\" or \"down\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles = []\n",
    "    shoulder_stability = []\n",
    "    hip_stability = []\n",
    "    wrist_angles = []\n",
    "    rep_depths = []  # To track curl depth\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for curl analysis\n",
    "            # We'll focus on right arm for simplicity, but you could analyze both\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get elbow angle (shoulder-elbow-wrist)\n",
    "            elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            elbow_angles.append(elbow_angle)\n",
    "            \n",
    "            # Track shoulder stability - shoulder should remain still relative to hip\n",
    "            shoulder_hip_distance = np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "            shoulder_stability.append(shoulder_hip_distance)\n",
    "            \n",
    "            # Measure wrist angle relative to forearm (to detect wrist curling/improper form)\n",
    "            # For simplicity, we'll estimate this as deviation from straight line\n",
    "            wrist_deviation = abs(elbow_angle - 180) if elbow_angle > 90 else elbow_angle\n",
    "            wrist_angles.append(wrist_deviation)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize elbow angle\n",
    "            shoulder_px = normalized_to_pixel_coordinates(shoulder[0], shoulder[1], frame_width, frame_height)\n",
    "            elbow_px = normalized_to_pixel_coordinates(elbow[0], elbow[1], frame_width, frame_height)\n",
    "            wrist_px = normalized_to_pixel_coordinates(wrist[0], wrist[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {elbow_angle:.1f}°\",\n",
    "                        (elbow_px[0] - 50, elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine curl stage based on elbow angle\n",
    "            if elbow_angle > 160 and curl_stage == \"up\":\n",
    "                curl_stage = \"down\"\n",
    "                # Draw curl stage\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"down\" position and now angle is < 60, we're in \"up\" position\n",
    "            elif elbow_angle < 60 and (curl_stage == \"down\" or curl_stage is None):\n",
    "                curl_stage = \"up\"\n",
    "                curl_count += 1\n",
    "                rep_depths.append(elbow_angle)  # Store depth of curl\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Curl #{curl_count} detected at frame with elbow angle {elbow_angle:.1f}\")\n",
    "                \n",
    "        # Display curl count\n",
    "        cv2.putText(annotated_image, f'Curls: {curl_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"curl_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_shoulder_stability = np.std(shoulder_stability) * 100  # Convert to percentage variation\n",
    "    avg_wrist_deviation = np.mean(wrist_angles)\n",
    "    avg_curl_depth = np.mean(rep_depths) if rep_depths else 0\n",
    "    full_extension = np.max(elbow_angles) > 150\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"curl_count\": curl_count,\n",
    "        \"form_analysis\": {\n",
    "            \"curl_depth\": avg_curl_depth,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"shoulder_stability\": 100 - avg_shoulder_stability,  # Higher is better\n",
    "            \"wrist_stability\": 100 - avg_wrist_deviation,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_curl_depth > 45:\n",
    "        feedback[\"feedback\"].append(\"You're not curling the weight fully to your shoulder. Try to bring the weight closer to your shoulder.\")\n",
    "    \n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arm at the bottom of the curl. Straighten your arm more for full range of motion.\")\n",
    "    \n",
    "    if avg_shoulder_stability > 10:  # If shoulder position varies too much\n",
    "        feedback[\"feedback\"].append(\"Keep your upper arm and shoulder more stable during the curl. Avoid swinging.\")\n",
    "    \n",
    "    if avg_wrist_deviation > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrist straight throughout the movement. Avoid bending your wrist.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bicep curls show good depth, stable shoulders, and proper wrist position.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_bicep_curl(\"clips/BicepCurl1.MOV\", \"clips/analyzed_curl1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('curl_count', 0)} curls\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Curl depth (lower is better): {result['form_analysis']['curl_depth']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist stability: {result['form_analysis']['wrist_stability']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948799.276314 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948799.348395 6366511 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948799.358357 6366521 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29\n",
      "Detected 33 landmarks\n",
      "Curl #1 detected at frame with elbow angle 42.8\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 curls\n",
      "Curl depth (lower is better): 42.8°\n",
      "Full arm extension: Yes\n",
      "Shoulder stability: 99.0%\n",
      "Wrist stability: 31.6%\n",
      "Frames analyzed: 459\n",
      "\n",
      "Feedback:\n",
      "- Keep your wrist straight throughout the movement. Avoid bending your wrist.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_bicep_curl(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track bicep curl state\n",
    "    curl_count = 0\n",
    "    curl_stage = None  # \"up\" or \"down\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles = []\n",
    "    shoulder_stability = []\n",
    "    hip_stability = []\n",
    "    wrist_angles = []\n",
    "    rep_depths = []  # To track curl depth\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for curl analysis\n",
    "            # We'll focus on right arm for simplicity, but you could analyze both\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get elbow angle (shoulder-elbow-wrist)\n",
    "            elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            elbow_angles.append(elbow_angle)\n",
    "            \n",
    "            # Track shoulder stability - shoulder should remain still relative to hip\n",
    "            shoulder_hip_distance = np.sqrt((shoulder[0] - hip[0])**2 + (shoulder[1] - hip[1])**2)\n",
    "            shoulder_stability.append(shoulder_hip_distance)\n",
    "            \n",
    "            # Measure wrist angle relative to forearm (to detect wrist curling/improper form)\n",
    "            # For simplicity, we'll estimate this as deviation from straight line\n",
    "            wrist_deviation = abs(elbow_angle - 180) if elbow_angle > 90 else elbow_angle\n",
    "            wrist_angles.append(wrist_deviation)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize elbow angle\n",
    "            shoulder_px = normalized_to_pixel_coordinates(shoulder[0], shoulder[1], frame_width, frame_height)\n",
    "            elbow_px = normalized_to_pixel_coordinates(elbow[0], elbow[1], frame_width, frame_height)\n",
    "            wrist_px = normalized_to_pixel_coordinates(wrist[0], wrist[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {elbow_angle:.1f}°\",\n",
    "                        (elbow_px[0] - 50, elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine curl stage based on elbow angle\n",
    "            if elbow_angle > 160 and curl_stage == \"up\":\n",
    "                curl_stage = \"down\"\n",
    "                # Draw curl stage\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"down\" position and now angle is < 60, we're in \"up\" position\n",
    "            elif elbow_angle < 60 and (curl_stage == \"down\" or curl_stage is None):\n",
    "                curl_stage = \"up\"\n",
    "                curl_count += 1\n",
    "                rep_depths.append(elbow_angle)  # Store depth of curl\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                print(f\"Curl #{curl_count} detected at frame with elbow angle {elbow_angle:.1f}\")\n",
    "                \n",
    "        # Display curl count\n",
    "        cv2.putText(annotated_image, f'Curls: {curl_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"curl_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_shoulder_stability = np.std(shoulder_stability) * 100  # Convert to percentage variation\n",
    "    avg_wrist_deviation = np.mean(wrist_angles)\n",
    "    avg_curl_depth = np.mean(rep_depths) if rep_depths else 0\n",
    "    full_extension = np.max(elbow_angles) > 150\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"curl_count\": curl_count,\n",
    "        \"form_analysis\": {\n",
    "            \"curl_depth\": avg_curl_depth,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"shoulder_stability\": 100 - avg_shoulder_stability,  # Higher is better\n",
    "            \"wrist_stability\": 100 - avg_wrist_deviation,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_curl_depth > 45:\n",
    "        feedback[\"feedback\"].append(\"You're not curling the weight fully to your shoulder. Try to bring the weight closer to your shoulder.\")\n",
    "    \n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arm at the bottom of the curl. Straighten your arm more for full range of motion.\")\n",
    "    \n",
    "    if avg_shoulder_stability > 10:  # If shoulder position varies too much\n",
    "        feedback[\"feedback\"].append(\"Keep your upper arm and shoulder more stable during the curl. Avoid swinging.\")\n",
    "    \n",
    "    if avg_wrist_deviation > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrist straight throughout the movement. Avoid bending your wrist.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bicep curls show good depth, stable shoulders, and proper wrist position.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_bicep_curl(\"clips/BicepCurl2.MOV\", \"clips/analyzed_curl2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('curl_count', 0)} curls\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Curl depth (lower is better): {result['form_analysis']['curl_depth']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist stability: {result['form_analysis']['wrist_stability']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745945101.329624 6263613 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745945101.420812 6268095 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745945101.432378 6268100 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745945101.446111 6268102 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29\n",
      "Detected 33 landmarks\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Press depth (lower is better): 0.0°\n",
      "Full arm extension: Yes\n",
      "Shoulder stability: 98.1%\n",
      "Wrist alignment: 57.2%\n",
      "Elbow symmetry: 79.3%\n",
      "Frames analyzed: 350\n",
      "\n",
      "Feedback:\n",
      "- Keep your wrists straight and aligned with your forearms. Avoid bending your wrists backward.\n",
      "- Your elbows are moving asymmetrically. Try to keep both arms moving together at the same pace and angle.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_bench_press(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track bench press state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" or \"down\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_width_values = []  # To track shoulder stability\n",
    "    chest_depth_values = []  # To track chest engagement\n",
    "    wrist_alignments = []  # To track wrist alignment with forearms\n",
    "    rep_depths = []  # To track press depth\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for bench press analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Also track chest (mid-point between shoulders) and hip landmarks for back arch analysis\n",
    "            chest = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                    (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            \n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Average elbow angle for determining press stage\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            \n",
    "            # Track shoulder width to ensure stable shoulder position during press\n",
    "            shoulder_width = np.sqrt((left_shoulder[0] - right_shoulder[0])**2 + \n",
    "                                   (left_shoulder[1] - right_shoulder[1])**2)\n",
    "            shoulder_width_values.append(shoulder_width)\n",
    "            \n",
    "            # Track chest depth (y-position of chest relative to shoulders)\n",
    "            # Higher y value means lower position (due to image coordinate system)\n",
    "            chest_depth = chest[1]  \n",
    "            chest_depth_values.append(chest_depth)\n",
    "            \n",
    "            # Track wrist alignment (wrists should be aligned with forearms)\n",
    "            left_wrist_alignment = abs(left_elbow_angle - 180) if left_elbow_angle > 90 else left_elbow_angle\n",
    "            right_wrist_alignment = abs(right_elbow_angle - 180) if right_elbow_angle > 90 else right_elbow_angle\n",
    "            wrist_alignments.append((left_wrist_alignment + right_wrist_alignment) / 2)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on elbow angle\n",
    "            # For bench press, \"down\" is when weights are near chest (elbow angle is small)\n",
    "            # \"up\" is when arms are extended (elbow angle is large)\n",
    "            if avg_elbow_angle > 160 and press_stage == \"down\":\n",
    "                press_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"up\" position and now angle is small, we're in \"down\" position\n",
    "            elif avg_elbow_angle < 90 and (press_stage == \"up\" or press_stage is None):\n",
    "                press_stage = \"down\"\n",
    "                # If we're coming from \"up\", count a rep\n",
    "                if press_stage == \"up\" or press_stage is None:\n",
    "                    rep_count += 1\n",
    "                    rep_depths.append(avg_elbow_angle)  # Store depth of press\n",
    "                    print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}\")\n",
    "                \n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_shoulder_stability = np.std(shoulder_width_values) * 100  # Convert to percentage variation\n",
    "    avg_wrist_alignment = np.mean(wrist_alignments)\n",
    "    avg_press_depth = np.mean(rep_depths) if rep_depths else 0\n",
    "    \n",
    "    # Check for elbow flare (elbows should be at ~45° angle to body)\n",
    "    elbow_symmetry = np.mean(np.abs(np.array(elbow_angles_left) - np.array(elbow_angles_right)))\n",
    "    \n",
    "    # Check for full extension at top of press\n",
    "    full_extension = np.max(elbow_angles_left) > 160 and np.max(elbow_angles_right) > 160\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"press_depth\": avg_press_depth,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"shoulder_stability\": 100 - avg_shoulder_stability,  # Higher is better\n",
    "            \"wrist_alignment\": 100 - avg_wrist_alignment,  # Higher is better\n",
    "            \"elbow_symmetry\": 100 - elbow_symmetry,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_press_depth > 70:  # Not going deep enough\n",
    "        feedback[\"feedback\"].append(\"You're not lowering the weights close enough to your chest. Try to achieve a deeper press for full muscle engagement.\")\n",
    "    \n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arms at the top of the press. Straighten your arms more for full range of motion.\")\n",
    "    \n",
    "    if avg_shoulder_stability > 10:  # If shoulder position varies too much\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders more stable during the press. Avoid excessive movement or shrugging.\")\n",
    "    \n",
    "    if avg_wrist_alignment > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists straight and aligned with your forearms. Avoid bending your wrists backward.\")\n",
    "    \n",
    "    if elbow_symmetry > 20:\n",
    "        feedback[\"feedback\"].append(\"Your elbows are moving asymmetrically. Try to keep both arms moving together at the same pace and angle.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bench press shows good depth, stable shoulders, proper wrist alignment, and symmetrical movement.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_bench_press(\"clips/BenchPress2.MOV\", \"clips/analyzed_bench_press.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Press depth (lower is better): {result['form_analysis']['press_depth']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist alignment: {result['form_analysis']['wrist_alignment']:.1f}%\")\n",
    "    print(f\"Elbow symmetry: {result['form_analysis']['elbow_symmetry']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745945194.285773 6263613 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745945194.366044 6270577 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745945194.379619 6270576 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29\n",
      "Detected 33 landmarks\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Press depth (lower is better): 0.0°\n",
      "Full arm extension: Yes\n",
      "Shoulder stability: 98.8%\n",
      "Wrist alignment: 60.0%\n",
      "Elbow symmetry: 64.6%\n",
      "Frames analyzed: 301\n",
      "\n",
      "Feedback:\n",
      "- Keep your wrists straight and aligned with your forearms. Avoid bending your wrists backward.\n",
      "- Your elbows are moving asymmetrically. Try to keep both arms moving together at the same pace and angle.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_bench_press(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track bench press state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" or \"down\"\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_width_values = []  # To track shoulder stability\n",
    "    chest_depth_values = []  # To track chest engagement\n",
    "    wrist_alignments = []  # To track wrist alignment with forearms\n",
    "    rep_depths = []  # To track press depth\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for bench press analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Also track chest (mid-point between shoulders) and hip landmarks for back arch analysis\n",
    "            chest = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                    (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            \n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Get elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Average elbow angle for determining press stage\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            \n",
    "            # Track shoulder width to ensure stable shoulder position during press\n",
    "            shoulder_width = np.sqrt((left_shoulder[0] - right_shoulder[0])**2 + \n",
    "                                   (left_shoulder[1] - right_shoulder[1])**2)\n",
    "            shoulder_width_values.append(shoulder_width)\n",
    "            \n",
    "            # Track chest depth (y-position of chest relative to shoulders)\n",
    "            # Higher y value means lower position (due to image coordinate system)\n",
    "            chest_depth = chest[1]  \n",
    "            chest_depth_values.append(chest_depth)\n",
    "            \n",
    "            # Track wrist alignment (wrists should be aligned with forearms)\n",
    "            left_wrist_alignment = abs(left_elbow_angle - 180) if left_elbow_angle > 90 else left_elbow_angle\n",
    "            right_wrist_alignment = abs(right_elbow_angle - 180) if right_elbow_angle > 90 else right_elbow_angle\n",
    "            wrist_alignments.append((left_wrist_alignment + right_wrist_alignment) / 2)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on elbow angle\n",
    "            # For bench press, \"down\" is when weights are near chest (elbow angle is small)\n",
    "            # \"up\" is when arms are extended (elbow angle is large)\n",
    "            if avg_elbow_angle > 160 and press_stage == \"down\":\n",
    "                press_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # If we were in \"up\" position and now angle is small, we're in \"down\" position\n",
    "            elif avg_elbow_angle < 90 and (press_stage == \"up\" or press_stage is None):\n",
    "                press_stage = \"down\"\n",
    "                # If we're coming from \"up\", count a rep\n",
    "                if press_stage == \"up\" or press_stage is None:\n",
    "                    rep_count += 1\n",
    "                    rep_depths.append(avg_elbow_angle)  # Store depth of press\n",
    "                    print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}\")\n",
    "                \n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_shoulder_stability = np.std(shoulder_width_values) * 100  # Convert to percentage variation\n",
    "    avg_wrist_alignment = np.mean(wrist_alignments)\n",
    "    avg_press_depth = np.mean(rep_depths) if rep_depths else 0\n",
    "    \n",
    "    # Check for elbow flare (elbows should be at ~45° angle to body)\n",
    "    elbow_symmetry = np.mean(np.abs(np.array(elbow_angles_left) - np.array(elbow_angles_right)))\n",
    "    \n",
    "    # Check for full extension at top of press\n",
    "    full_extension = np.max(elbow_angles_left) > 160 and np.max(elbow_angles_right) > 160\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"press_depth\": avg_press_depth,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"shoulder_stability\": 100 - avg_shoulder_stability,  # Higher is better\n",
    "            \"wrist_alignment\": 100 - avg_wrist_alignment,  # Higher is better\n",
    "            \"elbow_symmetry\": 100 - elbow_symmetry,  # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    if avg_press_depth > 70:  # Not going deep enough\n",
    "        feedback[\"feedback\"].append(\"You're not lowering the weights close enough to your chest. Try to achieve a deeper press for full muscle engagement.\")\n",
    "    \n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"You're not fully extending your arms at the top of the press. Straighten your arms more for full range of motion.\")\n",
    "    \n",
    "    if avg_shoulder_stability > 10:  # If shoulder position varies too much\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders more stable during the press. Avoid excessive movement or shrugging.\")\n",
    "    \n",
    "    if avg_wrist_alignment > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists straight and aligned with your forearms. Avoid bending your wrists backward.\")\n",
    "    \n",
    "    if elbow_symmetry > 20:\n",
    "        feedback[\"feedback\"].append(\"Your elbows are moving asymmetrically. Try to keep both arms moving together at the same pace and angle.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your bench press shows good depth, stable shoulders, proper wrist alignment, and symmetrical movement.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage\n",
    "result = analyze_bench_press(\"clips/BenchPress1.MOV\", \"clips/analyzed_bench_press1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Press depth (lower is better): {result['form_analysis']['press_depth']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist alignment: {result['form_analysis']['wrist_alignment']:.1f}%\")\n",
    "    print(f\"Elbow symmetry: {result['form_analysis']['elbow_symmetry']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947331.246154 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947331.368179 6322569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947331.380640 6322569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947331.395203 6322577 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 455\n",
      "Detected 33 landmarks\n",
      "Detected rowing with right arm\n",
      "Processing frame 100/455\n",
      "Processing frame 200/455\n",
      "Processing frame 300/455\n",
      "Processing frame 400/455\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Back angle (ideal ~45°): 9.9°\n",
      "Hip hinge (ideal ~170-175°): 68.2°\n",
      "Full arm extension: Yes\n",
      "Adequate pull: Yes\n",
      "Shoulder stability: 96.4%\n",
      "Wrist alignment: 73.0%\n",
      "Frames analyzed: 455\n",
      "\n",
      "Feedback:\n",
      "- Your back is too vertical. Bend forward more from the hips to engage your back muscles properly.\n",
      "- Improve your hip hinge. Bend at the hips rather than rounding your back.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_dumbbell_rows(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track row state\n",
    "    rep_count = 0\n",
    "    row_stage = None  # \"up\" (pulled up) or \"down\" (extended down)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles = []  # We'll focus primarily on one side for simplicity\n",
    "    back_angles = []   # Track back angle relative to vertical\n",
    "    hip_hinge_angles = [] # Track hip hinge\n",
    "    shoulder_heights = [] # Track if shoulders stay level\n",
    "    wrist_positions = []  # Track if wrist stays straight during pull\n",
    "    rep_heights = []      # To track how high the elbow is pulled\n",
    "    \n",
    "    # Side detection - we'll determine which side the person is rowing with\n",
    "    row_side = None       # \"left\" or \"right\"\n",
    "    side_confidence = 0\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for row analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            \n",
    "            # Calculate spine midpoints for back angle\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Detect which side is rowing (first few frames)\n",
    "            if good_frames <= 10 and row_side is None:\n",
    "                # Compare elbow heights (y is inverted in image coordinates)\n",
    "                left_elbow_height = left_elbow[1]\n",
    "                right_elbow_height = right_elbow[1]\n",
    "                \n",
    "                # Lower y-value means higher position in image\n",
    "                if left_elbow_height < right_elbow_height:\n",
    "                    side_confidence += 1  # Left arm is higher\n",
    "                else:\n",
    "                    side_confidence -= 1  # Right arm is higher\n",
    "                \n",
    "                # After 10 frames, determine the side\n",
    "                if good_frames == 10:\n",
    "                    row_side = \"left\" if side_confidence > 0 else \"right\"\n",
    "                    print(f\"Detected rowing with {row_side} arm\")\n",
    "            \n",
    "            # Choose which side to analyze based on detection\n",
    "            if row_side == \"left\" or row_side is None:\n",
    "                # Analyze left side\n",
    "                active_shoulder = left_shoulder\n",
    "                active_elbow = left_elbow\n",
    "                active_wrist = left_wrist\n",
    "                active_hip = left_hip\n",
    "                display_prefix = \"L\"\n",
    "            else:\n",
    "                # Analyze right side\n",
    "                active_shoulder = right_shoulder\n",
    "                active_elbow = right_elbow\n",
    "                active_wrist = right_wrist\n",
    "                active_hip = right_hip\n",
    "                display_prefix = \"R\"\n",
    "            \n",
    "            # Get elbow angle (shoulder-elbow-wrist)\n",
    "            elbow_angle = calculate_angle(active_shoulder, active_elbow, active_wrist)\n",
    "            elbow_angles.append(elbow_angle)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            # Convert to angle from vertical (90° would be perfectly upright)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Calculate hip hinge (knee-hip-shoulder angle)\n",
    "            # For left side\n",
    "            left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            # For right side\n",
    "            right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            # Use the side we're analyzing\n",
    "            hip_angle = left_hip_angle if row_side == \"left\" else right_hip_angle\n",
    "            hip_hinge_angles.append(hip_angle)\n",
    "            \n",
    "            # Track shoulder level (should stay parallel to ground during rows)\n",
    "            shoulder_height_diff = abs(left_shoulder[1] - right_shoulder[1])\n",
    "            shoulder_heights.append(shoulder_height_diff)\n",
    "            \n",
    "            # Track wrist position relative to elbow (should stay in line)\n",
    "            # For simplicity, we'll use the elbow angle as a proxy for wrist alignment\n",
    "            wrist_positions.append(elbow_angle)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            active_elbow_px = normalized_to_pixel_coordinates(active_elbow[0], active_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {elbow_angle:.1f}°\",\n",
    "                        (active_elbow_px[0] - 50, active_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine row stage based on elbow angle\n",
    "            # For rows, \"down\" is when arm is extended down/forward\n",
    "            # \"up\" is when elbow is pulled back/up\n",
    "            \n",
    "            # Row is \"up\" when elbow angle is small (arm bent in pulling position)\n",
    "            if elbow_angle < 90 and row_stage == \"down\":\n",
    "                row_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                rep_heights.append(active_elbow[1])  # Track height of the pull (y-coordinate)\n",
    "            \n",
    "            # Row is \"down\" when elbow angle is large (arm extended)\n",
    "            elif elbow_angle > 150 and (row_stage == \"up\" or row_stage is None):\n",
    "                row_stage = \"down\"\n",
    "                # If coming from \"up\", count a rep\n",
    "                if row_stage == \"up\":\n",
    "                    rep_count += 1\n",
    "                    print(f\"Rep #{rep_count} detected at frame with elbow angle {elbow_angle:.1f}\")\n",
    "                \n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 0\n",
    "    avg_hip_hinge = np.mean(hip_hinge_angles) if hip_hinge_angles else 0\n",
    "    shoulder_stability = np.std(shoulder_heights) * 100 if shoulder_heights else 0\n",
    "    wrist_alignment = np.mean(abs(np.array(wrist_positions) - 180)) if wrist_positions else 0\n",
    "    \n",
    "    # Check for full extension at bottom of row\n",
    "    full_extension = np.max(elbow_angles) > 150 if elbow_angles else False\n",
    "    \n",
    "    # Check for adequate pull (elbow should be pulled back enough)\n",
    "    adequate_pull = np.min(elbow_angles) < 80 if elbow_angles else False\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"back_angle\": avg_back_angle,  # Closer to 45° is ideal for rows\n",
    "            \"hip_hinge\": avg_hip_hinge,    # Should be around 170-175° for proper hip hinge\n",
    "            \"full_extension\": full_extension,\n",
    "            \"adequate_pull\": adequate_pull,\n",
    "            \"shoulder_stability\": 100 - shoulder_stability,  # Higher is better\n",
    "            \"wrist_alignment\": 100 - wrist_alignment,        # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check back angle - should be around 45° (bent forward but not too much)\n",
    "    if avg_back_angle < 30:\n",
    "        feedback[\"feedback\"].append(\"Your back is too vertical. Bend forward more from the hips to engage your back muscles properly.\")\n",
    "    elif avg_back_angle > 60:\n",
    "        feedback[\"feedback\"].append(\"You're bending too far forward. Maintain a back angle around 45° to protect your lower back.\")\n",
    "    \n",
    "    # Check hip hinge - should show proper hinging\n",
    "    if avg_hip_hinge < 160:\n",
    "        feedback[\"feedback\"].append(\"Improve your hip hinge. Bend at the hips rather than rounding your back.\")\n",
    "    \n",
    "    # Check pull height/quality\n",
    "    if not adequate_pull:\n",
    "        feedback[\"feedback\"].append(\"Pull the dumbbell higher by bringing your elbow further back to fully engage your back muscles.\")\n",
    "    \n",
    "    # Check extension\n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"Fully extend your arm at the bottom of the row for complete range of motion.\")\n",
    "    \n",
    "    # Check shoulder stability\n",
    "    if shoulder_stability > 10:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders level throughout the movement. Avoid twisting or rotating your torso.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if wrist_alignment > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrist straight and aligned with your forearm throughout the row.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your dumbbell rows show good back angle, proper hip hinge, full range of motion, and good control.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/DumbbellRow2.MOV\"  # Update this to the correct path\n",
    "result = analyze_dumbbell_rows(video_file, \"clips/analyzed_row2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Back angle (ideal ~45°): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Hip hinge (ideal ~170-175°): {result['form_analysis']['hip_hinge']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Adequate pull: {'Yes' if result['form_analysis']['adequate_pull'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist alignment: {result['form_analysis']['wrist_alignment']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947431.435876 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947431.544536 6326472 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947431.560739 6326479 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 331\n",
      "Detected 33 landmarks\n",
      "Detected rowing with left arm\n",
      "Processing frame 100/331\n",
      "Processing frame 200/331\n",
      "Processing frame 300/331\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Back angle (ideal ~45°): 15.4°\n",
      "Hip hinge (ideal ~170-175°): 88.4°\n",
      "Full arm extension: Yes\n",
      "Adequate pull: Yes\n",
      "Shoulder stability: 99.1%\n",
      "Wrist alignment: 40.3%\n",
      "Frames analyzed: 329\n",
      "\n",
      "Feedback:\n",
      "- Your back is too vertical. Bend forward more from the hips to engage your back muscles properly.\n",
      "- Improve your hip hinge. Bend at the hips rather than rounding your back.\n",
      "- Keep your wrist straight and aligned with your forearm throughout the row.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_dumbbell_rows(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track row state\n",
    "    rep_count = 0\n",
    "    row_stage = None  # \"up\" (pulled up) or \"down\" (extended down)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles = []  # We'll focus primarily on one side for simplicity\n",
    "    back_angles = []   # Track back angle relative to vertical\n",
    "    hip_hinge_angles = [] # Track hip hinge\n",
    "    shoulder_heights = [] # Track if shoulders stay level\n",
    "    wrist_positions = []  # Track if wrist stays straight during pull\n",
    "    rep_heights = []      # To track how high the elbow is pulled\n",
    "    \n",
    "    # Side detection - we'll determine which side the person is rowing with\n",
    "    row_side = None       # \"left\" or \"right\"\n",
    "    side_confidence = 0\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for row analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            \n",
    "            # Calculate spine midpoints for back angle\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Detect which side is rowing (first few frames)\n",
    "            if good_frames <= 10 and row_side is None:\n",
    "                # Compare elbow heights (y is inverted in image coordinates)\n",
    "                left_elbow_height = left_elbow[1]\n",
    "                right_elbow_height = right_elbow[1]\n",
    "                \n",
    "                # Lower y-value means higher position in image\n",
    "                if left_elbow_height < right_elbow_height:\n",
    "                    side_confidence += 1  # Left arm is higher\n",
    "                else:\n",
    "                    side_confidence -= 1  # Right arm is higher\n",
    "                \n",
    "                # After 10 frames, determine the side\n",
    "                if good_frames == 10:\n",
    "                    row_side = \"left\" if side_confidence > 0 else \"right\"\n",
    "                    print(f\"Detected rowing with {row_side} arm\")\n",
    "            \n",
    "            # Choose which side to analyze based on detection\n",
    "            if row_side == \"left\" or row_side is None:\n",
    "                # Analyze left side\n",
    "                active_shoulder = left_shoulder\n",
    "                active_elbow = left_elbow\n",
    "                active_wrist = left_wrist\n",
    "                active_hip = left_hip\n",
    "                display_prefix = \"L\"\n",
    "            else:\n",
    "                # Analyze right side\n",
    "                active_shoulder = right_shoulder\n",
    "                active_elbow = right_elbow\n",
    "                active_wrist = right_wrist\n",
    "                active_hip = right_hip\n",
    "                display_prefix = \"R\"\n",
    "            \n",
    "            # Get elbow angle (shoulder-elbow-wrist)\n",
    "            elbow_angle = calculate_angle(active_shoulder, active_elbow, active_wrist)\n",
    "            elbow_angles.append(elbow_angle)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            # Convert to angle from vertical (90° would be perfectly upright)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Calculate hip hinge (knee-hip-shoulder angle)\n",
    "            # For left side\n",
    "            left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            # For right side\n",
    "            right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            # Use the side we're analyzing\n",
    "            hip_angle = left_hip_angle if row_side == \"left\" else right_hip_angle\n",
    "            hip_hinge_angles.append(hip_angle)\n",
    "            \n",
    "            # Track shoulder level (should stay parallel to ground during rows)\n",
    "            shoulder_height_diff = abs(left_shoulder[1] - right_shoulder[1])\n",
    "            shoulder_heights.append(shoulder_height_diff)\n",
    "            \n",
    "            # Track wrist position relative to elbow (should stay in line)\n",
    "            # For simplicity, we'll use the elbow angle as a proxy for wrist alignment\n",
    "            wrist_positions.append(elbow_angle)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            active_elbow_px = normalized_to_pixel_coordinates(active_elbow[0], active_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Elbow: {elbow_angle:.1f}°\",\n",
    "                        (active_elbow_px[0] - 50, active_elbow_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine row stage based on elbow angle\n",
    "            # For rows, \"down\" is when arm is extended down/forward\n",
    "            # \"up\" is when elbow is pulled back/up\n",
    "            \n",
    "            # Row is \"up\" when elbow angle is small (arm bent in pulling position)\n",
    "            if elbow_angle < 90 and row_stage == \"down\":\n",
    "                row_stage = \"up\"\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                rep_heights.append(active_elbow[1])  # Track height of the pull (y-coordinate)\n",
    "            \n",
    "            # Row is \"down\" when elbow angle is large (arm extended)\n",
    "            elif elbow_angle > 150 and (row_stage == \"up\" or row_stage is None):\n",
    "                row_stage = \"down\"\n",
    "                # If coming from \"up\", count a rep\n",
    "                if row_stage == \"up\":\n",
    "                    rep_count += 1\n",
    "                    print(f\"Rep #{rep_count} detected at frame with elbow angle {elbow_angle:.1f}\")\n",
    "                \n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 0\n",
    "    avg_hip_hinge = np.mean(hip_hinge_angles) if hip_hinge_angles else 0\n",
    "    shoulder_stability = np.std(shoulder_heights) * 100 if shoulder_heights else 0\n",
    "    wrist_alignment = np.mean(abs(np.array(wrist_positions) - 180)) if wrist_positions else 0\n",
    "    \n",
    "    # Check for full extension at bottom of row\n",
    "    full_extension = np.max(elbow_angles) > 150 if elbow_angles else False\n",
    "    \n",
    "    # Check for adequate pull (elbow should be pulled back enough)\n",
    "    adequate_pull = np.min(elbow_angles) < 80 if elbow_angles else False\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"back_angle\": avg_back_angle,  # Closer to 45° is ideal for rows\n",
    "            \"hip_hinge\": avg_hip_hinge,    # Should be around 170-175° for proper hip hinge\n",
    "            \"full_extension\": full_extension,\n",
    "            \"adequate_pull\": adequate_pull,\n",
    "            \"shoulder_stability\": 100 - shoulder_stability,  # Higher is better\n",
    "            \"wrist_alignment\": 100 - wrist_alignment,        # Higher is better\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check back angle - should be around 45° (bent forward but not too much)\n",
    "    if avg_back_angle < 30:\n",
    "        feedback[\"feedback\"].append(\"Your back is too vertical. Bend forward more from the hips to engage your back muscles properly.\")\n",
    "    elif avg_back_angle > 60:\n",
    "        feedback[\"feedback\"].append(\"You're bending too far forward. Maintain a back angle around 45° to protect your lower back.\")\n",
    "    \n",
    "    # Check hip hinge - should show proper hinging\n",
    "    if avg_hip_hinge < 160:\n",
    "        feedback[\"feedback\"].append(\"Improve your hip hinge. Bend at the hips rather than rounding your back.\")\n",
    "    \n",
    "    # Check pull height/quality\n",
    "    if not adequate_pull:\n",
    "        feedback[\"feedback\"].append(\"Pull the dumbbell higher by bringing your elbow further back to fully engage your back muscles.\")\n",
    "    \n",
    "    # Check extension\n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"Fully extend your arm at the bottom of the row for complete range of motion.\")\n",
    "    \n",
    "    # Check shoulder stability\n",
    "    if shoulder_stability > 10:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders level throughout the movement. Avoid twisting or rotating your torso.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if wrist_alignment > 30:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrist straight and aligned with your forearm throughout the row.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your dumbbell rows show good back angle, proper hip hinge, full range of motion, and good control.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/DumbbellRow1.MOV\"  # Update this to the correct path\n",
    "result = analyze_dumbbell_rows(video_file, \"clips/analyzed_row1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Back angle (ideal ~45°): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Hip hinge (ideal ~170-175°): {result['form_analysis']['hip_hinge']:.1f}°\")\n",
    "    print(f\"Full arm extension: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Adequate pull: {'Yes' if result['form_analysis']['adequate_pull'] else 'No'}\")\n",
    "    print(f\"Shoulder stability: {result['form_analysis']['shoulder_stability']:.1f}%\")\n",
    "    print(f\"Wrist alignment: {result['form_analysis']['wrist_alignment']:.1f}%\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947599.568750 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947599.675835 6331069 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947599.691168 6331068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 549\n",
      "Detected 33 landmarks\n",
      "Rep #1 detected at frame with average knee angle 165.7\n",
      "Processing frame 100/549\n",
      "Processing frame 200/549\n",
      "Rep #2 detected at frame with average knee angle 161.7\n",
      "Processing frame 300/549\n",
      "Rep #3 detected at frame with average knee angle 162.1\n",
      "Rep #4 detected at frame with average knee angle 161.3\n",
      "Processing frame 400/549\n",
      "Rep #5 detected at frame with average knee angle 163.1\n",
      "Processing frame 500/549\n",
      "Rep #6 detected at frame with average knee angle 163.1\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 6 reps\n",
      "Squat depth (knee angle, lower is deeper): 79.0°\n",
      "Hip mobility (hip angle, lower is better): 85.7°\n",
      "Ankle mobility: 159.9°\n",
      "Back angle (90° is upright): 87.8°\n",
      "Knee alignment score: 90.4%\n",
      "Achieved full depth: Yes\n",
      "Knees past toes: Yes\n",
      "Frames analyzed: 549\n",
      "\n",
      "Feedback:\n",
      "- Your knees are moving too far forward past your toes. Try to push your hips back more as you descend.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_goblet_squat(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track squat state\n",
    "    rep_count = 0\n",
    "    squat_stage = None  # \"up\" (standing) or \"down\" (squatting)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    knee_angles_left = []\n",
    "    knee_angles_right = []\n",
    "    hip_angles_left = []\n",
    "    hip_angles_right = []\n",
    "    ankle_angles_left = []\n",
    "    ankle_angles_right = []\n",
    "    back_angles = []\n",
    "    hip_depths = []\n",
    "    knee_alignments = []  # Track knee alignment with ankles and hips\n",
    "    torso_heights = []    # Track torso height for squat depth\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for squat analysis\n",
    "            # Foot points\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Leg points\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Upper body points\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Calculate spine midpoints for back angle\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            \n",
    "            knee_angles_left.append(left_knee_angle)\n",
    "            knee_angles_right.append(right_knee_angle)\n",
    "            \n",
    "            # Calculate hip angles (knee-hip-shoulder)\n",
    "            left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            \n",
    "            hip_angles_left.append(left_hip_angle)\n",
    "            hip_angles_right.append(right_hip_angle)\n",
    "            \n",
    "            # Calculate ankle angles (knee-ankle-foot_index) - measures dorsiflexion\n",
    "            left_ankle_angle = calculate_angle(left_knee, left_ankle, left_foot_index)\n",
    "            right_ankle_angle = calculate_angle(right_knee, right_ankle, right_foot_index)\n",
    "            \n",
    "            ankle_angles_left.append(left_ankle_angle)\n",
    "            ankle_angles_right.append(right_ankle_angle)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Track hip depth (y-position of hip relative to knee)\n",
    "            # In a proper squat, hips should drop to at least knee level or slightly below\n",
    "            left_hip_depth = left_hip[1] - left_knee[1]  # Negative values mean hip is above knee\n",
    "            right_hip_depth = right_hip[1] - right_knee[1]\n",
    "            avg_hip_depth = (left_hip_depth + right_hip_depth) / 2\n",
    "            hip_depths.append(avg_hip_depth)\n",
    "            \n",
    "            # Calculate knee alignment\n",
    "            # Measure horizontal distance from knee to ankle to track knee position\n",
    "            # Knees should track over toes, not cave in or out\n",
    "            left_knee_to_ankle_x = left_knee[0] - left_ankle[0]\n",
    "            right_knee_to_ankle_x = right_knee[0] - right_ankle[0]\n",
    "            knee_alignments.append((left_knee_to_ankle_x, right_knee_to_ankle_x))\n",
    "            \n",
    "            # Track torso height for squat depth\n",
    "            torso_height = mid_shoulder[1]  # y-coordinate of mid-shoulder\n",
    "            torso_heights.append(torso_height)\n",
    "            \n",
    "            # Average knee angle for determining squat stage\n",
    "            avg_knee_angle = (left_knee_angle + right_knee_angle) / 2\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_knee_px = normalized_to_pixel_coordinates(left_knee[0], left_knee[1], frame_width, frame_height)\n",
    "            right_knee_px = normalized_to_pixel_coordinates(right_knee[0], right_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L Knee: {left_knee_angle:.1f}°\",\n",
    "                        (left_knee_px[0] - 70, left_knee_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R Knee: {right_knee_angle:.1f}°\",\n",
    "                        (right_knee_px[0] - 70, right_knee_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine squat stage based on knee angle\n",
    "            # For squats, \"down\" is when knees are deeply bent (angle is small)\n",
    "            # \"up\" is when standing (angle is large close to 180)\n",
    "            \n",
    "            # Squat is \"down\" when knee angle is small (deep squat position)\n",
    "            if avg_knee_angle < 110 and (squat_stage == \"up\" or squat_stage is None):\n",
    "                squat_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Squat is \"up\" when knee angle is large (standing position)\n",
    "            elif avg_knee_angle > 160 and squat_stage == \"down\":\n",
    "                squat_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average knee angle {avg_knee_angle:.1f}\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_knee_angle_min = np.min([np.min(knee_angles_left), np.min(knee_angles_right)]) if knee_angles_left and knee_angles_right else 180\n",
    "    avg_hip_angle_min = np.min([np.min(hip_angles_left), np.min(hip_angles_right)]) if hip_angles_left and hip_angles_right else 180\n",
    "    avg_ankle_angle = np.mean([np.mean(ankle_angles_left), np.mean(ankle_angles_right)]) if ankle_angles_left and ankle_angles_right else 0\n",
    "    \n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 90\n",
    "    max_hip_depth = np.max(hip_depths) if hip_depths else 0\n",
    "    \n",
    "    # Calculate knee alignment score\n",
    "    # Ideal is when knees track over ankles\n",
    "    knee_alignment_scores = []\n",
    "    for left_align, right_align in knee_alignments:\n",
    "        # Calculate a score where 0 is perfect alignment\n",
    "        # Higher values mean knees are tracking too far in or out\n",
    "        left_score = abs(left_align)\n",
    "        right_score = abs(right_align)\n",
    "        knee_alignment_scores.append((left_score + right_score) / 2)\n",
    "    \n",
    "    avg_knee_alignment = np.mean(knee_alignment_scores) if knee_alignment_scores else 0\n",
    "    \n",
    "    # Full squat check - did they go deep enough?\n",
    "    deep_squat = avg_knee_angle_min < 100  # Proper depth typically has knee angle < 100°\n",
    "    \n",
    "    # Check for knees passing toes\n",
    "    # This is a simplified check - in reality, the judgment depends on ankle mobility\n",
    "    knees_past_toes = False\n",
    "    if knee_alignments:\n",
    "        # Check if there are many frames where knees are significantly ahead of ankles\n",
    "        forward_knee_count = sum(1 for l, r in knee_alignments if abs(l) > 0.1 or abs(r) > 0.1)\n",
    "        knees_past_toes = forward_knee_count > len(knee_alignments) * 0.5\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"squat_depth\": avg_knee_angle_min,           # Lower is deeper\n",
    "            \"hip_mobility\": avg_hip_angle_min,           # Lower shows better hip mobility\n",
    "            \"ankle_mobility\": avg_ankle_angle,           # Higher angle indicates better dorsiflexion\n",
    "            \"back_angle\": avg_back_angle,                # Should stay upright (close to 90°)\n",
    "            \"knee_alignment\": 100 - avg_knee_alignment*100,  # Higher is better (knees tracking over toes)\n",
    "            \"deep_squat\": deep_squat,\n",
    "            \"knees_past_toes\": knees_past_toes,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check squat depth\n",
    "    if not deep_squat:\n",
    "        feedback[\"feedback\"].append(\"Try to squat deeper. Aim to get your thighs at least parallel to the ground for full muscle engagement.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if avg_back_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your back more upright. Your torso is leaning too far forward during the squat.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if avg_knee_alignment > 0.1:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your knees aligned with your toes. Your knees are tracking too far inward or outward.\")\n",
    "    \n",
    "    # Check for knees past toes\n",
    "    if knees_past_toes:\n",
    "        feedback[\"feedback\"].append(\"Your knees are moving too far forward past your toes. Try to push your hips back more as you descend.\")\n",
    "    \n",
    "    # Check ankle mobility\n",
    "    if avg_ankle_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Work on ankle mobility. Limited ankle dorsiflexion is affecting your squat depth and form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your goblet squat shows good depth, proper back position, and good knee alignment.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/GobletSquat1.MOV\"  # Update this to the correct path\n",
    "result = analyze_goblet_squat(video_file, \"clips/analyzed_squat1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Squat depth (knee angle, lower is deeper): {result['form_analysis']['squat_depth']:.1f}°\")\n",
    "    print(f\"Hip mobility (hip angle, lower is better): {result['form_analysis']['hip_mobility']:.1f}°\")\n",
    "    print(f\"Ankle mobility: {result['form_analysis']['ankle_mobility']:.1f}°\")\n",
    "    print(f\"Back angle (90° is upright): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}%\")\n",
    "    print(f\"Achieved full depth: {'Yes' if result['form_analysis']['deep_squat'] else 'No'}\")\n",
    "    print(f\"Knees past toes: {'Yes' if result['form_analysis']['knees_past_toes'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947640.092082 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947640.213394 6332333 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947640.228408 6332341 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 30, Total frames: 114\n",
      "Detected 33 landmarks\n",
      "Processing frame 100/114\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Squat depth (knee angle, lower is deeper): 135.3°\n",
      "Hip mobility (hip angle, lower is better): 126.4°\n",
      "Ankle mobility: 163.1°\n",
      "Back angle (90° is upright): 88.0°\n",
      "Knee alignment score: 88.4%\n",
      "Achieved full depth: No\n",
      "Knees past toes: Yes\n",
      "Frames analyzed: 114\n",
      "\n",
      "Feedback:\n",
      "- Try to squat deeper. Aim to get your thighs at least parallel to the ground for full muscle engagement.\n",
      "- Focus on keeping your knees aligned with your toes. Your knees are tracking too far inward or outward.\n",
      "- Your knees are moving too far forward past your toes. Try to push your hips back more as you descend.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_goblet_squat(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track squat state\n",
    "    rep_count = 0\n",
    "    squat_stage = None  # \"up\" (standing) or \"down\" (squatting)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    knee_angles_left = []\n",
    "    knee_angles_right = []\n",
    "    hip_angles_left = []\n",
    "    hip_angles_right = []\n",
    "    ankle_angles_left = []\n",
    "    ankle_angles_right = []\n",
    "    back_angles = []\n",
    "    hip_depths = []\n",
    "    knee_alignments = []  # Track knee alignment with ankles and hips\n",
    "    torso_heights = []    # Track torso height for squat depth\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for squat analysis\n",
    "            # Foot points\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Leg points\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Upper body points\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Calculate spine midpoints for back angle\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            \n",
    "            knee_angles_left.append(left_knee_angle)\n",
    "            knee_angles_right.append(right_knee_angle)\n",
    "            \n",
    "            # Calculate hip angles (knee-hip-shoulder)\n",
    "            left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            \n",
    "            hip_angles_left.append(left_hip_angle)\n",
    "            hip_angles_right.append(right_hip_angle)\n",
    "            \n",
    "            # Calculate ankle angles (knee-ankle-foot_index) - measures dorsiflexion\n",
    "            left_ankle_angle = calculate_angle(left_knee, left_ankle, left_foot_index)\n",
    "            right_ankle_angle = calculate_angle(right_knee, right_ankle, right_foot_index)\n",
    "            \n",
    "            ankle_angles_left.append(left_ankle_angle)\n",
    "            ankle_angles_right.append(right_ankle_angle)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Track hip depth (y-position of hip relative to knee)\n",
    "            # In a proper squat, hips should drop to at least knee level or slightly below\n",
    "            left_hip_depth = left_hip[1] - left_knee[1]  # Negative values mean hip is above knee\n",
    "            right_hip_depth = right_hip[1] - right_knee[1]\n",
    "            avg_hip_depth = (left_hip_depth + right_hip_depth) / 2\n",
    "            hip_depths.append(avg_hip_depth)\n",
    "            \n",
    "            # Calculate knee alignment\n",
    "            # Measure horizontal distance from knee to ankle to track knee position\n",
    "            # Knees should track over toes, not cave in or out\n",
    "            left_knee_to_ankle_x = left_knee[0] - left_ankle[0]\n",
    "            right_knee_to_ankle_x = right_knee[0] - right_ankle[0]\n",
    "            knee_alignments.append((left_knee_to_ankle_x, right_knee_to_ankle_x))\n",
    "            \n",
    "            # Track torso height for squat depth\n",
    "            torso_height = mid_shoulder[1]  # y-coordinate of mid-shoulder\n",
    "            torso_heights.append(torso_height)\n",
    "            \n",
    "            # Average knee angle for determining squat stage\n",
    "            avg_knee_angle = (left_knee_angle + right_knee_angle) / 2\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_knee_px = normalized_to_pixel_coordinates(left_knee[0], left_knee[1], frame_width, frame_height)\n",
    "            right_knee_px = normalized_to_pixel_coordinates(right_knee[0], right_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L Knee: {left_knee_angle:.1f}°\",\n",
    "                        (left_knee_px[0] - 70, left_knee_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R Knee: {right_knee_angle:.1f}°\",\n",
    "                        (right_knee_px[0] - 70, right_knee_px[1] + 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine squat stage based on knee angle\n",
    "            # For squats, \"down\" is when knees are deeply bent (angle is small)\n",
    "            # \"up\" is when standing (angle is large close to 180)\n",
    "            \n",
    "            # Squat is \"down\" when knee angle is small (deep squat position)\n",
    "            if avg_knee_angle < 110 and (squat_stage == \"up\" or squat_stage is None):\n",
    "                squat_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Squat is \"up\" when knee angle is large (standing position)\n",
    "            elif avg_knee_angle > 160 and squat_stage == \"down\":\n",
    "                squat_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average knee angle {avg_knee_angle:.1f}\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_knee_angle_min = np.min([np.min(knee_angles_left), np.min(knee_angles_right)]) if knee_angles_left and knee_angles_right else 180\n",
    "    avg_hip_angle_min = np.min([np.min(hip_angles_left), np.min(hip_angles_right)]) if hip_angles_left and hip_angles_right else 180\n",
    "    avg_ankle_angle = np.mean([np.mean(ankle_angles_left), np.mean(ankle_angles_right)]) if ankle_angles_left and ankle_angles_right else 0\n",
    "    \n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 90\n",
    "    max_hip_depth = np.max(hip_depths) if hip_depths else 0\n",
    "    \n",
    "    # Calculate knee alignment score\n",
    "    # Ideal is when knees track over ankles\n",
    "    knee_alignment_scores = []\n",
    "    for left_align, right_align in knee_alignments:\n",
    "        # Calculate a score where 0 is perfect alignment\n",
    "        # Higher values mean knees are tracking too far in or out\n",
    "        left_score = abs(left_align)\n",
    "        right_score = abs(right_align)\n",
    "        knee_alignment_scores.append((left_score + right_score) / 2)\n",
    "    \n",
    "    avg_knee_alignment = np.mean(knee_alignment_scores) if knee_alignment_scores else 0\n",
    "    \n",
    "    # Full squat check - did they go deep enough?\n",
    "    deep_squat = avg_knee_angle_min < 100  # Proper depth typically has knee angle < 100°\n",
    "    \n",
    "    # Check for knees passing toes\n",
    "    # This is a simplified check - in reality, the judgment depends on ankle mobility\n",
    "    knees_past_toes = False\n",
    "    if knee_alignments:\n",
    "        # Check if there are many frames where knees are significantly ahead of ankles\n",
    "        forward_knee_count = sum(1 for l, r in knee_alignments if abs(l) > 0.1 or abs(r) > 0.1)\n",
    "        knees_past_toes = forward_knee_count > len(knee_alignments) * 0.5\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"squat_depth\": avg_knee_angle_min,           # Lower is deeper\n",
    "            \"hip_mobility\": avg_hip_angle_min,           # Lower shows better hip mobility\n",
    "            \"ankle_mobility\": avg_ankle_angle,           # Higher angle indicates better dorsiflexion\n",
    "            \"back_angle\": avg_back_angle,                # Should stay upright (close to 90°)\n",
    "            \"knee_alignment\": 100 - avg_knee_alignment*100,  # Higher is better (knees tracking over toes)\n",
    "            \"deep_squat\": deep_squat,\n",
    "            \"knees_past_toes\": knees_past_toes,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check squat depth\n",
    "    if not deep_squat:\n",
    "        feedback[\"feedback\"].append(\"Try to squat deeper. Aim to get your thighs at least parallel to the ground for full muscle engagement.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if avg_back_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your back more upright. Your torso is leaning too far forward during the squat.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if avg_knee_alignment > 0.1:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your knees aligned with your toes. Your knees are tracking too far inward or outward.\")\n",
    "    \n",
    "    # Check for knees past toes\n",
    "    if knees_past_toes:\n",
    "        feedback[\"feedback\"].append(\"Your knees are moving too far forward past your toes. Try to push your hips back more as you descend.\")\n",
    "    \n",
    "    # Check ankle mobility\n",
    "    if avg_ankle_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Work on ankle mobility. Limited ankle dorsiflexion is affecting your squat depth and form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your goblet squat shows good depth, proper back position, and good knee alignment.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/GobletSquat3.MOV\"  # Update this to the correct path\n",
    "result = analyze_goblet_squat(video_file, \"clips/analyzed_squat3.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Squat depth (knee angle, lower is deeper): {result['form_analysis']['squat_depth']:.1f}°\")\n",
    "    print(f\"Hip mobility (hip angle, lower is better): {result['form_analysis']['hip_mobility']:.1f}°\")\n",
    "    print(f\"Ankle mobility: {result['form_analysis']['ankle_mobility']:.1f}°\")\n",
    "    print(f\"Back angle (90° is upright): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}%\")\n",
    "    print(f\"Achieved full depth: {'Yes' if result['form_analysis']['deep_squat'] else 'No'}\")\n",
    "    print(f\"Knees past toes: {'Yes' if result['form_analysis']['knees_past_toes'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947839.971401 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947840.059931 6338055 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947840.071497 6338053 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 474\n",
      "Detected 33 landmarks\n",
      "Processing frame 100/474\n",
      "Processing frame 200/474\n",
      "Processing frame 300/474\n",
      "Processing frame 400/474\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Hip hinge (lower means deeper hinge): 56.8°\n",
      "Hip hinge quality score: 45.1/100\n",
      "Knee angle (should be 140-170°): 156.3°\n",
      "Back flatness score: 0.0/100\n",
      "Shin verticality score: 53.3/100\n",
      "Bar path consistency score: 77.7/100\n",
      "Maximum forward lean: 90.0°\n",
      "Hip hinge sufficient: Yes\n",
      "Knees properly bent: Yes\n",
      "Back remained flat: No\n",
      "Shins remained vertical: No\n",
      "Frames analyzed: 474\n",
      "\n",
      "Feedback:\n",
      "- Focus on maintaining a flat back throughout the movement. Your back is rounding, which can increase injury risk.\n",
      "- Try to keep your shins more vertical throughout the movement. Your shins are angling forward too much.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_rdl(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track RDL state\n",
    "    rep_count = 0\n",
    "    rdl_stage = None  # \"up\" (standing) or \"down\" (hips back, torso forward)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    hip_angles = []       # Hip hinge angle\n",
    "    knee_angles = []      # Knee angle (slight bend is good)\n",
    "    back_angles = []      # Back angle relative to horizontal (should remain flat)\n",
    "    torso_angles = []     # Torso angle relative to vertical\n",
    "    shins_vertical = []   # Track if shins remain vertical\n",
    "    bar_path = []         # Track bar path (approximated by wrist position)\n",
    "    hip_depths = []       # Track how far back the hips travel\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for RDL analysis\n",
    "            # We'll analyze both sides and average for better accuracy\n",
    "            \n",
    "            # Foot points\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Leg points\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Upper body points\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Wrist points to approximate bar position\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate mid points for better analysis\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            mid_knee = [(left_knee[0] + right_knee[0])/2, \n",
    "                       (left_knee[1] + right_knee[1])/2]\n",
    "            mid_ankle = [(left_ankle[0] + right_ankle[0])/2, \n",
    "                        (left_ankle[1] + right_ankle[1])/2]\n",
    "            mid_wrist = [(left_wrist[0] + right_wrist[0])/2, \n",
    "                        (left_wrist[1] + right_wrist[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            avg_knee_angle = (left_knee_angle + right_knee_angle) / 2\n",
    "            knee_angles.append(avg_knee_angle)\n",
    "            \n",
    "            # Calculate hip angle (shoulder-hip-knee) - this measures the hip hinge\n",
    "            left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "            avg_hip_angle = (left_hip_angle + right_hip_angle) / 2\n",
    "            hip_angles.append(avg_hip_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Calculate back angle relative to horizontal\n",
    "            # Create a point directly to the right of mid_hip to represent horizontal\n",
    "            horizontal_point = [mid_hip[0] + 0.2, mid_hip[1]]\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, horizontal_point)\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Check if shins remain vertical\n",
    "            # Calculate shin angle (knee-ankle-foot)\n",
    "            left_shin_angle = calculate_angle(left_knee, left_ankle, left_foot_index)\n",
    "            right_shin_angle = calculate_angle(right_knee, right_ankle, right_foot_index)\n",
    "            # Adjust angles to measure deviation from vertical (0° is vertical)\n",
    "            left_shin_vertical = abs(left_shin_angle - 90)\n",
    "            right_shin_vertical = abs(right_shin_angle - 90)\n",
    "            avg_shin_vertical = (left_shin_vertical + right_shin_vertical) / 2\n",
    "            shins_vertical.append(avg_shin_vertical)\n",
    "            \n",
    "            # Track bar path (using wrist position as proxy)\n",
    "            bar_path.append(mid_wrist)\n",
    "            \n",
    "            # Track hip depth (horizontal distance from hip to ankle)\n",
    "            hip_depth = abs(mid_hip[0] - mid_ankle[0])\n",
    "            hip_depths.append(hip_depth)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            knee_px = normalized_to_pixel_coordinates(mid_knee[0], mid_knee[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Hip angle: {avg_hip_angle:.1f}°\",\n",
    "                        (hip_px[0] - 70, hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Knee angle: {avg_knee_angle:.1f}°\",\n",
    "                        (knee_px[0] - 70, knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso angle: {torso_angle:.1f}°\",\n",
    "                        (hip_px[0] - 70, hip_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine RDL stage based on hip angle and torso angle\n",
    "            # For RDLs, \"down\" is when hips are pushed back and torso is forward\n",
    "            # \"up\" is when standing upright\n",
    "            \n",
    "            # RDL is \"down\" when hip angle is smaller and torso is more horizontal\n",
    "            if avg_hip_angle < 100 and torso_angle > 45 and (rdl_stage == \"up\" or rdl_stage is None):\n",
    "                rdl_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # RDL is \"up\" when hip angle is larger and torso is more vertical\n",
    "            elif avg_hip_angle > 160 and torso_angle < 20 and rdl_stage == \"down\":\n",
    "                rdl_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with hip angle {avg_hip_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_hip_angle = np.min(hip_angles) if hip_angles else 180\n",
    "    avg_knee_angle = np.mean(knee_angles) if knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    max_torso_angle = np.max(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate back flatness\n",
    "    # Check if back angle changes significantly during the movement\n",
    "    back_flatness = 100 - (np.std(back_angles) * 10) if back_angles else 0\n",
    "    back_flatness = max(0, min(100, back_flatness))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate shin verticality (lower is better)\n",
    "    shin_verticality = np.mean(shins_vertical) if shins_vertical else 45\n",
    "    shin_verticality_score = max(0, 100 - (shin_verticality * 2))  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate bar path consistency\n",
    "    # Measure horizontal deviation in bar path\n",
    "    if len(bar_path) > 1:\n",
    "        bar_x_positions = [pos[0] for pos in bar_path]\n",
    "        bar_path_consistency = 100 - (np.std(bar_x_positions) * 500)  # Convert to 0-100 score\n",
    "        bar_path_consistency = max(0, min(100, bar_path_consistency))  # Clamp between 0-100\n",
    "    else:\n",
    "        bar_path_consistency = 0\n",
    "    \n",
    "    # Calculate hip hinge quality\n",
    "    max_hip_depth = np.max(hip_depths) if hip_depths else 0\n",
    "    hip_hinge_quality = min(100, max_hip_depth * 200)  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key RDL form criteria\n",
    "    hip_hinge_sufficient = min_hip_angle < 110  # Did they hinge enough at the hips?\n",
    "    knees_slightly_bent = 140 < avg_knee_angle < 170  # Knees should be slightly bent\n",
    "    back_flat = back_flatness > 70  # Back stayed relatively flat\n",
    "    proper_shin_angle = shin_verticality_score > 70  # Shins stayed close to vertical\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"hip_hinge\": min_hip_angle,              # Lower value means greater hip hinge\n",
    "            \"hip_hinge_quality\": hip_hinge_quality,  # Higher is better (0-100)\n",
    "            \"knee_angle\": avg_knee_angle,            # Should be slightly bent (140-170°)\n",
    "            \"back_flatness\": back_flatness,          # Higher is better (0-100)\n",
    "            \"shin_verticality\": shin_verticality_score,  # Higher is better (0-100)\n",
    "            \"bar_path\": bar_path_consistency,        # Higher is better (0-100)\n",
    "            \"max_forward_lean\": max_torso_angle,     # Higher means more forward lean\n",
    "            \"hip_hinge_sufficient\": hip_hinge_sufficient,\n",
    "            \"knees_slightly_bent\": knees_slightly_bent,\n",
    "            \"back_flat\": back_flat,\n",
    "            \"proper_shin_angle\": proper_shin_angle,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check hip hinge\n",
    "    if not hip_hinge_sufficient:\n",
    "        feedback[\"feedback\"].append(\"Focus on pushing your hips further back. Your hip hinge isn't deep enough for proper hamstring engagement.\")\n",
    "    \n",
    "    # Check knee bend\n",
    "    if avg_knee_angle > 170:\n",
    "        feedback[\"feedback\"].append(\"Keep a slight bend in your knees throughout the movement. Your knees are too straight.\")\n",
    "    elif avg_knee_angle < 140:\n",
    "        feedback[\"feedback\"].append(\"Your knees are bending too much. For an RDL, keep only a slight bend in the knees and focus on hinging at the hips.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if not back_flat:\n",
    "        feedback[\"feedback\"].append(\"Focus on maintaining a flat back throughout the movement. Your back is rounding, which can increase injury risk.\")\n",
    "    \n",
    "    # Check shin angle\n",
    "    if not proper_shin_angle:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your shins more vertical throughout the movement. Your shins are angling forward too much.\")\n",
    "    \n",
    "    # Check bar path\n",
    "    if bar_path_consistency < 70:\n",
    "        feedback[\"feedback\"].append(\"Work on keeping the bar path more consistent. The bar should travel in a straight vertical line close to your legs.\")\n",
    "    \n",
    "    # Check forward lean\n",
    "    if max_torso_angle < 30:\n",
    "        feedback[\"feedback\"].append(\"You're not leaning forward enough. In a proper RDL, your torso should reach a more horizontal position.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your RDL shows good hip hinge, proper knee bend, flat back, and a consistent bar path.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/RDL1.MOV\"  # Update this to the correct path\n",
    "result = analyze_rdl(video_file, \"clips/analyzed_rdl1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Hip hinge (lower means deeper hinge): {result['form_analysis']['hip_hinge']:.1f}°\")\n",
    "    print(f\"Hip hinge quality score: {result['form_analysis']['hip_hinge_quality']:.1f}/100\")\n",
    "    print(f\"Knee angle (should be 140-170°): {result['form_analysis']['knee_angle']:.1f}°\")\n",
    "    print(f\"Back flatness score: {result['form_analysis']['back_flatness']:.1f}/100\")\n",
    "    print(f\"Shin verticality score: {result['form_analysis']['shin_verticality']:.1f}/100\")\n",
    "    print(f\"Bar path consistency score: {result['form_analysis']['bar_path']:.1f}/100\")\n",
    "    print(f\"Maximum forward lean: {result['form_analysis']['max_forward_lean']:.1f}°\")\n",
    "    print(f\"Hip hinge sufficient: {'Yes' if result['form_analysis']['hip_hinge_sufficient'] else 'No'}\")\n",
    "    print(f\"Knees properly bent: {'Yes' if result['form_analysis']['knees_slightly_bent'] else 'No'}\")\n",
    "    print(f\"Back remained flat: {'Yes' if result['form_analysis']['back_flat'] else 'No'}\")\n",
    "    print(f\"Shins remained vertical: {'Yes' if result['form_analysis']['proper_shin_angle'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745947914.124683 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745947914.242110 6340080 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745947914.256765 6340080 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 599\n",
      "Detected 33 landmarks\n",
      "Processing frame 100/599\n",
      "Processing frame 200/599\n",
      "Processing frame 300/599\n",
      "Processing frame 400/599\n",
      "Processing frame 500/599\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 0 reps\n",
      "Hip hinge (lower means deeper hinge): 38.5°\n",
      "Hip hinge quality score: 58.1/100\n",
      "Knee angle (should be 140-170°): 140.0°\n",
      "Back flatness score: 0.0/100\n",
      "Shin verticality score: 82.0/100\n",
      "Bar path consistency score: 63.3/100\n",
      "Maximum forward lean: 90.0°\n",
      "Hip hinge sufficient: Yes\n",
      "Knees properly bent: No\n",
      "Back remained flat: No\n",
      "Shins remained vertical: Yes\n",
      "Frames analyzed: 599\n",
      "\n",
      "Feedback:\n",
      "- Your knees are bending too much. For an RDL, keep only a slight bend in the knees and focus on hinging at the hips.\n",
      "- Focus on maintaining a flat back throughout the movement. Your back is rounding, which can increase injury risk.\n",
      "- Work on keeping the bar path more consistent. The bar should travel in a straight vertical line close to your legs.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_rdl(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track RDL state\n",
    "    rep_count = 0\n",
    "    rdl_stage = None  # \"up\" (standing) or \"down\" (hips back, torso forward)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    hip_angles = []       # Hip hinge angle\n",
    "    knee_angles = []      # Knee angle (slight bend is good)\n",
    "    back_angles = []      # Back angle relative to horizontal (should remain flat)\n",
    "    torso_angles = []     # Torso angle relative to vertical\n",
    "    shins_vertical = []   # Track if shins remain vertical\n",
    "    bar_path = []         # Track bar path (approximated by wrist position)\n",
    "    hip_depths = []       # Track how far back the hips travel\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get key points for RDL analysis\n",
    "            # We'll analyze both sides and average for better accuracy\n",
    "            \n",
    "            # Foot points\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Leg points\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Upper body points\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Wrist points to approximate bar position\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate mid points for better analysis\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            mid_knee = [(left_knee[0] + right_knee[0])/2, \n",
    "                       (left_knee[1] + right_knee[1])/2]\n",
    "            mid_ankle = [(left_ankle[0] + right_ankle[0])/2, \n",
    "                        (left_ankle[1] + right_ankle[1])/2]\n",
    "            mid_wrist = [(left_wrist[0] + right_wrist[0])/2, \n",
    "                        (left_wrist[1] + right_wrist[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            avg_knee_angle = (left_knee_angle + right_knee_angle) / 2\n",
    "            knee_angles.append(avg_knee_angle)\n",
    "            \n",
    "            # Calculate hip angle (shoulder-hip-knee) - this measures the hip hinge\n",
    "            left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "            avg_hip_angle = (left_hip_angle + right_hip_angle) / 2\n",
    "            hip_angles.append(avg_hip_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Calculate back angle relative to horizontal\n",
    "            # Create a point directly to the right of mid_hip to represent horizontal\n",
    "            horizontal_point = [mid_hip[0] + 0.2, mid_hip[1]]\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, horizontal_point)\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Check if shins remain vertical\n",
    "            # Calculate shin angle (knee-ankle-foot)\n",
    "            left_shin_angle = calculate_angle(left_knee, left_ankle, left_foot_index)\n",
    "            right_shin_angle = calculate_angle(right_knee, right_ankle, right_foot_index)\n",
    "            # Adjust angles to measure deviation from vertical (0° is vertical)\n",
    "            left_shin_vertical = abs(left_shin_angle - 90)\n",
    "            right_shin_vertical = abs(right_shin_angle - 90)\n",
    "            avg_shin_vertical = (left_shin_vertical + right_shin_vertical) / 2\n",
    "            shins_vertical.append(avg_shin_vertical)\n",
    "            \n",
    "            # Track bar path (using wrist position as proxy)\n",
    "            bar_path.append(mid_wrist)\n",
    "            \n",
    "            # Track hip depth (horizontal distance from hip to ankle)\n",
    "            hip_depth = abs(mid_hip[0] - mid_ankle[0])\n",
    "            hip_depths.append(hip_depth)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            knee_px = normalized_to_pixel_coordinates(mid_knee[0], mid_knee[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Hip angle: {avg_hip_angle:.1f}°\",\n",
    "                        (hip_px[0] - 70, hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Knee angle: {avg_knee_angle:.1f}°\",\n",
    "                        (knee_px[0] - 70, knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso angle: {torso_angle:.1f}°\",\n",
    "                        (hip_px[0] - 70, hip_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine RDL stage based on hip angle and torso angle\n",
    "            # For RDLs, \"down\" is when hips are pushed back and torso is forward\n",
    "            # \"up\" is when standing upright\n",
    "            \n",
    "            # RDL is \"down\" when hip angle is smaller and torso is more horizontal\n",
    "            if avg_hip_angle < 100 and torso_angle > 45 and (rdl_stage == \"up\" or rdl_stage is None):\n",
    "                rdl_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # RDL is \"up\" when hip angle is larger and torso is more vertical\n",
    "            elif avg_hip_angle > 160 and torso_angle < 20 and rdl_stage == \"down\":\n",
    "                rdl_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with hip angle {avg_hip_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_hip_angle = np.min(hip_angles) if hip_angles else 180\n",
    "    avg_knee_angle = np.mean(knee_angles) if knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    max_torso_angle = np.max(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate back flatness\n",
    "    # Check if back angle changes significantly during the movement\n",
    "    back_flatness = 100 - (np.std(back_angles) * 10) if back_angles else 0\n",
    "    back_flatness = max(0, min(100, back_flatness))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate shin verticality (lower is better)\n",
    "    shin_verticality = np.mean(shins_vertical) if shins_vertical else 45\n",
    "    shin_verticality_score = max(0, 100 - (shin_verticality * 2))  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate bar path consistency\n",
    "    # Measure horizontal deviation in bar path\n",
    "    if len(bar_path) > 1:\n",
    "        bar_x_positions = [pos[0] for pos in bar_path]\n",
    "        bar_path_consistency = 100 - (np.std(bar_x_positions) * 500)  # Convert to 0-100 score\n",
    "        bar_path_consistency = max(0, min(100, bar_path_consistency))  # Clamp between 0-100\n",
    "    else:\n",
    "        bar_path_consistency = 0\n",
    "    \n",
    "    # Calculate hip hinge quality\n",
    "    max_hip_depth = np.max(hip_depths) if hip_depths else 0\n",
    "    hip_hinge_quality = min(100, max_hip_depth * 200)  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key RDL form criteria\n",
    "    hip_hinge_sufficient = min_hip_angle < 110  # Did they hinge enough at the hips?\n",
    "    knees_slightly_bent = 140 < avg_knee_angle < 170  # Knees should be slightly bent\n",
    "    back_flat = back_flatness > 70  # Back stayed relatively flat\n",
    "    proper_shin_angle = shin_verticality_score > 70  # Shins stayed close to vertical\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"hip_hinge\": min_hip_angle,              # Lower value means greater hip hinge\n",
    "            \"hip_hinge_quality\": hip_hinge_quality,  # Higher is better (0-100)\n",
    "            \"knee_angle\": avg_knee_angle,            # Should be slightly bent (140-170°)\n",
    "            \"back_flatness\": back_flatness,          # Higher is better (0-100)\n",
    "            \"shin_verticality\": shin_verticality_score,  # Higher is better (0-100)\n",
    "            \"bar_path\": bar_path_consistency,        # Higher is better (0-100)\n",
    "            \"max_forward_lean\": max_torso_angle,     # Higher means more forward lean\n",
    "            \"hip_hinge_sufficient\": hip_hinge_sufficient,\n",
    "            \"knees_slightly_bent\": knees_slightly_bent,\n",
    "            \"back_flat\": back_flat,\n",
    "            \"proper_shin_angle\": proper_shin_angle,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check hip hinge\n",
    "    if not hip_hinge_sufficient:\n",
    "        feedback[\"feedback\"].append(\"Focus on pushing your hips further back. Your hip hinge isn't deep enough for proper hamstring engagement.\")\n",
    "    \n",
    "    # Check knee bend\n",
    "    if avg_knee_angle > 170:\n",
    "        feedback[\"feedback\"].append(\"Keep a slight bend in your knees throughout the movement. Your knees are too straight.\")\n",
    "    elif avg_knee_angle < 140:\n",
    "        feedback[\"feedback\"].append(\"Your knees are bending too much. For an RDL, keep only a slight bend in the knees and focus on hinging at the hips.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if not back_flat:\n",
    "        feedback[\"feedback\"].append(\"Focus on maintaining a flat back throughout the movement. Your back is rounding, which can increase injury risk.\")\n",
    "    \n",
    "    # Check shin angle\n",
    "    if not proper_shin_angle:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your shins more vertical throughout the movement. Your shins are angling forward too much.\")\n",
    "    \n",
    "    # Check bar path\n",
    "    if bar_path_consistency < 70:\n",
    "        feedback[\"feedback\"].append(\"Work on keeping the bar path more consistent. The bar should travel in a straight vertical line close to your legs.\")\n",
    "    \n",
    "    # Check forward lean\n",
    "    if max_torso_angle < 30:\n",
    "        feedback[\"feedback\"].append(\"You're not leaning forward enough. In a proper RDL, your torso should reach a more horizontal position.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your RDL shows good hip hinge, proper knee bend, flat back, and a consistent bar path.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/RDL2.MOV\"  # Update this to the correct path\n",
    "result = analyze_rdl(video_file, \"clips/analyzed_rdl2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Hip hinge (lower means deeper hinge): {result['form_analysis']['hip_hinge']:.1f}°\")\n",
    "    print(f\"Hip hinge quality score: {result['form_analysis']['hip_hinge_quality']:.1f}/100\")\n",
    "    print(f\"Knee angle (should be 140-170°): {result['form_analysis']['knee_angle']:.1f}°\")\n",
    "    print(f\"Back flatness score: {result['form_analysis']['back_flatness']:.1f}/100\")\n",
    "    print(f\"Shin verticality score: {result['form_analysis']['shin_verticality']:.1f}/100\")\n",
    "    print(f\"Bar path consistency score: {result['form_analysis']['bar_path']:.1f}/100\")\n",
    "    print(f\"Maximum forward lean: {result['form_analysis']['max_forward_lean']:.1f}°\")\n",
    "    print(f\"Hip hinge sufficient: {'Yes' if result['form_analysis']['hip_hinge_sufficient'] else 'No'}\")\n",
    "    print(f\"Knees properly bent: {'Yes' if result['form_analysis']['knees_slightly_bent'] else 'No'}\")\n",
    "    print(f\"Back remained flat: {'Yes' if result['form_analysis']['back_flat'] else 'No'}\")\n",
    "    print(f\"Shins remained vertical: {'Yes' if result['form_analysis']['proper_shin_angle'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948138.650268 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948138.739511 6346551 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948138.758923 6346550 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 468\n",
      "Detected 33 landmarks\n",
      "Detected left leg as the stepping leg for reverse lunges\n",
      "Processing frame 100/468\n",
      "Rep #1 detected at frame with front knee angle 164.1°\n",
      "Processing frame 200/468\n",
      "Rep #2 detected at frame with front knee angle 166.4°\n",
      "Processing frame 300/468\n",
      "Rep #3 detected at frame with front knee angle 172.1°\n",
      "Rep #4 detected at frame with front knee angle 161.5°\n",
      "Processing frame 400/468\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 4 reps\n",
      "Front knee angle (ideal ~90°): 21.4°\n",
      "Back knee angle (lower is better): 0.3°\n",
      "Torso angle (lower is better): 85.9°\n",
      "Stride length: 0.122\n",
      "Knee alignment score: 80.9/100\n",
      "Hip stability score: 53.9/100\n",
      "Front knee proper position: No\n",
      "Back knee proper bend: Yes\n",
      "Torso stayed upright: No\n",
      "Knee properly aligned: Yes\n",
      "Good hip stability: No\n",
      "Frames analyzed: 468\n",
      "\n",
      "Feedback:\n",
      "- Your front knee is bending too much (below 80°). This puts excessive pressure on the knee joint.\n",
      "- Try to keep your torso more upright. You're leaning forward too much during the lunge.\n",
      "- Focus on keeping your hips level throughout the movement. Your hips are rotating or dipping to one side.\n",
      "- Your stride length is too short. Step back further to achieve proper lunge depth and form.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_reverse_lunge(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track lunge state\n",
    "    rep_count = 0\n",
    "    lunge_stage = None  # \"up\" (standing) or \"down\" (in lunge position)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine which leg is stepping back by tracking movements\n",
    "    active_leg = None  # \"left\" or \"right\"\n",
    "    left_ankle_positions = []\n",
    "    right_ankle_positions = []\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    front_knee_angles = []  # Front knee should be ~90 degrees at bottom\n",
    "    back_knee_angles = []   # Back knee should almost touch the ground\n",
    "    torso_angles = []       # Torso should stay upright\n",
    "    stride_lengths = []     # Distance between feet\n",
    "    knee_alignments = []    # Front knee should stay aligned with ankle\n",
    "    hip_heights = []        # Hip drop/rotation\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for lunge analysis\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Calculate mid points\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Track ankle positions to determine which leg steps back\n",
    "            left_ankle_positions.append(left_ankle)\n",
    "            right_ankle_positions.append(right_ankle)\n",
    "            \n",
    "            # If we have enough frames, determine which leg is moving back (the active lunge leg)\n",
    "            if good_frames == 30 and active_leg is None:\n",
    "                # Calculate movement for each ankle\n",
    "                left_movement = 0\n",
    "                right_movement = 0\n",
    "                \n",
    "                for i in range(1, len(left_ankle_positions)):\n",
    "                    left_movement += abs(left_ankle_positions[i][0] - left_ankle_positions[i-1][0])\n",
    "                    left_movement += abs(left_ankle_positions[i][1] - left_ankle_positions[i-1][1])\n",
    "                    \n",
    "                    right_movement += abs(right_ankle_positions[i][0] - right_ankle_positions[i-1][0])\n",
    "                    right_movement += abs(right_ankle_positions[i][1] - right_ankle_positions[i-1][1])\n",
    "                \n",
    "                # The leg with more movement is likely the one stepping back\n",
    "                if left_movement > right_movement:\n",
    "                    active_leg = \"left\"\n",
    "                else:\n",
    "                    active_leg = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {active_leg} leg as the stepping leg for reverse lunges\")\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Determine front and back legs based on detected active leg\n",
    "            # If left leg is stepping back, right leg is the front\n",
    "            if active_leg == \"left\" or active_leg is None:\n",
    "                front_ankle = right_ankle\n",
    "                front_knee = right_knee\n",
    "                front_hip = right_hip\n",
    "                front_foot_index = right_foot_index\n",
    "                \n",
    "                back_ankle = left_ankle\n",
    "                back_knee = left_knee\n",
    "                back_hip = left_hip\n",
    "                back_foot_index = left_foot_index\n",
    "                \n",
    "                front_label = \"R\"\n",
    "                back_label = \"L\"\n",
    "            else:\n",
    "                front_ankle = left_ankle\n",
    "                front_knee = left_knee\n",
    "                front_hip = left_hip\n",
    "                front_foot_index = left_foot_index\n",
    "                \n",
    "                back_ankle = right_ankle\n",
    "                back_knee = right_knee\n",
    "                back_hip = right_hip\n",
    "                back_foot_index = right_foot_index\n",
    "                \n",
    "                front_label = \"L\"\n",
    "                back_label = \"R\"\n",
    "            \n",
    "            # Calculate front knee angle (hip-knee-ankle)\n",
    "            front_knee_angle = calculate_angle(front_hip, front_knee, front_ankle)\n",
    "            front_knee_angles.append(front_knee_angle)\n",
    "            \n",
    "            # Calculate back knee angle (hip-knee-ankle)\n",
    "            back_knee_angle = calculate_angle(back_hip, back_knee, back_ankle)\n",
    "            back_knee_angles.append(back_knee_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Calculate stride length (distance between ankles)\n",
    "            stride_length = np.sqrt((front_ankle[0] - back_ankle[0])**2 + \n",
    "                                  (front_ankle[1] - back_ankle[1])**2)\n",
    "            stride_lengths.append(stride_length)\n",
    "            \n",
    "            # Calculate front knee alignment\n",
    "            # Measure horizontal distance from knee to ankle to track knee position\n",
    "            front_knee_to_ankle_x = front_knee[0] - front_ankle[0]\n",
    "            knee_alignments.append(front_knee_to_ankle_x)\n",
    "            \n",
    "            # Calculate hip drop/rotation\n",
    "            # Measure height difference between hips\n",
    "            hip_height_diff = abs(left_hip[1] - right_hip[1])\n",
    "            hip_heights.append(hip_height_diff)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            front_knee_px = normalized_to_pixel_coordinates(front_knee[0], front_knee[1], frame_width, frame_height)\n",
    "            back_knee_px = normalized_to_pixel_coordinates(back_knee[0], back_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{front_label} Knee: {front_knee_angle:.1f}°\",\n",
    "                        (front_knee_px[0] - 70, front_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{back_label} Knee: {back_knee_angle:.1f}°\",\n",
    "                        (back_knee_px[0] - 70, back_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine lunge stage based on front knee angle\n",
    "            # For lunges, \"down\" is when front knee is bent (smaller angle)\n",
    "            # \"up\" is when standing upright (larger angle)\n",
    "            \n",
    "            # Lunge is \"down\" when front knee angle is small (in deep lunge position)\n",
    "            if front_knee_angle < 120 and (lunge_stage == \"up\" or lunge_stage is None):\n",
    "                lunge_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Lunge is \"up\" when front knee angle is large (standing position)\n",
    "            elif front_knee_angle > 160 and lunge_stage == \"down\":\n",
    "                lunge_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with front knee angle {front_knee_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_front_knee_angle = np.min(front_knee_angles) if front_knee_angles else 180\n",
    "    min_back_knee_angle = np.min(back_knee_angles) if back_knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    max_stride_length = np.max(stride_lengths) if stride_lengths else 0\n",
    "    \n",
    "    # Calculate front knee alignment (negative = knee behind ankle, positive = knee over ankle)\n",
    "    knee_alignment_avg = np.mean(knee_alignments) if knee_alignments else 0\n",
    "    knee_alignment_score = 100 - (abs(knee_alignment_avg) * 300)  # Convert to 0-100 score\n",
    "    knee_alignment_score = max(0, min(100, knee_alignment_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate hip stability (lower is better)\n",
    "    hip_stability = np.mean(hip_heights) if hip_heights else 0.1\n",
    "    hip_stability_score = 100 - (hip_stability * 500)  # Convert to 0-100 score\n",
    "    hip_stability_score = max(0, min(100, hip_stability_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Check for key lunge form criteria\n",
    "    front_knee_proper = 80 <= min_front_knee_angle <= 110  # ~90° is ideal\n",
    "    back_knee_proper = min_back_knee_angle < 110  # Should bend significantly\n",
    "    torso_upright = avg_torso_angle < 20  # Torso should stay relatively vertical\n",
    "    knee_aligned = knee_alignment_score > 70  # Knee should track over ankle\n",
    "    good_hip_stability = hip_stability_score > 70  # Hips should stay level\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"front_knee_angle\": min_front_knee_angle,  # Should be ~90° at bottom\n",
    "            \"back_knee_angle\": min_back_knee_angle,    # Should be bent significantly\n",
    "            \"torso_angle\": avg_torso_angle,            # Should stay upright (<20°)\n",
    "            \"stride_length\": max_stride_length,        # Higher is generally better for proper depth\n",
    "            \"knee_alignment\": knee_alignment_score,    # Higher is better (0-100)\n",
    "            \"hip_stability\": hip_stability_score,      # Higher is better (0-100)\n",
    "            \"front_knee_proper\": front_knee_proper,\n",
    "            \"back_knee_proper\": back_knee_proper,\n",
    "            \"torso_upright\": torso_upright,\n",
    "            \"knee_aligned\": knee_aligned,\n",
    "            \"good_hip_stability\": good_hip_stability,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check front knee angle\n",
    "    if min_front_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"You're not going deep enough in your lunge. Aim for your front knee to bend to about 90 degrees.\")\n",
    "    elif min_front_knee_angle < 80:\n",
    "        feedback[\"feedback\"].append(\"Your front knee is bending too much (below 80°). This puts excessive pressure on the knee joint.\")\n",
    "    \n",
    "    # Check back knee angle\n",
    "    if min_back_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Your back leg isn't bending enough. Allow your back knee to bend more as you lower into the lunge.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if avg_torso_angle > 20:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more upright. You're leaning forward too much during the lunge.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if not knee_aligned:\n",
    "        if knee_alignment_avg > 0:\n",
    "            feedback[\"feedback\"].append(\"Your front knee is tracking too far forward over your toes. Keep your knee aligned with your ankle.\")\n",
    "        else:\n",
    "            feedback[\"feedback\"].append(\"Your front knee is positioned too far back. Ensure it's aligned properly over your ankle.\")\n",
    "    \n",
    "    # Check hip stability\n",
    "    if not good_hip_stability:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your hips level throughout the movement. Your hips are rotating or dipping to one side.\")\n",
    "    \n",
    "    # Check stride length\n",
    "    if max_stride_length < 0.3:  # This threshold might need tuning\n",
    "        feedback[\"feedback\"].append(\"Your stride length is too short. Step back further to achieve proper lunge depth and form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your reverse lunges show good depth, proper knee position, upright torso, and stable hips.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/ReverseLunge1.MOV\"  # Update this to the correct path\n",
    "result = analyze_reverse_lunge(video_file, \"clips/analyzed_lunge1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Front knee angle (ideal ~90°): {result['form_analysis']['front_knee_angle']:.1f}°\")\n",
    "    print(f\"Back knee angle (lower is better): {result['form_analysis']['back_knee_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Stride length: {result['form_analysis']['stride_length']:.3f}\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}/100\")\n",
    "    print(f\"Hip stability score: {result['form_analysis']['hip_stability']:.1f}/100\")\n",
    "    print(f\"Front knee proper position: {'Yes' if result['form_analysis']['front_knee_proper'] else 'No'}\")\n",
    "    print(f\"Back knee proper bend: {'Yes' if result['form_analysis']['back_knee_proper'] else 'No'}\")\n",
    "    print(f\"Torso stayed upright: {'Yes' if result['form_analysis']['torso_upright'] else 'No'}\")\n",
    "    print(f\"Knee properly aligned: {'Yes' if result['form_analysis']['knee_aligned'] else 'No'}\")\n",
    "    print(f\"Good hip stability: {'Yes' if result['form_analysis']['good_hip_stability'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948174.471411 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948174.551790 6347512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948174.564542 6347514 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 679\n",
      "Detected 33 landmarks\n",
      "Detected right leg as the stepping leg for reverse lunges\n",
      "Processing frame 100/679\n",
      "Rep #1 detected at frame with front knee angle 167.8°\n",
      "Rep #2 detected at frame with front knee angle 161.8°\n",
      "Processing frame 200/679\n",
      "Processing frame 300/679\n",
      "Processing frame 400/679\n",
      "Rep #3 detected at frame with front knee angle 163.8°\n",
      "Processing frame 500/679\n",
      "Processing frame 600/679\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 3 reps\n",
      "Front knee angle (ideal ~90°): 70.1°\n",
      "Back knee angle (lower is better): 52.4°\n",
      "Torso angle (lower is better): 85.8°\n",
      "Stride length: 0.329\n",
      "Knee alignment score: 66.0/100\n",
      "Hip stability score: 11.5/100\n",
      "Front knee proper position: No\n",
      "Back knee proper bend: Yes\n",
      "Torso stayed upright: No\n",
      "Knee properly aligned: No\n",
      "Good hip stability: No\n",
      "Frames analyzed: 679\n",
      "\n",
      "Feedback:\n",
      "- Your front knee is bending too much (below 80°). This puts excessive pressure on the knee joint.\n",
      "- Try to keep your torso more upright. You're leaning forward too much during the lunge.\n",
      "- Your front knee is positioned too far back. Ensure it's aligned properly over your ankle.\n",
      "- Focus on keeping your hips level throughout the movement. Your hips are rotating or dipping to one side.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_reverse_lunge(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track lunge state\n",
    "    rep_count = 0\n",
    "    lunge_stage = None  # \"up\" (standing) or \"down\" (in lunge position)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine which leg is stepping back by tracking movements\n",
    "    active_leg = None  # \"left\" or \"right\"\n",
    "    left_ankle_positions = []\n",
    "    right_ankle_positions = []\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    front_knee_angles = []  # Front knee should be ~90 degrees at bottom\n",
    "    back_knee_angles = []   # Back knee should almost touch the ground\n",
    "    torso_angles = []       # Torso should stay upright\n",
    "    stride_lengths = []     # Distance between feet\n",
    "    knee_alignments = []    # Front knee should stay aligned with ankle\n",
    "    hip_heights = []        # Hip drop/rotation\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for lunge analysis\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # Calculate mid points\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Track ankle positions to determine which leg steps back\n",
    "            left_ankle_positions.append(left_ankle)\n",
    "            right_ankle_positions.append(right_ankle)\n",
    "            \n",
    "            # If we have enough frames, determine which leg is moving back (the active lunge leg)\n",
    "            if good_frames == 30 and active_leg is None:\n",
    "                # Calculate movement for each ankle\n",
    "                left_movement = 0\n",
    "                right_movement = 0\n",
    "                \n",
    "                for i in range(1, len(left_ankle_positions)):\n",
    "                    left_movement += abs(left_ankle_positions[i][0] - left_ankle_positions[i-1][0])\n",
    "                    left_movement += abs(left_ankle_positions[i][1] - left_ankle_positions[i-1][1])\n",
    "                    \n",
    "                    right_movement += abs(right_ankle_positions[i][0] - right_ankle_positions[i-1][0])\n",
    "                    right_movement += abs(right_ankle_positions[i][1] - right_ankle_positions[i-1][1])\n",
    "                \n",
    "                # The leg with more movement is likely the one stepping back\n",
    "                if left_movement > right_movement:\n",
    "                    active_leg = \"left\"\n",
    "                else:\n",
    "                    active_leg = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {active_leg} leg as the stepping leg for reverse lunges\")\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Determine front and back legs based on detected active leg\n",
    "            # If left leg is stepping back, right leg is the front\n",
    "            if active_leg == \"left\" or active_leg is None:\n",
    "                front_ankle = right_ankle\n",
    "                front_knee = right_knee\n",
    "                front_hip = right_hip\n",
    "                front_foot_index = right_foot_index\n",
    "                \n",
    "                back_ankle = left_ankle\n",
    "                back_knee = left_knee\n",
    "                back_hip = left_hip\n",
    "                back_foot_index = left_foot_index\n",
    "                \n",
    "                front_label = \"R\"\n",
    "                back_label = \"L\"\n",
    "            else:\n",
    "                front_ankle = left_ankle\n",
    "                front_knee = left_knee\n",
    "                front_hip = left_hip\n",
    "                front_foot_index = left_foot_index\n",
    "                \n",
    "                back_ankle = right_ankle\n",
    "                back_knee = right_knee\n",
    "                back_hip = right_hip\n",
    "                back_foot_index = right_foot_index\n",
    "                \n",
    "                front_label = \"L\"\n",
    "                back_label = \"R\"\n",
    "            \n",
    "            # Calculate front knee angle (hip-knee-ankle)\n",
    "            front_knee_angle = calculate_angle(front_hip, front_knee, front_ankle)\n",
    "            front_knee_angles.append(front_knee_angle)\n",
    "            \n",
    "            # Calculate back knee angle (hip-knee-ankle)\n",
    "            back_knee_angle = calculate_angle(back_hip, back_knee, back_ankle)\n",
    "            back_knee_angles.append(back_knee_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Calculate stride length (distance between ankles)\n",
    "            stride_length = np.sqrt((front_ankle[0] - back_ankle[0])**2 + \n",
    "                                  (front_ankle[1] - back_ankle[1])**2)\n",
    "            stride_lengths.append(stride_length)\n",
    "            \n",
    "            # Calculate front knee alignment\n",
    "            # Measure horizontal distance from knee to ankle to track knee position\n",
    "            front_knee_to_ankle_x = front_knee[0] - front_ankle[0]\n",
    "            knee_alignments.append(front_knee_to_ankle_x)\n",
    "            \n",
    "            # Calculate hip drop/rotation\n",
    "            # Measure height difference between hips\n",
    "            hip_height_diff = abs(left_hip[1] - right_hip[1])\n",
    "            hip_heights.append(hip_height_diff)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            front_knee_px = normalized_to_pixel_coordinates(front_knee[0], front_knee[1], frame_width, frame_height)\n",
    "            back_knee_px = normalized_to_pixel_coordinates(back_knee[0], back_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{front_label} Knee: {front_knee_angle:.1f}°\",\n",
    "                        (front_knee_px[0] - 70, front_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{back_label} Knee: {back_knee_angle:.1f}°\",\n",
    "                        (back_knee_px[0] - 70, back_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine lunge stage based on front knee angle\n",
    "            # For lunges, \"down\" is when front knee is bent (smaller angle)\n",
    "            # \"up\" is when standing upright (larger angle)\n",
    "            \n",
    "            # Lunge is \"down\" when front knee angle is small (in deep lunge position)\n",
    "            if front_knee_angle < 120 and (lunge_stage == \"up\" or lunge_stage is None):\n",
    "                lunge_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Lunge is \"up\" when front knee angle is large (standing position)\n",
    "            elif front_knee_angle > 160 and lunge_stage == \"down\":\n",
    "                lunge_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with front knee angle {front_knee_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_front_knee_angle = np.min(front_knee_angles) if front_knee_angles else 180\n",
    "    min_back_knee_angle = np.min(back_knee_angles) if back_knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    max_stride_length = np.max(stride_lengths) if stride_lengths else 0\n",
    "    \n",
    "    # Calculate front knee alignment (negative = knee behind ankle, positive = knee over ankle)\n",
    "    knee_alignment_avg = np.mean(knee_alignments) if knee_alignments else 0\n",
    "    knee_alignment_score = 100 - (abs(knee_alignment_avg) * 300)  # Convert to 0-100 score\n",
    "    knee_alignment_score = max(0, min(100, knee_alignment_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate hip stability (lower is better)\n",
    "    hip_stability = np.mean(hip_heights) if hip_heights else 0.1\n",
    "    hip_stability_score = 100 - (hip_stability * 500)  # Convert to 0-100 score\n",
    "    hip_stability_score = max(0, min(100, hip_stability_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Check for key lunge form criteria\n",
    "    front_knee_proper = 80 <= min_front_knee_angle <= 110  # ~90° is ideal\n",
    "    back_knee_proper = min_back_knee_angle < 110  # Should bend significantly\n",
    "    torso_upright = avg_torso_angle < 20  # Torso should stay relatively vertical\n",
    "    knee_aligned = knee_alignment_score > 70  # Knee should track over ankle\n",
    "    good_hip_stability = hip_stability_score > 70  # Hips should stay level\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"front_knee_angle\": min_front_knee_angle,  # Should be ~90° at bottom\n",
    "            \"back_knee_angle\": min_back_knee_angle,    # Should be bent significantly\n",
    "            \"torso_angle\": avg_torso_angle,            # Should stay upright (<20°)\n",
    "            \"stride_length\": max_stride_length,        # Higher is generally better for proper depth\n",
    "            \"knee_alignment\": knee_alignment_score,    # Higher is better (0-100)\n",
    "            \"hip_stability\": hip_stability_score,      # Higher is better (0-100)\n",
    "            \"front_knee_proper\": front_knee_proper,\n",
    "            \"back_knee_proper\": back_knee_proper,\n",
    "            \"torso_upright\": torso_upright,\n",
    "            \"knee_aligned\": knee_aligned,\n",
    "            \"good_hip_stability\": good_hip_stability,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check front knee angle\n",
    "    if min_front_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"You're not going deep enough in your lunge. Aim for your front knee to bend to about 90 degrees.\")\n",
    "    elif min_front_knee_angle < 80:\n",
    "        feedback[\"feedback\"].append(\"Your front knee is bending too much (below 80°). This puts excessive pressure on the knee joint.\")\n",
    "    \n",
    "    # Check back knee angle\n",
    "    if min_back_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Your back leg isn't bending enough. Allow your back knee to bend more as you lower into the lunge.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if avg_torso_angle > 20:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more upright. You're leaning forward too much during the lunge.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if not knee_aligned:\n",
    "        if knee_alignment_avg > 0:\n",
    "            feedback[\"feedback\"].append(\"Your front knee is tracking too far forward over your toes. Keep your knee aligned with your ankle.\")\n",
    "        else:\n",
    "            feedback[\"feedback\"].append(\"Your front knee is positioned too far back. Ensure it's aligned properly over your ankle.\")\n",
    "    \n",
    "    # Check hip stability\n",
    "    if not good_hip_stability:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your hips level throughout the movement. Your hips are rotating or dipping to one side.\")\n",
    "    \n",
    "    # Check stride length\n",
    "    if max_stride_length < 0.3:  # This threshold might need tuning\n",
    "        feedback[\"feedback\"].append(\"Your stride length is too short. Step back further to achieve proper lunge depth and form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your reverse lunges show good depth, proper knee position, upright torso, and stable hips.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/ReverseLunge2.MOV\"  # Update this to the correct path\n",
    "result = analyze_reverse_lunge(video_file, \"clips/analyzed_lunge2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Front knee angle (ideal ~90°): {result['form_analysis']['front_knee_angle']:.1f}°\")\n",
    "    print(f\"Back knee angle (lower is better): {result['form_analysis']['back_knee_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Stride length: {result['form_analysis']['stride_length']:.3f}\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}/100\")\n",
    "    print(f\"Hip stability score: {result['form_analysis']['hip_stability']:.1f}/100\")\n",
    "    print(f\"Front knee proper position: {'Yes' if result['form_analysis']['front_knee_proper'] else 'No'}\")\n",
    "    print(f\"Back knee proper bend: {'Yes' if result['form_analysis']['back_knee_proper'] else 'No'}\")\n",
    "    print(f\"Torso stayed upright: {'Yes' if result['form_analysis']['torso_upright'] else 'No'}\")\n",
    "    print(f\"Knee properly aligned: {'Yes' if result['form_analysis']['knee_aligned'] else 'No'}\")\n",
    "    print(f\"Good hip stability: {'Yes' if result['form_analysis']['good_hip_stability'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948235.793811 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948235.878715 6349325 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948235.890754 6349325 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 1102\n",
      "Detected 33 landmarks\n",
      "Rep #1 detected at frame with average elbow angle 161.8°\n",
      "Processing frame 100/1102\n",
      "Processing frame 200/1102\n",
      "Rep #2 detected at frame with average elbow angle 163.6°\n",
      "Processing frame 300/1102\n",
      "Rep #3 detected at frame with average elbow angle 171.7°\n",
      "Rep #4 detected at frame with average elbow angle 172.0°\n",
      "Processing frame 400/1102\n",
      "Rep #5 detected at frame with average elbow angle 165.7°\n",
      "Processing frame 500/1102\n",
      "Processing frame 600/1102\n",
      "Processing frame 700/1102\n",
      "Rep #6 detected at frame with average elbow angle 164.2°\n",
      "Processing frame 800/1102\n",
      "Rep #7 detected at frame with average elbow angle 165.0°\n",
      "Processing frame 900/1102\n",
      "Rep #8 detected at frame with average elbow angle 172.4°\n",
      "Processing frame 1000/1102\n",
      "Rep #9 detected at frame with average elbow angle 176.7°\n",
      "Processing frame 1100/1102\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 9 reps\n",
      "Min elbow angle (lower is better): 5.0°\n",
      "Max elbow angle (higher is better): 179.8°\n",
      "Back angle (should be close to 0°): 56.9°\n",
      "Shoulder stability score: 98.2/100\n",
      "Wrist alignment score: 86.3/100\n",
      "Shoulders level score: 99.3/100\n",
      "Full range of motion: Yes\n",
      "Back stayed upright: No\n",
      "Shoulders stayed stable: Yes\n",
      "Wrists properly aligned: Yes\n",
      "Shoulders stayed level: Yes\n",
      "Frames analyzed: 1082\n",
      "\n",
      "Feedback:\n",
      "- Keep your back more upright against the seat back. You're leaning forward during the press.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_shoulder_press(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track press state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" (arms extended) or \"down\" (arms at shoulders)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_heights = []  # To track if shoulders stay level\n",
    "    back_angles = []       # To track back posture (should stay upright)\n",
    "    wrist_positions = []   # To track wrist alignment with shoulders\n",
    "    press_heights = []     # To track how high the weights are pressed\n",
    "    shoulder_rotations = [] # To detect shoulder rotation\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for shoulder press analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Get hip points to measure back angle\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate midpoints for better analysis\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Average elbow angle for determining press stage\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            \n",
    "            # Calculate shoulder height difference to check if shoulders are level\n",
    "            shoulder_height_diff = abs(left_shoulder[1] - right_shoulder[1])\n",
    "            shoulder_heights.append(shoulder_height_diff)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Check wrist position relative to shoulders\n",
    "            # For proper press, wrists should be aligned with or slightly in front of shoulders\n",
    "            left_wrist_to_shoulder_x = left_wrist[0] - left_shoulder[0]\n",
    "            right_wrist_to_shoulder_x = right_wrist[0] - right_shoulder[0]\n",
    "            avg_wrist_position = (left_wrist_to_shoulder_x + right_wrist_to_shoulder_x) / 2\n",
    "            wrist_positions.append(avg_wrist_position)\n",
    "            \n",
    "            # Track press height (wrist height relative to shoulder)\n",
    "            left_press_height = left_shoulder[1] - left_wrist[1]  # Higher value means higher press\n",
    "            right_press_height = right_shoulder[1] - right_wrist[1]\n",
    "            avg_press_height = (left_press_height + right_press_height) / 2\n",
    "            press_heights.append(avg_press_height)\n",
    "            \n",
    "            # Detect shoulder rotation (shoulders should stay level and not rotate forward/backward)\n",
    "            # Simple proxy: difference in the depth (x-coordinate) of shoulders\n",
    "            shoulder_rotation = abs(left_shoulder[0] - right_shoulder[0])\n",
    "            shoulder_rotations.append(shoulder_rotation)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on elbow angle\n",
    "            # For shoulder press, \"down\" is when arms are bent (close to shoulders)\n",
    "            # \"up\" is when arms are extended overhead\n",
    "            \n",
    "            # Press is \"down\" when elbow angle is small (arms bent, weights at shoulders)\n",
    "            if avg_elbow_angle < 90 and (press_stage == \"up\" or press_stage is None):\n",
    "                press_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Press is \"up\" when elbow angle is large (arms extended overhead)\n",
    "            elif avg_elbow_angle > 160 and press_stage == \"down\":\n",
    "                press_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_min_elbow_angle = (np.min(elbow_angles_left) + np.min(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 180\n",
    "    avg_max_elbow_angle = (np.max(elbow_angles_left) + np.max(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 0\n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 0\n",
    "    \n",
    "    # Calculate shoulder stability (lower is better)\n",
    "    shoulder_stability = np.std(shoulder_heights) * 100 if shoulder_heights else 0\n",
    "    shoulder_stability_score = max(0, 100 - shoulder_stability)  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate wrist position relative to shoulders\n",
    "    # For proper press, wrists should be aligned with or slightly in front of shoulders\n",
    "    avg_wrist_position_score = 100 - (abs(np.mean(wrist_positions)) * 300) if wrist_positions else 50\n",
    "    avg_wrist_position_score = max(0, min(100, avg_wrist_position_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate press height consistency\n",
    "    max_press_height = np.max(press_heights) if press_heights else 0\n",
    "    \n",
    "    # Calculate shoulder rotation stability\n",
    "    rotation_stability = np.std(shoulder_rotations) * 100 if shoulder_rotations else 0\n",
    "    rotation_stability_score = max(0, 100 - rotation_stability)  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key shoulder press form criteria\n",
    "    full_range_of_motion = avg_min_elbow_angle < 80 and avg_max_elbow_angle > 160\n",
    "    back_upright = avg_back_angle < 15  # Back should be very upright in seated press\n",
    "    shoulders_stable = shoulder_stability_score > 80\n",
    "    wrists_aligned = avg_wrist_position_score > 70\n",
    "    shoulders_level = rotation_stability_score > 80\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_elbow_angle\": avg_min_elbow_angle,  # Lower value means better range of motion at bottom\n",
    "            \"max_elbow_angle\": avg_max_elbow_angle,  # Higher value means better extension at top\n",
    "            \"back_angle\": avg_back_angle,            # Should be close to 0° (upright)\n",
    "            \"shoulder_stability\": shoulder_stability_score,  # Higher is better (0-100)\n",
    "            \"wrist_alignment\": avg_wrist_position_score,    # Higher is better (0-100)\n",
    "            \"shoulder_level\": rotation_stability_score,     # Higher is better (0-100)\n",
    "            \"max_press_height\": max_press_height,           # Higher is better\n",
    "            \"full_range_of_motion\": full_range_of_motion,\n",
    "            \"back_upright\": back_upright,\n",
    "            \"shoulders_stable\": shoulders_stable,\n",
    "            \"wrists_aligned\": wrists_aligned,\n",
    "            \"shoulders_level\": shoulders_level,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check range of motion\n",
    "    if avg_min_elbow_angle > 80:\n",
    "        feedback[\"feedback\"].append(\"Try to lower the weights more at the bottom of the movement. Your elbows aren't bending enough.\")\n",
    "    \n",
    "    if avg_max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the press. You're not reaching full extension.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if avg_back_angle > 15:\n",
    "        feedback[\"feedback\"].append(\"Keep your back more upright against the seat back. You're leaning forward during the press.\")\n",
    "    \n",
    "    # Check shoulder stability\n",
    "    if not shoulders_stable:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your shoulders more stable throughout the movement. Your shoulders are moving excessively.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if not wrists_aligned:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists aligned with your shoulders. Your wrists are drifting too far forward or backward.\")\n",
    "    \n",
    "    # Check shoulder rotation\n",
    "    if not shoulders_level:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders level and avoid rotating them during the press. One shoulder is moving more than the other.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your shoulder press shows good range of motion, proper back position, and stable shoulders.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/ShoulderPress1.MOV\"  # Update this to the correct path\n",
    "result = analyze_shoulder_press(video_file, \"clips/analyzed_press1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Min elbow angle (lower is better): {result['form_analysis']['min_elbow_angle']:.1f}°\")\n",
    "    print(f\"Max elbow angle (higher is better): {result['form_analysis']['max_elbow_angle']:.1f}°\")\n",
    "    print(f\"Back angle (should be close to 0°): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Shoulder stability score: {result['form_analysis']['shoulder_stability']:.1f}/100\")\n",
    "    print(f\"Wrist alignment score: {result['form_analysis']['wrist_alignment']:.1f}/100\")\n",
    "    print(f\"Shoulders level score: {result['form_analysis']['shoulder_level']:.1f}/100\")\n",
    "    print(f\"Full range of motion: {'Yes' if result['form_analysis']['full_range_of_motion'] else 'No'}\")\n",
    "    print(f\"Back stayed upright: {'Yes' if result['form_analysis']['back_upright'] else 'No'}\")\n",
    "    print(f\"Shoulders stayed stable: {'Yes' if result['form_analysis']['shoulders_stable'] else 'No'}\")\n",
    "    print(f\"Wrists properly aligned: {'Yes' if result['form_analysis']['wrists_aligned'] else 'No'}\")\n",
    "    print(f\"Shoulders stayed level: {'Yes' if result['form_analysis']['shoulders_level'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948291.839619 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948291.933619 6350895 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948291.945874 6350901 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 435\n",
      "Detected 33 landmarks\n",
      "Rep #1 detected at frame with average elbow angle 166.6°\n",
      "Processing frame 100/435\n",
      "Rep #2 detected at frame with average elbow angle 162.3°\n",
      "Processing frame 200/435\n",
      "Processing frame 300/435\n",
      "Processing frame 400/435\n",
      "Rep #3 detected at frame with average elbow angle 162.0°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 3 reps\n",
      "Min elbow angle (lower is better): 4.5°\n",
      "Max elbow angle (higher is better): 172.7°\n",
      "Back angle (should be close to 0°): 40.8°\n",
      "Shoulder stability score: 96.9/100\n",
      "Wrist alignment score: 56.4/100\n",
      "Shoulders level score: 98.4/100\n",
      "Full range of motion: Yes\n",
      "Back stayed upright: No\n",
      "Shoulders stayed stable: Yes\n",
      "Wrists properly aligned: No\n",
      "Shoulders stayed level: Yes\n",
      "Frames analyzed: 435\n",
      "\n",
      "Feedback:\n",
      "- Keep your back more upright against the seat back. You're leaning forward during the press.\n",
      "- Keep your wrists aligned with your shoulders. Your wrists are drifting too far forward or backward.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_shoulder_press(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track press state\n",
    "    rep_count = 0\n",
    "    press_stage = None  # \"up\" (arms extended) or \"down\" (arms at shoulders)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_heights = []  # To track if shoulders stay level\n",
    "    back_angles = []       # To track back posture (should stay upright)\n",
    "    wrist_positions = []   # To track wrist alignment with shoulders\n",
    "    press_heights = []     # To track how high the weights are pressed\n",
    "    shoulder_rotations = [] # To detect shoulder rotation\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for shoulder press analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Get hip points to measure back angle\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Calculate midpoints for better analysis\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Average elbow angle for determining press stage\n",
    "            avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            \n",
    "            # Calculate shoulder height difference to check if shoulders are level\n",
    "            shoulder_height_diff = abs(left_shoulder[1] - right_shoulder[1])\n",
    "            shoulder_heights.append(shoulder_height_diff)\n",
    "            \n",
    "            # Calculate back angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            back_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            back_angle = 180 - back_angle if back_angle > 90 else back_angle\n",
    "            back_angles.append(back_angle)\n",
    "            \n",
    "            # Check wrist position relative to shoulders\n",
    "            # For proper press, wrists should be aligned with or slightly in front of shoulders\n",
    "            left_wrist_to_shoulder_x = left_wrist[0] - left_shoulder[0]\n",
    "            right_wrist_to_shoulder_x = right_wrist[0] - right_shoulder[0]\n",
    "            avg_wrist_position = (left_wrist_to_shoulder_x + right_wrist_to_shoulder_x) / 2\n",
    "            wrist_positions.append(avg_wrist_position)\n",
    "            \n",
    "            # Track press height (wrist height relative to shoulder)\n",
    "            left_press_height = left_shoulder[1] - left_wrist[1]  # Higher value means higher press\n",
    "            right_press_height = right_shoulder[1] - right_wrist[1]\n",
    "            avg_press_height = (left_press_height + right_press_height) / 2\n",
    "            press_heights.append(avg_press_height)\n",
    "            \n",
    "            # Detect shoulder rotation (shoulders should stay level and not rotate forward/backward)\n",
    "            # Simple proxy: difference in the depth (x-coordinate) of shoulders\n",
    "            shoulder_rotation = abs(left_shoulder[0] - right_shoulder[0])\n",
    "            shoulder_rotations.append(shoulder_rotation)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Back: {back_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine press stage based on elbow angle\n",
    "            # For shoulder press, \"down\" is when arms are bent (close to shoulders)\n",
    "            # \"up\" is when arms are extended overhead\n",
    "            \n",
    "            # Press is \"down\" when elbow angle is small (arms bent, weights at shoulders)\n",
    "            if avg_elbow_angle < 90 and (press_stage == \"up\" or press_stage is None):\n",
    "                press_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Press is \"up\" when elbow angle is large (arms extended overhead)\n",
    "            elif avg_elbow_angle > 160 and press_stage == \"down\":\n",
    "                press_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    avg_min_elbow_angle = (np.min(elbow_angles_left) + np.min(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 180\n",
    "    avg_max_elbow_angle = (np.max(elbow_angles_left) + np.max(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 0\n",
    "    avg_back_angle = np.mean(back_angles) if back_angles else 0\n",
    "    \n",
    "    # Calculate shoulder stability (lower is better)\n",
    "    shoulder_stability = np.std(shoulder_heights) * 100 if shoulder_heights else 0\n",
    "    shoulder_stability_score = max(0, 100 - shoulder_stability)  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate wrist position relative to shoulders\n",
    "    # For proper press, wrists should be aligned with or slightly in front of shoulders\n",
    "    avg_wrist_position_score = 100 - (abs(np.mean(wrist_positions)) * 300) if wrist_positions else 50\n",
    "    avg_wrist_position_score = max(0, min(100, avg_wrist_position_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate press height consistency\n",
    "    max_press_height = np.max(press_heights) if press_heights else 0\n",
    "    \n",
    "    # Calculate shoulder rotation stability\n",
    "    rotation_stability = np.std(shoulder_rotations) * 100 if shoulder_rotations else 0\n",
    "    rotation_stability_score = max(0, 100 - rotation_stability)  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key shoulder press form criteria\n",
    "    full_range_of_motion = avg_min_elbow_angle < 80 and avg_max_elbow_angle > 160\n",
    "    back_upright = avg_back_angle < 15  # Back should be very upright in seated press\n",
    "    shoulders_stable = shoulder_stability_score > 80\n",
    "    wrists_aligned = avg_wrist_position_score > 70\n",
    "    shoulders_level = rotation_stability_score > 80\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"min_elbow_angle\": avg_min_elbow_angle,  # Lower value means better range of motion at bottom\n",
    "            \"max_elbow_angle\": avg_max_elbow_angle,  # Higher value means better extension at top\n",
    "            \"back_angle\": avg_back_angle,            # Should be close to 0° (upright)\n",
    "            \"shoulder_stability\": shoulder_stability_score,  # Higher is better (0-100)\n",
    "            \"wrist_alignment\": avg_wrist_position_score,    # Higher is better (0-100)\n",
    "            \"shoulder_level\": rotation_stability_score,     # Higher is better (0-100)\n",
    "            \"max_press_height\": max_press_height,           # Higher is better\n",
    "            \"full_range_of_motion\": full_range_of_motion,\n",
    "            \"back_upright\": back_upright,\n",
    "            \"shoulders_stable\": shoulders_stable,\n",
    "            \"wrists_aligned\": wrists_aligned,\n",
    "            \"shoulders_level\": shoulders_level,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check range of motion\n",
    "    if avg_min_elbow_angle > 80:\n",
    "        feedback[\"feedback\"].append(\"Try to lower the weights more at the bottom of the movement. Your elbows aren't bending enough.\")\n",
    "    \n",
    "    if avg_max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the press. You're not reaching full extension.\")\n",
    "    \n",
    "    # Check back position\n",
    "    if avg_back_angle > 15:\n",
    "        feedback[\"feedback\"].append(\"Keep your back more upright against the seat back. You're leaning forward during the press.\")\n",
    "    \n",
    "    # Check shoulder stability\n",
    "    if not shoulders_stable:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your shoulders more stable throughout the movement. Your shoulders are moving excessively.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if not wrists_aligned:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists aligned with your shoulders. Your wrists are drifting too far forward or backward.\")\n",
    "    \n",
    "    # Check shoulder rotation\n",
    "    if not shoulders_level:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders level and avoid rotating them during the press. One shoulder is moving more than the other.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your shoulder press shows good range of motion, proper back position, and stable shoulders.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/ShoulderPress2.MOV\"  # Update this to the correct path\n",
    "result = analyze_shoulder_press(video_file, \"clips/analyzed_press2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Min elbow angle (lower is better): {result['form_analysis']['min_elbow_angle']:.1f}°\")\n",
    "    print(f\"Max elbow angle (higher is better): {result['form_analysis']['max_elbow_angle']:.1f}°\")\n",
    "    print(f\"Back angle (should be close to 0°): {result['form_analysis']['back_angle']:.1f}°\")\n",
    "    print(f\"Shoulder stability score: {result['form_analysis']['shoulder_stability']:.1f}/100\")\n",
    "    print(f\"Wrist alignment score: {result['form_analysis']['wrist_alignment']:.1f}/100\")\n",
    "    print(f\"Shoulders level score: {result['form_analysis']['shoulder_level']:.1f}/100\")\n",
    "    print(f\"Full range of motion: {'Yes' if result['form_analysis']['full_range_of_motion'] else 'No'}\")\n",
    "    print(f\"Back stayed upright: {'Yes' if result['form_analysis']['back_upright'] else 'No'}\")\n",
    "    print(f\"Shoulders stayed stable: {'Yes' if result['form_analysis']['shoulders_stable'] else 'No'}\")\n",
    "    print(f\"Wrists properly aligned: {'Yes' if result['form_analysis']['wrists_aligned'] else 'No'}\")\n",
    "    print(f\"Shoulders stayed level: {'Yes' if result['form_analysis']['shoulders_level'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948483.088899 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948483.206086 6356599 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948483.219770 6356600 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 725\n",
      "Detected 33 landmarks\n",
      "Detected left leg as the lead leg for step-ups\n",
      "Processing frame 100/725\n",
      "Rep #1 detected at frame with hip height 0.690\n",
      "Processing frame 200/725\n",
      "Rep #2 detected at frame with hip height 0.687\n",
      "Processing frame 300/725\n",
      "Rep #3 detected at frame with hip height 0.690\n",
      "Processing frame 400/725\n",
      "Processing frame 500/725\n",
      "Processing frame 600/725\n",
      "Processing frame 700/725\n",
      "Rep #4 detected at frame with hip height 0.686\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 4 reps\n",
      "Lead knee angle (ideal ~90°): 29.5°\n",
      "Torso angle (lower is better): 71.5°\n",
      "Hip extension: 0.247\n",
      "Knee alignment score: 74.6/100\n",
      "Hip stability score: 90.5/100\n",
      "Ankle mobility score: 100.0/100\n",
      "Proper knee angle: No\n",
      "Full extension at top: Yes\n",
      "Torso stayed upright: No\n",
      "Proper knee alignment: Yes\n",
      "Good hip stability: Yes\n",
      "Good ankle mobility: Yes\n",
      "Frames analyzed: 725\n",
      "\n",
      "Feedback:\n",
      "- Your knee is bending too much. This might indicate the step is too high or you're leaning too far forward.\n",
      "- Try to keep your torso more upright. You're leaning forward too much during the step-up.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_step_up(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track step-up state\n",
    "    rep_count = 0\n",
    "    step_stage = None  # \"up\" (standing on box) or \"down\" (on ground)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine which leg is the lead leg by tracking movements\n",
    "    active_leg = None  # \"left\" or \"right\"\n",
    "    left_knee_positions = []\n",
    "    right_knee_positions = []\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    lead_knee_angles = []    # Lead knee should be around 90° at bottom of movement\n",
    "    trail_knee_angles = []   # Trail leg knee angles\n",
    "    hip_heights = []         # Hip height relative to step to track full extension\n",
    "    torso_angles = []        # Torso should stay upright\n",
    "    knee_alignments = []     # Lead knee should track over ankle\n",
    "    hip_stability = []       # Hip drop/rotation\n",
    "    lead_ankle_angles = []   # Ankle mobility on lead leg\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_height = None      # To store initial height for comparison\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for step-up analysis\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Track knee positions to determine lead leg\n",
    "            left_knee_positions.append(left_knee)\n",
    "            right_knee_positions.append(right_knee)\n",
    "            \n",
    "            # If we have enough frames, determine which leg is the lead leg\n",
    "            if good_frames == 30 and active_leg is None:\n",
    "                # Calculate vertical movement (y-coordinate) for each knee\n",
    "                left_movement = 0\n",
    "                right_movement = 0\n",
    "                \n",
    "                for i in range(1, len(left_knee_positions)):\n",
    "                    # We focus on y movement (vertical) for step-ups\n",
    "                    left_movement += abs(left_knee_positions[i][1] - left_knee_positions[i-1][1])\n",
    "                    right_movement += abs(right_knee_positions[i][1] - right_knee_positions[i-1][1])\n",
    "                \n",
    "                # The leg with more vertical movement is likely the lead leg\n",
    "                if left_movement > right_movement:\n",
    "                    active_leg = \"left\"\n",
    "                else:\n",
    "                    active_leg = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {active_leg} leg as the lead leg for step-ups\")\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Determine lead and trail legs based on detected active leg\n",
    "            if active_leg == \"left\" or active_leg is None:\n",
    "                lead_hip = left_hip\n",
    "                lead_knee = left_knee\n",
    "                lead_ankle = left_ankle\n",
    "                lead_foot_index = left_foot_index\n",
    "                \n",
    "                trail_hip = right_hip\n",
    "                trail_knee = right_knee\n",
    "                trail_ankle = right_ankle\n",
    "                trail_foot_index = right_foot_index\n",
    "                \n",
    "                lead_label = \"L\"\n",
    "                trail_label = \"R\"\n",
    "            else:\n",
    "                lead_hip = right_hip\n",
    "                lead_knee = right_knee\n",
    "                lead_ankle = right_ankle\n",
    "                lead_foot_index = right_foot_index\n",
    "                \n",
    "                trail_hip = left_hip\n",
    "                trail_knee = left_knee\n",
    "                trail_ankle = left_ankle\n",
    "                trail_foot_index = left_foot_index\n",
    "                \n",
    "                lead_label = \"R\"\n",
    "                trail_label = \"L\"\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            lead_knee_angle = calculate_angle(lead_hip, lead_knee, lead_ankle)\n",
    "            trail_knee_angle = calculate_angle(trail_hip, trail_knee, trail_ankle)\n",
    "            \n",
    "            lead_knee_angles.append(lead_knee_angle)\n",
    "            trail_knee_angles.append(trail_knee_angle)\n",
    "            \n",
    "            # Calculate ankle angle (knee-ankle-foot) for lead leg\n",
    "            lead_ankle_angle = calculate_angle(lead_knee, lead_ankle, lead_foot_index)\n",
    "            lead_ankle_angles.append(lead_ankle_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Track hip height for full extension\n",
    "            hip_height = mid_hip[1]  # Lower y-value means higher position in image coordinates\n",
    "            hip_heights.append(hip_height)\n",
    "            \n",
    "            # Store starting height for comparison if it's not set yet\n",
    "            if start_height is None and good_frames > 5:  # Wait a few frames for stability\n",
    "                start_height = hip_height\n",
    "            \n",
    "            # Calculate knee alignment (should track over ankle)\n",
    "            lead_knee_to_ankle_x = lead_knee[0] - lead_ankle[0]\n",
    "            knee_alignments.append(lead_knee_to_ankle_x)\n",
    "            \n",
    "            # Calculate hip stability (measure level of hips)\n",
    "            hip_level_diff = abs(left_hip[1] - right_hip[1])\n",
    "            hip_stability.append(hip_level_diff)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            lead_knee_px = normalized_to_pixel_coordinates(lead_knee[0], lead_knee[1], frame_width, frame_height)\n",
    "            trail_knee_px = normalized_to_pixel_coordinates(trail_knee[0], trail_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{lead_label} Knee: {lead_knee_angle:.1f}°\",\n",
    "                        (lead_knee_px[0] - 70, lead_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine step stage based on hip height relative to starting position\n",
    "            # For step-ups, we need to track position more than angles\n",
    "            \n",
    "            # Use lowest observed hip height for reference (higher value in image coords)\n",
    "            if start_height is not None:\n",
    "                # If we're significantly higher than starting position, we're in \"up\" stage\n",
    "                if hip_height < (start_height - 0.05) and (step_stage == \"down\" or step_stage is None):\n",
    "                    step_stage = \"up\"\n",
    "                    cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # If we're close to or below starting position, we're in \"down\" stage\n",
    "                elif hip_height > (start_height - 0.02) and step_stage == \"up\":\n",
    "                    step_stage = \"down\"\n",
    "                    # Coming from \"up\", count a rep\n",
    "                    rep_count += 1\n",
    "                    print(f\"Rep #{rep_count} detected at frame with hip height {hip_height:.3f}\")\n",
    "                    cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_lead_knee_angle = np.min(lead_knee_angles) if lead_knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate max hip height change (to check if full extension at top)\n",
    "    if hip_heights and start_height is not None:\n",
    "        min_hip_height = np.min(hip_heights)  # Highest position (lowest y-value in image)\n",
    "        hip_height_change = start_height - min_hip_height\n",
    "    else:\n",
    "        hip_height_change = 0\n",
    "    \n",
    "    # Calculate knee alignment score\n",
    "    knee_alignment_avg = np.mean(abs(np.array(knee_alignments))) if knee_alignments else 0\n",
    "    knee_alignment_score = 100 - (knee_alignment_avg * 300)  # Convert to 0-100 score\n",
    "    knee_alignment_score = max(0, min(100, knee_alignment_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate hip stability score\n",
    "    hip_stability_avg = np.mean(hip_stability) if hip_stability else 0\n",
    "    hip_stability_score = 100 - (hip_stability_avg * 500)  # Convert to 0-100 score\n",
    "    hip_stability_score = max(0, min(100, hip_stability_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate ankle mobility score\n",
    "    ankle_mobility = np.min(lead_ankle_angles) if lead_ankle_angles else 90\n",
    "    # Lower ankle angle indicates better dorsiflexion\n",
    "    ankle_mobility_score = 100 - ((ankle_mobility - 70) * 3)  # Convert to 0-100 score\n",
    "    ankle_mobility_score = max(0, min(100, ankle_mobility_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Check for key step-up form criteria\n",
    "    proper_knee_angle = 70 <= min_lead_knee_angle <= 110  # Should bend to ~90° at bottom\n",
    "    full_extension = hip_height_change > 0.08  # Sufficient height change indicates full extension\n",
    "    torso_upright = avg_torso_angle < 20  # Torso should stay relatively vertical\n",
    "    proper_knee_alignment = knee_alignment_score > 70  # Knee should track over ankle\n",
    "    good_hip_stability = hip_stability_score > 70  # Hips should stay level\n",
    "    good_ankle_mobility = ankle_mobility_score > 60  # Sufficient ankle mobility\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"lead_knee_angle\": min_lead_knee_angle,  # Should be ~90° at bottom\n",
    "            \"torso_angle\": avg_torso_angle,          # Should stay upright (<20°)\n",
    "            \"hip_extension\": hip_height_change,      # Higher is better (full extension)\n",
    "            \"knee_alignment\": knee_alignment_score,  # Higher is better (0-100)\n",
    "            \"hip_stability\": hip_stability_score,    # Higher is better (0-100)\n",
    "            \"ankle_mobility\": ankle_mobility_score,  # Higher is better (0-100)\n",
    "            \"proper_knee_angle\": proper_knee_angle,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"torso_upright\": torso_upright,\n",
    "            \"proper_knee_alignment\": proper_knee_alignment,\n",
    "            \"good_hip_stability\": good_hip_stability,\n",
    "            \"good_ankle_mobility\": good_ankle_mobility,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check knee angle\n",
    "    if min_lead_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Your knee isn't bending enough as you step up. Try a higher step or focus on a deeper knee bend.\")\n",
    "    elif min_lead_knee_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Your knee is bending too much. This might indicate the step is too high or you're leaning too far forward.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if avg_torso_angle > 20:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more upright. You're leaning forward too much during the step-up.\")\n",
    "    \n",
    "    # Check hip extension\n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"Extend your hips fully at the top of the movement. Stand tall on the step before lowering back down.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if not proper_knee_alignment:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your knee aligned over your ankle. Your knee is tracking too far inward or outward.\")\n",
    "    \n",
    "    # Check hip stability\n",
    "    if not good_hip_stability:\n",
    "        feedback[\"feedback\"].append(\"Keep your hips level throughout the movement. Your hips are dropping or rotating to one side.\")\n",
    "    \n",
    "    # Check ankle mobility\n",
    "    if not good_ankle_mobility:\n",
    "        feedback[\"feedback\"].append(\"Work on ankle mobility. Limited ankle dorsiflexion is affecting your step-up form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your step-ups show good knee alignment, proper torso position, and full extension at the top.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/StepUp1.MOV\"  # Update this to the correct path\n",
    "result = analyze_step_up(video_file, \"clips/analyzed_stepup1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Lead knee angle (ideal ~90°): {result['form_analysis']['lead_knee_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Hip extension: {result['form_analysis']['hip_extension']:.3f}\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}/100\")\n",
    "    print(f\"Hip stability score: {result['form_analysis']['hip_stability']:.1f}/100\")\n",
    "    print(f\"Ankle mobility score: {result['form_analysis']['ankle_mobility']:.1f}/100\")\n",
    "    print(f\"Proper knee angle: {'Yes' if result['form_analysis']['proper_knee_angle'] else 'No'}\")\n",
    "    print(f\"Full extension at top: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Torso stayed upright: {'Yes' if result['form_analysis']['torso_upright'] else 'No'}\")\n",
    "    print(f\"Proper knee alignment: {'Yes' if result['form_analysis']['proper_knee_alignment'] else 'No'}\")\n",
    "    print(f\"Good hip stability: {'Yes' if result['form_analysis']['good_hip_stability'] else 'No'}\")\n",
    "    print(f\"Good ankle mobility: {'Yes' if result['form_analysis']['good_ankle_mobility'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948518.565481 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948518.642722 6357974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948518.654726 6357984 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 525\n",
      "Detected 33 landmarks\n",
      "Detected left leg as the lead leg for step-ups\n",
      "Processing frame 100/525\n",
      "Rep #1 detected at frame with hip height 0.763\n",
      "Processing frame 200/525\n",
      "Rep #2 detected at frame with hip height 0.754\n",
      "Processing frame 300/525\n",
      "Rep #3 detected at frame with hip height 0.751\n",
      "Processing frame 400/525\n",
      "Processing frame 500/525\n",
      "Rep #4 detected at frame with hip height 0.751\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 4 reps\n",
      "Lead knee angle (ideal ~90°): 21.8°\n",
      "Torso angle (lower is better): 77.7°\n",
      "Hip extension: 0.407\n",
      "Knee alignment score: 58.0/100\n",
      "Hip stability score: 80.9/100\n",
      "Ankle mobility score: 100.0/100\n",
      "Proper knee angle: No\n",
      "Full extension at top: Yes\n",
      "Torso stayed upright: No\n",
      "Proper knee alignment: No\n",
      "Good hip stability: Yes\n",
      "Good ankle mobility: Yes\n",
      "Frames analyzed: 525\n",
      "\n",
      "Feedback:\n",
      "- Your knee is bending too much. This might indicate the step is too high or you're leaning too far forward.\n",
      "- Try to keep your torso more upright. You're leaning forward too much during the step-up.\n",
      "- Focus on keeping your knee aligned over your ankle. Your knee is tracking too far inward or outward.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_step_up(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track step-up state\n",
    "    rep_count = 0\n",
    "    step_stage = None  # \"up\" (standing on box) or \"down\" (on ground)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine which leg is the lead leg by tracking movements\n",
    "    active_leg = None  # \"left\" or \"right\"\n",
    "    left_knee_positions = []\n",
    "    right_knee_positions = []\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    lead_knee_angles = []    # Lead knee should be around 90° at bottom of movement\n",
    "    trail_knee_angles = []   # Trail leg knee angles\n",
    "    hip_heights = []         # Hip height relative to step to track full extension\n",
    "    torso_angles = []        # Torso should stay upright\n",
    "    knee_alignments = []     # Lead knee should track over ankle\n",
    "    hip_stability = []       # Hip drop/rotation\n",
    "    lead_ankle_angles = []   # Ankle mobility on lead leg\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_height = None      # To store initial height for comparison\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for step-up analysis\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_foot_index = [landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_foot_index = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Track knee positions to determine lead leg\n",
    "            left_knee_positions.append(left_knee)\n",
    "            right_knee_positions.append(right_knee)\n",
    "            \n",
    "            # If we have enough frames, determine which leg is the lead leg\n",
    "            if good_frames == 30 and active_leg is None:\n",
    "                # Calculate vertical movement (y-coordinate) for each knee\n",
    "                left_movement = 0\n",
    "                right_movement = 0\n",
    "                \n",
    "                for i in range(1, len(left_knee_positions)):\n",
    "                    # We focus on y movement (vertical) for step-ups\n",
    "                    left_movement += abs(left_knee_positions[i][1] - left_knee_positions[i-1][1])\n",
    "                    right_movement += abs(right_knee_positions[i][1] - right_knee_positions[i-1][1])\n",
    "                \n",
    "                # The leg with more vertical movement is likely the lead leg\n",
    "                if left_movement > right_movement:\n",
    "                    active_leg = \"left\"\n",
    "                else:\n",
    "                    active_leg = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {active_leg} leg as the lead leg for step-ups\")\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Determine lead and trail legs based on detected active leg\n",
    "            if active_leg == \"left\" or active_leg is None:\n",
    "                lead_hip = left_hip\n",
    "                lead_knee = left_knee\n",
    "                lead_ankle = left_ankle\n",
    "                lead_foot_index = left_foot_index\n",
    "                \n",
    "                trail_hip = right_hip\n",
    "                trail_knee = right_knee\n",
    "                trail_ankle = right_ankle\n",
    "                trail_foot_index = right_foot_index\n",
    "                \n",
    "                lead_label = \"L\"\n",
    "                trail_label = \"R\"\n",
    "            else:\n",
    "                lead_hip = right_hip\n",
    "                lead_knee = right_knee\n",
    "                lead_ankle = right_ankle\n",
    "                lead_foot_index = right_foot_index\n",
    "                \n",
    "                trail_hip = left_hip\n",
    "                trail_knee = left_knee\n",
    "                trail_ankle = left_ankle\n",
    "                trail_foot_index = left_foot_index\n",
    "                \n",
    "                lead_label = \"R\"\n",
    "                trail_label = \"L\"\n",
    "            \n",
    "            # Calculate knee angles (hip-knee-ankle)\n",
    "            lead_knee_angle = calculate_angle(lead_hip, lead_knee, lead_ankle)\n",
    "            trail_knee_angle = calculate_angle(trail_hip, trail_knee, trail_ankle)\n",
    "            \n",
    "            lead_knee_angles.append(lead_knee_angle)\n",
    "            trail_knee_angles.append(trail_knee_angle)\n",
    "            \n",
    "            # Calculate ankle angle (knee-ankle-foot) for lead leg\n",
    "            lead_ankle_angle = calculate_angle(lead_knee, lead_ankle, lead_foot_index)\n",
    "            lead_ankle_angles.append(lead_ankle_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Track hip height for full extension\n",
    "            hip_height = mid_hip[1]  # Lower y-value means higher position in image coordinates\n",
    "            hip_heights.append(hip_height)\n",
    "            \n",
    "            # Store starting height for comparison if it's not set yet\n",
    "            if start_height is None and good_frames > 5:  # Wait a few frames for stability\n",
    "                start_height = hip_height\n",
    "            \n",
    "            # Calculate knee alignment (should track over ankle)\n",
    "            lead_knee_to_ankle_x = lead_knee[0] - lead_ankle[0]\n",
    "            knee_alignments.append(lead_knee_to_ankle_x)\n",
    "            \n",
    "            # Calculate hip stability (measure level of hips)\n",
    "            hip_level_diff = abs(left_hip[1] - right_hip[1])\n",
    "            hip_stability.append(hip_level_diff)\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            lead_knee_px = normalized_to_pixel_coordinates(lead_knee[0], lead_knee[1], frame_width, frame_height)\n",
    "            trail_knee_px = normalized_to_pixel_coordinates(trail_knee[0], trail_knee[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"{lead_label} Knee: {lead_knee_angle:.1f}°\",\n",
    "                        (lead_knee_px[0] - 70, lead_knee_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine step stage based on hip height relative to starting position\n",
    "            # For step-ups, we need to track position more than angles\n",
    "            \n",
    "            # Use lowest observed hip height for reference (higher value in image coords)\n",
    "            if start_height is not None:\n",
    "                # If we're significantly higher than starting position, we're in \"up\" stage\n",
    "                if hip_height < (start_height - 0.05) and (step_stage == \"down\" or step_stage is None):\n",
    "                    step_stage = \"up\"\n",
    "                    cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # If we're close to or below starting position, we're in \"down\" stage\n",
    "                elif hip_height > (start_height - 0.02) and step_stage == \"up\":\n",
    "                    step_stage = \"down\"\n",
    "                    # Coming from \"up\", count a rep\n",
    "                    rep_count += 1\n",
    "                    print(f\"Rep #{rep_count} detected at frame with hip height {hip_height:.3f}\")\n",
    "                    cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    min_lead_knee_angle = np.min(lead_knee_angles) if lead_knee_angles else 180\n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate max hip height change (to check if full extension at top)\n",
    "    if hip_heights and start_height is not None:\n",
    "        min_hip_height = np.min(hip_heights)  # Highest position (lowest y-value in image)\n",
    "        hip_height_change = start_height - min_hip_height\n",
    "    else:\n",
    "        hip_height_change = 0\n",
    "    \n",
    "    # Calculate knee alignment score\n",
    "    knee_alignment_avg = np.mean(abs(np.array(knee_alignments))) if knee_alignments else 0\n",
    "    knee_alignment_score = 100 - (knee_alignment_avg * 300)  # Convert to 0-100 score\n",
    "    knee_alignment_score = max(0, min(100, knee_alignment_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate hip stability score\n",
    "    hip_stability_avg = np.mean(hip_stability) if hip_stability else 0\n",
    "    hip_stability_score = 100 - (hip_stability_avg * 500)  # Convert to 0-100 score\n",
    "    hip_stability_score = max(0, min(100, hip_stability_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Calculate ankle mobility score\n",
    "    ankle_mobility = np.min(lead_ankle_angles) if lead_ankle_angles else 90\n",
    "    # Lower ankle angle indicates better dorsiflexion\n",
    "    ankle_mobility_score = 100 - ((ankle_mobility - 70) * 3)  # Convert to 0-100 score\n",
    "    ankle_mobility_score = max(0, min(100, ankle_mobility_score))  # Clamp between 0-100\n",
    "    \n",
    "    # Check for key step-up form criteria\n",
    "    proper_knee_angle = 70 <= min_lead_knee_angle <= 110  # Should bend to ~90° at bottom\n",
    "    full_extension = hip_height_change > 0.08  # Sufficient height change indicates full extension\n",
    "    torso_upright = avg_torso_angle < 20  # Torso should stay relatively vertical\n",
    "    proper_knee_alignment = knee_alignment_score > 70  # Knee should track over ankle\n",
    "    good_hip_stability = hip_stability_score > 70  # Hips should stay level\n",
    "    good_ankle_mobility = ankle_mobility_score > 60  # Sufficient ankle mobility\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"lead_knee_angle\": min_lead_knee_angle,  # Should be ~90° at bottom\n",
    "            \"torso_angle\": avg_torso_angle,          # Should stay upright (<20°)\n",
    "            \"hip_extension\": hip_height_change,      # Higher is better (full extension)\n",
    "            \"knee_alignment\": knee_alignment_score,  # Higher is better (0-100)\n",
    "            \"hip_stability\": hip_stability_score,    # Higher is better (0-100)\n",
    "            \"ankle_mobility\": ankle_mobility_score,  # Higher is better (0-100)\n",
    "            \"proper_knee_angle\": proper_knee_angle,\n",
    "            \"full_extension\": full_extension,\n",
    "            \"torso_upright\": torso_upright,\n",
    "            \"proper_knee_alignment\": proper_knee_alignment,\n",
    "            \"good_hip_stability\": good_hip_stability,\n",
    "            \"good_ankle_mobility\": good_ankle_mobility,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check knee angle\n",
    "    if min_lead_knee_angle > 110:\n",
    "        feedback[\"feedback\"].append(\"Your knee isn't bending enough as you step up. Try a higher step or focus on a deeper knee bend.\")\n",
    "    elif min_lead_knee_angle < 70:\n",
    "        feedback[\"feedback\"].append(\"Your knee is bending too much. This might indicate the step is too high or you're leaning too far forward.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if avg_torso_angle > 20:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more upright. You're leaning forward too much during the step-up.\")\n",
    "    \n",
    "    # Check hip extension\n",
    "    if not full_extension:\n",
    "        feedback[\"feedback\"].append(\"Extend your hips fully at the top of the movement. Stand tall on the step before lowering back down.\")\n",
    "    \n",
    "    # Check knee alignment\n",
    "    if not proper_knee_alignment:\n",
    "        feedback[\"feedback\"].append(\"Focus on keeping your knee aligned over your ankle. Your knee is tracking too far inward or outward.\")\n",
    "    \n",
    "    # Check hip stability\n",
    "    if not good_hip_stability:\n",
    "        feedback[\"feedback\"].append(\"Keep your hips level throughout the movement. Your hips are dropping or rotating to one side.\")\n",
    "    \n",
    "    # Check ankle mobility\n",
    "    if not good_ankle_mobility:\n",
    "        feedback[\"feedback\"].append(\"Work on ankle mobility. Limited ankle dorsiflexion is affecting your step-up form.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your step-ups show good knee alignment, proper torso position, and full extension at the top.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/StepUp2.MOV\"  # Update this to the correct path\n",
    "result = analyze_step_up(video_file, \"clips/analyzed_stepup2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Lead knee angle (ideal ~90°): {result['form_analysis']['lead_knee_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Hip extension: {result['form_analysis']['hip_extension']:.3f}\")\n",
    "    print(f\"Knee alignment score: {result['form_analysis']['knee_alignment']:.1f}/100\")\n",
    "    print(f\"Hip stability score: {result['form_analysis']['hip_stability']:.1f}/100\")\n",
    "    print(f\"Ankle mobility score: {result['form_analysis']['ankle_mobility']:.1f}/100\")\n",
    "    print(f\"Proper knee angle: {'Yes' if result['form_analysis']['proper_knee_angle'] else 'No'}\")\n",
    "    print(f\"Full extension at top: {'Yes' if result['form_analysis']['full_extension'] else 'No'}\")\n",
    "    print(f\"Torso stayed upright: {'Yes' if result['form_analysis']['torso_upright'] else 'No'}\")\n",
    "    print(f\"Proper knee alignment: {'Yes' if result['form_analysis']['proper_knee_alignment'] else 'No'}\")\n",
    "    print(f\"Good hip stability: {'Yes' if result['form_analysis']['good_hip_stability'] else 'No'}\")\n",
    "    print(f\"Good ankle mobility: {'Yes' if result['form_analysis']['good_ankle_mobility'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948578.852465 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948578.945771 6360067 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948578.959545 6360069 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 373\n",
      "Detected 33 landmarks\n",
      "Detected double-arm tricep extension with both arm(s)\n",
      "Rep #1 detected at frame with average elbow angle 171.4°\n",
      "Rep #2 detected at frame with average elbow angle 164.5°\n",
      "Processing frame 100/373\n",
      "Rep #3 detected at frame with average elbow angle 165.7°\n",
      "Rep #4 detected at frame with average elbow angle 162.3°\n",
      "Processing frame 200/373\n",
      "Rep #5 detected at frame with average elbow angle 165.2°\n",
      "Processing frame 300/373\n",
      "Rep #6 detected at frame with average elbow angle 164.0°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 6 reps\n",
      "Exercise type: double-arm tricep extension\n",
      "Active arm: both\n",
      "Min elbow angle (lower is better): 17.2°\n",
      "Max elbow angle (higher is better): 179.7°\n",
      "Upper arm angle (should be ~90°): 75.1°\n",
      "Torso angle (lower is better): 81.0°\n",
      "Wrist alignment score: 15.2/100\n",
      "Head stability score: 94.2/100\n",
      "Full range of motion: Yes\n",
      "Upper arms stayed vertical: Yes\n",
      "Torso stayed stable: No\n",
      "Wrists properly aligned: No\n",
      "Head stayed stable: Yes\n",
      "Frames analyzed: 373\n",
      "\n",
      "Feedback:\n",
      "- Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\n",
      "- Keep your wrists straight and aligned with your forearms throughout the movement.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_tricep_extension(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track tricep extension state\n",
    "    rep_count = 0\n",
    "    extension_stage = None  # \"up\" (arms extended) or \"down\" (arms bent)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine if it's two-arm or one-arm extension by analyzing initial frames\n",
    "    exercise_type = None    # \"single\" or \"double\"\n",
    "    active_arm = None       # \"left\" or \"right\" (for single-arm only)\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_angles_left = [] # To check if upper arm stays vertical/stationary\n",
    "    shoulder_angles_right = []\n",
    "    wrist_alignments = []   # To track wrist alignment with forearms\n",
    "    torso_angles = []       # To track torso stability\n",
    "    head_positions = []     # To track head position\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for tricep extension analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Get hip and head points for posture analysis\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Calculate shoulder angles to check if upper arm stays vertical\n",
    "            # Create vertical reference points directly below shoulders\n",
    "            left_vertical_ref = [left_shoulder[0], left_shoulder[1] + 0.2]\n",
    "            right_vertical_ref = [right_shoulder[0], right_shoulder[1] + 0.2]\n",
    "            \n",
    "            # Calculate angle between shoulder, elbow, and vertical reference\n",
    "            left_shoulder_angle = calculate_angle(left_vertical_ref, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_vertical_ref, right_shoulder, right_elbow)\n",
    "            \n",
    "            shoulder_angles_left.append(left_shoulder_angle)\n",
    "            shoulder_angles_right.append(right_shoulder_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Track head position relative to shoulders\n",
    "            head_to_shoulder_distance = math.sqrt((nose[0] - mid_shoulder[0])**2 + \n",
    "                                                 (nose[1] - mid_shoulder[1])**2)\n",
    "            head_positions.append(head_to_shoulder_distance)\n",
    "            \n",
    "            # Determine exercise type based on elbow movement in first 30 frames\n",
    "            if good_frames == 30 and exercise_type is None:\n",
    "                left_range = max(elbow_angles_left) - min(elbow_angles_left)\n",
    "                right_range = max(elbow_angles_right) - min(elbow_angles_right)\n",
    "                \n",
    "                # If both elbows have significant movement, it's double-arm\n",
    "                if left_range > 20 and right_range > 20:\n",
    "                    exercise_type = \"double\"\n",
    "                elif left_range > right_range:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"left\"\n",
    "                else:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {exercise_type}-arm tricep extension with {active_arm if exercise_type == 'single' else 'both'} arm(s)\")\n",
    "            \n",
    "            # Calculate average wrist alignment\n",
    "            # For tricep extensions, wrists should stay aligned with forearms\n",
    "            left_wrist_alignment = abs(left_elbow_angle - 180) if left_elbow_angle > 90 else left_elbow_angle\n",
    "            right_wrist_alignment = abs(right_elbow_angle - 180) if right_elbow_angle > 90 else right_elbow_angle\n",
    "            \n",
    "            if exercise_type == \"double\":\n",
    "                avg_wrist_alignment = (left_wrist_alignment + right_wrist_alignment) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_wrist_alignment = left_wrist_alignment\n",
    "            else:\n",
    "                avg_wrist_alignment = right_wrist_alignment\n",
    "                \n",
    "            wrist_alignments.append(avg_wrist_alignment)\n",
    "            \n",
    "            # Determine which elbow angle to use for rep counting\n",
    "            if exercise_type == \"double\":\n",
    "                avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_elbow_angle = left_elbow_angle\n",
    "            else:\n",
    "                avg_elbow_angle = right_elbow_angle\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine extension stage based on elbow angle\n",
    "            # For tricep extensions, \"down\" is when elbows are bent\n",
    "            # \"up\" is when arms are extended\n",
    "            \n",
    "            # Extension is \"down\" when elbow angle is small (arms bent, weight behind head)\n",
    "            if avg_elbow_angle < 90 and (extension_stage == \"up\" or extension_stage is None):\n",
    "                extension_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Extension is \"up\" when elbow angle is large (arms extended)\n",
    "            elif avg_elbow_angle > 160 and extension_stage == \"down\":\n",
    "                extension_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    if exercise_type == \"double\":\n",
    "        min_elbow_angle = (np.min(elbow_angles_left) + np.min(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 180\n",
    "        max_elbow_angle = (np.max(elbow_angles_left) + np.max(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 0\n",
    "        avg_shoulder_angle = (np.mean(shoulder_angles_left) + np.mean(shoulder_angles_right)) / 2 if shoulder_angles_left and shoulder_angles_right else 0\n",
    "    elif active_arm == \"left\":\n",
    "        min_elbow_angle = np.min(elbow_angles_left) if elbow_angles_left else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_left) if elbow_angles_left else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_left) if shoulder_angles_left else 0\n",
    "    else:  # right arm\n",
    "        min_elbow_angle = np.min(elbow_angles_right) if elbow_angles_right else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_right) if elbow_angles_right else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_right) if shoulder_angles_right else 0\n",
    "    \n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate wrist alignment (lower is better)\n",
    "    avg_wrist_alignment = np.mean(wrist_alignments) if wrist_alignments else 45\n",
    "    wrist_alignment_score = max(0, 100 - (avg_wrist_alignment * 2))  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate head position stability\n",
    "    head_stability = np.std(head_positions) * 100 if head_positions else 0\n",
    "    head_stability_score = max(0, 100 - (head_stability * 10))  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key tricep extension form criteria\n",
    "    full_range_of_motion = min_elbow_angle < 80 and max_elbow_angle > 160\n",
    "    upper_arm_vertical = abs(avg_shoulder_angle - 90) < 20  # Upper arm should stay close to vertical\n",
    "    torso_stable = avg_torso_angle < 15  # Torso should stay upright\n",
    "    wrists_proper = wrist_alignment_score > 70  # Wrists should stay aligned with forearms\n",
    "    head_stable = head_stability_score > 70  # Head should stay in stable position\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"exercise_type\": exercise_type,\n",
    "            \"active_arm\": active_arm if exercise_type == \"single\" else \"both\",\n",
    "            \"min_elbow_angle\": min_elbow_angle,    # Lower value means better range of motion\n",
    "            \"max_elbow_angle\": max_elbow_angle,    # Higher value means better extension\n",
    "            \"upper_arm_angle\": avg_shoulder_angle, # Should be close to 90° (vertical)\n",
    "            \"torso_angle\": avg_torso_angle,        # Should be close to 0° (upright)\n",
    "            \"wrist_alignment\": wrist_alignment_score,  # Higher is better (0-100)\n",
    "            \"head_stability\": head_stability_score,    # Higher is better (0-100)\n",
    "            \"full_range_of_motion\": full_range_of_motion,\n",
    "            \"upper_arm_vertical\": upper_arm_vertical,\n",
    "            \"torso_stable\": torso_stable,\n",
    "            \"wrists_proper\": wrists_proper,\n",
    "            \"head_stable\": head_stable,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check range of motion\n",
    "    if min_elbow_angle > 80:\n",
    "        feedback[\"feedback\"].append(\"Try to bend your elbows more at the bottom of the movement. You're not getting a full range of motion.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the movement to fully engage your triceps.\")\n",
    "    \n",
    "    # Check upper arm position\n",
    "    if not upper_arm_vertical:\n",
    "        if avg_shoulder_angle < 70:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far forward.\")\n",
    "        else:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far backward.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if not torso_stable:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if not wrists_proper:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists straight and aligned with your forearms throughout the movement.\")\n",
    "    \n",
    "    # Check head position\n",
    "    if not head_stable:\n",
    "        feedback[\"feedback\"].append(\"Keep your head in a stable position. Avoid moving it forward or backward as you extend your arms.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your tricep extensions show good range of motion, stable upper arms, and proper extension.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/TricepExtension1.MOV\"  # Update this to the correct path\n",
    "result = analyze_tricep_extension(video_file, \"clips/analyzed_triceps1.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Exercise type: {result['form_analysis']['exercise_type']}-arm tricep extension\")\n",
    "    print(f\"Active arm: {result['form_analysis']['active_arm']}\")\n",
    "    print(f\"Min elbow angle (lower is better): {result['form_analysis']['min_elbow_angle']:.1f}°\")\n",
    "    print(f\"Max elbow angle (higher is better): {result['form_analysis']['max_elbow_angle']:.1f}°\")\n",
    "    print(f\"Upper arm angle (should be ~90°): {result['form_analysis']['upper_arm_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Wrist alignment score: {result['form_analysis']['wrist_alignment']:.1f}/100\")\n",
    "    print(f\"Head stability score: {result['form_analysis']['head_stability']:.1f}/100\")\n",
    "    print(f\"Full range of motion: {'Yes' if result['form_analysis']['full_range_of_motion'] else 'No'}\")\n",
    "    print(f\"Upper arms stayed vertical: {'Yes' if result['form_analysis']['upper_arm_vertical'] else 'No'}\")\n",
    "    print(f\"Torso stayed stable: {'Yes' if result['form_analysis']['torso_stable'] else 'No'}\")\n",
    "    print(f\"Wrists properly aligned: {'Yes' if result['form_analysis']['wrists_proper'] else 'No'}\")\n",
    "    print(f\"Head stayed stable: {'Yes' if result['form_analysis']['head_stable'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948614.126786 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948614.218453 6361084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948614.229012 6361084 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 29, Total frames: 373\n",
      "Detected 33 landmarks\n",
      "Rep #1 detected at frame with average elbow angle 160.2°\n",
      "Detected double-arm tricep extension with both arm(s)\n",
      "Processing frame 100/373\n",
      "Processing frame 200/373\n",
      "Processing frame 300/373\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 reps\n",
      "Exercise type: double-arm tricep extension\n",
      "Active arm: both\n",
      "Min elbow angle (lower is better): 16.2°\n",
      "Max elbow angle (higher is better): 158.7°\n",
      "Upper arm angle (should be ~90°): 27.3°\n",
      "Torso angle (lower is better): 86.1°\n",
      "Wrist alignment score: 2.3/100\n",
      "Head stability score: 84.0/100\n",
      "Full range of motion: No\n",
      "Upper arms stayed vertical: No\n",
      "Torso stayed stable: No\n",
      "Wrists properly aligned: No\n",
      "Head stayed stable: Yes\n",
      "Frames analyzed: 373\n",
      "\n",
      "Feedback:\n",
      "- Extend your arms more fully at the top of the movement to fully engage your triceps.\n",
      "- Keep your upper arms more vertical. You're letting your elbows drift too far forward.\n",
      "- Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\n",
      "- Keep your wrists straight and aligned with your forearms throughout the movement.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_tricep_extension(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track tricep extension state\n",
    "    rep_count = 0\n",
    "    extension_stage = None  # \"up\" (arms extended) or \"down\" (arms bent)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine if it's two-arm or one-arm extension by analyzing initial frames\n",
    "    exercise_type = None    # \"single\" or \"double\"\n",
    "    active_arm = None       # \"left\" or \"right\" (for single-arm only)\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_angles_left = [] # To check if upper arm stays vertical/stationary\n",
    "    shoulder_angles_right = []\n",
    "    wrist_alignments = []   # To track wrist alignment with forearms\n",
    "    torso_angles = []       # To track torso stability\n",
    "    head_positions = []     # To track head position\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for tricep extension analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Get hip and head points for posture analysis\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Calculate shoulder angles to check if upper arm stays vertical\n",
    "            # Create vertical reference points directly below shoulders\n",
    "            left_vertical_ref = [left_shoulder[0], left_shoulder[1] + 0.2]\n",
    "            right_vertical_ref = [right_shoulder[0], right_shoulder[1] + 0.2]\n",
    "            \n",
    "            # Calculate angle between shoulder, elbow, and vertical reference\n",
    "            left_shoulder_angle = calculate_angle(left_vertical_ref, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_vertical_ref, right_shoulder, right_elbow)\n",
    "            \n",
    "            shoulder_angles_left.append(left_shoulder_angle)\n",
    "            shoulder_angles_right.append(right_shoulder_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Track head position relative to shoulders\n",
    "            head_to_shoulder_distance = math.sqrt((nose[0] - mid_shoulder[0])**2 + \n",
    "                                                 (nose[1] - mid_shoulder[1])**2)\n",
    "            head_positions.append(head_to_shoulder_distance)\n",
    "            \n",
    "            # Determine exercise type based on elbow movement in first 30 frames\n",
    "            if good_frames == 30 and exercise_type is None:\n",
    "                left_range = max(elbow_angles_left) - min(elbow_angles_left)\n",
    "                right_range = max(elbow_angles_right) - min(elbow_angles_right)\n",
    "                \n",
    "                # If both elbows have significant movement, it's double-arm\n",
    "                if left_range > 20 and right_range > 20:\n",
    "                    exercise_type = \"double\"\n",
    "                elif left_range > right_range:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"left\"\n",
    "                else:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {exercise_type}-arm tricep extension with {active_arm if exercise_type == 'single' else 'both'} arm(s)\")\n",
    "            \n",
    "            # Calculate average wrist alignment\n",
    "            # For tricep extensions, wrists should stay aligned with forearms\n",
    "            left_wrist_alignment = abs(left_elbow_angle - 180) if left_elbow_angle > 90 else left_elbow_angle\n",
    "            right_wrist_alignment = abs(right_elbow_angle - 180) if right_elbow_angle > 90 else right_elbow_angle\n",
    "            \n",
    "            if exercise_type == \"double\":\n",
    "                avg_wrist_alignment = (left_wrist_alignment + right_wrist_alignment) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_wrist_alignment = left_wrist_alignment\n",
    "            else:\n",
    "                avg_wrist_alignment = right_wrist_alignment\n",
    "                \n",
    "            wrist_alignments.append(avg_wrist_alignment)\n",
    "            \n",
    "            # Determine which elbow angle to use for rep counting\n",
    "            if exercise_type == \"double\":\n",
    "                avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_elbow_angle = left_elbow_angle\n",
    "            else:\n",
    "                avg_elbow_angle = right_elbow_angle\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine extension stage based on elbow angle\n",
    "            # For tricep extensions, \"down\" is when elbows are bent\n",
    "            # \"up\" is when arms are extended\n",
    "            \n",
    "            # Extension is \"down\" when elbow angle is small (arms bent, weight behind head)\n",
    "            if avg_elbow_angle < 90 and (extension_stage == \"up\" or extension_stage is None):\n",
    "                extension_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Extension is \"up\" when elbow angle is large (arms extended)\n",
    "            elif avg_elbow_angle > 160 and extension_stage == \"down\":\n",
    "                extension_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    if exercise_type == \"double\":\n",
    "        min_elbow_angle = (np.min(elbow_angles_left) + np.min(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 180\n",
    "        max_elbow_angle = (np.max(elbow_angles_left) + np.max(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 0\n",
    "        avg_shoulder_angle = (np.mean(shoulder_angles_left) + np.mean(shoulder_angles_right)) / 2 if shoulder_angles_left and shoulder_angles_right else 0\n",
    "    elif active_arm == \"left\":\n",
    "        min_elbow_angle = np.min(elbow_angles_left) if elbow_angles_left else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_left) if elbow_angles_left else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_left) if shoulder_angles_left else 0\n",
    "    else:  # right arm\n",
    "        min_elbow_angle = np.min(elbow_angles_right) if elbow_angles_right else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_right) if elbow_angles_right else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_right) if shoulder_angles_right else 0\n",
    "    \n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate wrist alignment (lower is better)\n",
    "    avg_wrist_alignment = np.mean(wrist_alignments) if wrist_alignments else 45\n",
    "    wrist_alignment_score = max(0, 100 - (avg_wrist_alignment * 2))  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate head position stability\n",
    "    head_stability = np.std(head_positions) * 100 if head_positions else 0\n",
    "    head_stability_score = max(0, 100 - (head_stability * 10))  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key tricep extension form criteria\n",
    "    full_range_of_motion = min_elbow_angle < 80 and max_elbow_angle > 160\n",
    "    upper_arm_vertical = abs(avg_shoulder_angle - 90) < 20  # Upper arm should stay close to vertical\n",
    "    torso_stable = avg_torso_angle < 15  # Torso should stay upright\n",
    "    wrists_proper = wrist_alignment_score > 70  # Wrists should stay aligned with forearms\n",
    "    head_stable = head_stability_score > 70  # Head should stay in stable position\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"exercise_type\": exercise_type,\n",
    "            \"active_arm\": active_arm if exercise_type == \"single\" else \"both\",\n",
    "            \"min_elbow_angle\": min_elbow_angle,    # Lower value means better range of motion\n",
    "            \"max_elbow_angle\": max_elbow_angle,    # Higher value means better extension\n",
    "            \"upper_arm_angle\": avg_shoulder_angle, # Should be close to 90° (vertical)\n",
    "            \"torso_angle\": avg_torso_angle,        # Should be close to 0° (upright)\n",
    "            \"wrist_alignment\": wrist_alignment_score,  # Higher is better (0-100)\n",
    "            \"head_stability\": head_stability_score,    # Higher is better (0-100)\n",
    "            \"full_range_of_motion\": full_range_of_motion,\n",
    "            \"upper_arm_vertical\": upper_arm_vertical,\n",
    "            \"torso_stable\": torso_stable,\n",
    "            \"wrists_proper\": wrists_proper,\n",
    "            \"head_stable\": head_stable,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check range of motion\n",
    "    if min_elbow_angle > 80:\n",
    "        feedback[\"feedback\"].append(\"Try to bend your elbows more at the bottom of the movement. You're not getting a full range of motion.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the movement to fully engage your triceps.\")\n",
    "    \n",
    "    # Check upper arm position\n",
    "    if not upper_arm_vertical:\n",
    "        if avg_shoulder_angle < 70:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far forward.\")\n",
    "        else:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far backward.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if not torso_stable:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if not wrists_proper:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists straight and aligned with your forearms throughout the movement.\")\n",
    "    \n",
    "    # Check head position\n",
    "    if not head_stable:\n",
    "        feedback[\"feedback\"].append(\"Keep your head in a stable position. Avoid moving it forward or backward as you extend your arms.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your tricep extensions show good range of motion, stable upper arms, and proper extension.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/TricepExtension2.MOV\"  # Update this to the correct path\n",
    "result = analyze_tricep_extension(video_file, \"clips/analyzed_triceps2.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Exercise type: {result['form_analysis']['exercise_type']}-arm tricep extension\")\n",
    "    print(f\"Active arm: {result['form_analysis']['active_arm']}\")\n",
    "    print(f\"Min elbow angle (lower is better): {result['form_analysis']['min_elbow_angle']:.1f}°\")\n",
    "    print(f\"Max elbow angle (higher is better): {result['form_analysis']['max_elbow_angle']:.1f}°\")\n",
    "    print(f\"Upper arm angle (should be ~90°): {result['form_analysis']['upper_arm_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Wrist alignment score: {result['form_analysis']['wrist_alignment']:.1f}/100\")\n",
    "    print(f\"Head stability score: {result['form_analysis']['head_stability']:.1f}/100\")\n",
    "    print(f\"Full range of motion: {'Yes' if result['form_analysis']['full_range_of_motion'] else 'No'}\")\n",
    "    print(f\"Upper arms stayed vertical: {'Yes' if result['form_analysis']['upper_arm_vertical'] else 'No'}\")\n",
    "    print(f\"Torso stayed stable: {'Yes' if result['form_analysis']['torso_stable'] else 'No'}\")\n",
    "    print(f\"Wrists properly aligned: {'Yes' if result['form_analysis']['wrists_proper'] else 'No'}\")\n",
    "    print(f\"Head stayed stable: {'Yes' if result['form_analysis']['head_stable'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745948637.674162 6301017 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "W0000 00:00:1745948637.791337 6361771 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745948637.803816 6361771 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 30, Total frames: 166\n",
      "Detected 33 landmarks\n",
      "Detected double-arm tricep extension with both arm(s)\n",
      "Processing frame 100/166\n",
      "Rep #1 detected at frame with average elbow angle 160.5°\n",
      "\n",
      "=== ANALYSIS RESULTS ===\n",
      "Counted 1 reps\n",
      "Exercise type: double-arm tricep extension\n",
      "Active arm: both\n",
      "Min elbow angle (lower is better): 15.6°\n",
      "Max elbow angle (higher is better): 168.0°\n",
      "Upper arm angle (should be ~90°): 51.9°\n",
      "Torso angle (lower is better): 79.1°\n",
      "Wrist alignment score: 9.1/100\n",
      "Head stability score: 61.9/100\n",
      "Full range of motion: Yes\n",
      "Upper arms stayed vertical: No\n",
      "Torso stayed stable: No\n",
      "Wrists properly aligned: No\n",
      "Head stayed stable: No\n",
      "Frames analyzed: 165\n",
      "\n",
      "Feedback:\n",
      "- Keep your upper arms more vertical. You're letting your elbows drift too far forward.\n",
      "- Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\n",
      "- Keep your wrists straight and aligned with your forearms throughout the movement.\n",
      "- Keep your head in a stable position. Avoid moving it forward or backward as you extend your arms.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_tricep_extension(video_path, output_video_path=None):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: File '{video_path}' does not exist!\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Video file not found: {video_path}\"\n",
    "        }\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{video_path}'\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": f\"Could not open video file: {video_path}. Check file format and codecs.\"\n",
    "        }\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Add debugging info\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # If we still have 0x0 dimensions, there's a codec issue\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        print(f\"Error: Could not determine video dimensions. Try converting the video to MP4 format.\")\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Could not determine video dimensions. Try converting to MP4 format.\"\n",
    "        }\n",
    "    \n",
    "    # Setup output video writer if path is provided\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or try 'avc1'\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Variables to track tricep extension state\n",
    "    rep_count = 0\n",
    "    extension_stage = None  # \"up\" (arms extended) or \"down\" (arms bent)\n",
    "    good_frames = 0\n",
    "    \n",
    "    # Determine if it's two-arm or one-arm extension by analyzing initial frames\n",
    "    exercise_type = None    # \"single\" or \"double\"\n",
    "    active_arm = None       # \"left\" or \"right\" (for single-arm only)\n",
    "    \n",
    "    # Lists to store angles and positions for analysis\n",
    "    elbow_angles_left = []\n",
    "    elbow_angles_right = []\n",
    "    shoulder_angles_left = [] # To check if upper arm stays vertical/stationary\n",
    "    shoulder_angles_right = []\n",
    "    wrist_alignments = []   # To track wrist alignment with forearms\n",
    "    torso_angles = []       # To track torso stability\n",
    "    head_positions = []     # To track head position\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "        # Convert to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        # Draw pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, \n",
    "                results.pose_landmarks, \n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Debug output to see what landmarks are detected\n",
    "            if good_frames == 1:\n",
    "                print(f\"Detected {len(landmarks)} landmarks\")\n",
    "            \n",
    "            # Get all key points for tricep extension analysis\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # Get hip and head points for posture analysis\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, \n",
    "                          (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, \n",
    "                      (left_hip[1] + right_hip[1])/2]\n",
    "            \n",
    "            # Calculate angle function\n",
    "            def calculate_angle(a, b, c):\n",
    "                a = np.array(a)\n",
    "                b = np.array(b)\n",
    "                c = np.array(c)\n",
    "                \n",
    "                radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                    \n",
    "                return angle\n",
    "            \n",
    "            # Calculate elbow angles (shoulder-elbow-wrist)\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            \n",
    "            elbow_angles_left.append(left_elbow_angle)\n",
    "            elbow_angles_right.append(right_elbow_angle)\n",
    "            \n",
    "            # Calculate shoulder angles to check if upper arm stays vertical\n",
    "            # Create vertical reference points directly below shoulders\n",
    "            left_vertical_ref = [left_shoulder[0], left_shoulder[1] + 0.2]\n",
    "            right_vertical_ref = [right_shoulder[0], right_shoulder[1] + 0.2]\n",
    "            \n",
    "            # Calculate angle between shoulder, elbow, and vertical reference\n",
    "            left_shoulder_angle = calculate_angle(left_vertical_ref, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_vertical_ref, right_shoulder, right_elbow)\n",
    "            \n",
    "            shoulder_angles_left.append(left_shoulder_angle)\n",
    "            shoulder_angles_right.append(right_shoulder_angle)\n",
    "            \n",
    "            # Calculate torso angle relative to vertical\n",
    "            # Create a point directly below mid_hip to represent vertical\n",
    "            vertical_point = [mid_hip[0], mid_hip[1] + 0.2]  # Adding to y moves down in image coords\n",
    "            torso_angle = calculate_angle(mid_shoulder, mid_hip, vertical_point)\n",
    "            torso_angle = 180 - torso_angle if torso_angle > 90 else torso_angle\n",
    "            torso_angles.append(torso_angle)\n",
    "            \n",
    "            # Track head position relative to shoulders\n",
    "            head_to_shoulder_distance = math.sqrt((nose[0] - mid_shoulder[0])**2 + \n",
    "                                                 (nose[1] - mid_shoulder[1])**2)\n",
    "            head_positions.append(head_to_shoulder_distance)\n",
    "            \n",
    "            # Determine exercise type based on elbow movement in first 30 frames\n",
    "            if good_frames == 30 and exercise_type is None:\n",
    "                left_range = max(elbow_angles_left) - min(elbow_angles_left)\n",
    "                right_range = max(elbow_angles_right) - min(elbow_angles_right)\n",
    "                \n",
    "                # If both elbows have significant movement, it's double-arm\n",
    "                if left_range > 20 and right_range > 20:\n",
    "                    exercise_type = \"double\"\n",
    "                elif left_range > right_range:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"left\"\n",
    "                else:\n",
    "                    exercise_type = \"single\"\n",
    "                    active_arm = \"right\"\n",
    "                    \n",
    "                print(f\"Detected {exercise_type}-arm tricep extension with {active_arm if exercise_type == 'single' else 'both'} arm(s)\")\n",
    "            \n",
    "            # Calculate average wrist alignment\n",
    "            # For tricep extensions, wrists should stay aligned with forearms\n",
    "            left_wrist_alignment = abs(left_elbow_angle - 180) if left_elbow_angle > 90 else left_elbow_angle\n",
    "            right_wrist_alignment = abs(right_elbow_angle - 180) if right_elbow_angle > 90 else right_elbow_angle\n",
    "            \n",
    "            if exercise_type == \"double\":\n",
    "                avg_wrist_alignment = (left_wrist_alignment + right_wrist_alignment) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_wrist_alignment = left_wrist_alignment\n",
    "            else:\n",
    "                avg_wrist_alignment = right_wrist_alignment\n",
    "                \n",
    "            wrist_alignments.append(avg_wrist_alignment)\n",
    "            \n",
    "            # Determine which elbow angle to use for rep counting\n",
    "            if exercise_type == \"double\":\n",
    "                avg_elbow_angle = (left_elbow_angle + right_elbow_angle) / 2\n",
    "            elif active_arm == \"left\":\n",
    "                avg_elbow_angle = left_elbow_angle\n",
    "            else:\n",
    "                avg_elbow_angle = right_elbow_angle\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates for visualization\n",
    "            def normalized_to_pixel_coordinates(normalized_x, normalized_y, image_width, image_height):\n",
    "                x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "                y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "                return x_px, y_px\n",
    "            \n",
    "            # Visualize key angles\n",
    "            left_elbow_px = normalized_to_pixel_coordinates(left_elbow[0], left_elbow[1], frame_width, frame_height)\n",
    "            right_elbow_px = normalized_to_pixel_coordinates(right_elbow[0], right_elbow[1], frame_width, frame_height)\n",
    "            mid_hip_px = normalized_to_pixel_coordinates(mid_hip[0], mid_hip[1], frame_width, frame_height)\n",
    "            \n",
    "            # Draw angle text\n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"L: {left_elbow_angle:.1f}°\",\n",
    "                        (left_elbow_px[0] - 50, left_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"R: {right_elbow_angle:.1f}°\",\n",
    "                        (right_elbow_px[0] - 50, right_elbow_px[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(annotated_image, \n",
    "                        f\"Torso: {torso_angle:.1f}°\",\n",
    "                        (mid_hip_px[0] - 50, mid_hip_px[1] - 20), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Determine extension stage based on elbow angle\n",
    "            # For tricep extensions, \"down\" is when elbows are bent\n",
    "            # \"up\" is when arms are extended\n",
    "            \n",
    "            # Extension is \"down\" when elbow angle is small (arms bent, weight behind head)\n",
    "            if avg_elbow_angle < 90 and (extension_stage == \"up\" or extension_stage is None):\n",
    "                extension_stage = \"down\"\n",
    "                cv2.putText(annotated_image, 'DOWN', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Extension is \"up\" when elbow angle is large (arms extended)\n",
    "            elif avg_elbow_angle > 160 and extension_stage == \"down\":\n",
    "                extension_stage = \"up\"\n",
    "                # Coming from \"down\", count a rep\n",
    "                rep_count += 1\n",
    "                print(f\"Rep #{rep_count} detected at frame with average elbow angle {avg_elbow_angle:.1f}°\")\n",
    "                cv2.putText(annotated_image, 'UP', (50, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "        # Display rep count\n",
    "        cv2.putText(annotated_image, f'Reps: {rep_count}', (10, 100), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "        # Write frame to output video\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "                \n",
    "    cap.release()\n",
    "    if output_video_path and 'out' in locals():\n",
    "        out.release()\n",
    "    \n",
    "    # Only analyze if we have enough valid frames\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"rep_count\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "        \n",
    "    # Calculate metrics for analysis\n",
    "    if exercise_type == \"double\":\n",
    "        min_elbow_angle = (np.min(elbow_angles_left) + np.min(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 180\n",
    "        max_elbow_angle = (np.max(elbow_angles_left) + np.max(elbow_angles_right)) / 2 if elbow_angles_left and elbow_angles_right else 0\n",
    "        avg_shoulder_angle = (np.mean(shoulder_angles_left) + np.mean(shoulder_angles_right)) / 2 if shoulder_angles_left and shoulder_angles_right else 0\n",
    "    elif active_arm == \"left\":\n",
    "        min_elbow_angle = np.min(elbow_angles_left) if elbow_angles_left else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_left) if elbow_angles_left else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_left) if shoulder_angles_left else 0\n",
    "    else:  # right arm\n",
    "        min_elbow_angle = np.min(elbow_angles_right) if elbow_angles_right else 180\n",
    "        max_elbow_angle = np.max(elbow_angles_right) if elbow_angles_right else 0\n",
    "        avg_shoulder_angle = np.mean(shoulder_angles_right) if shoulder_angles_right else 0\n",
    "    \n",
    "    avg_torso_angle = np.mean(torso_angles) if torso_angles else 0\n",
    "    \n",
    "    # Calculate wrist alignment (lower is better)\n",
    "    avg_wrist_alignment = np.mean(wrist_alignments) if wrist_alignments else 45\n",
    "    wrist_alignment_score = max(0, 100 - (avg_wrist_alignment * 2))  # Convert to 0-100 score\n",
    "    \n",
    "    # Calculate head position stability\n",
    "    head_stability = np.std(head_positions) * 100 if head_positions else 0\n",
    "    head_stability_score = max(0, 100 - (head_stability * 10))  # Convert to 0-100 score\n",
    "    \n",
    "    # Check for key tricep extension form criteria\n",
    "    full_range_of_motion = min_elbow_angle < 80 and max_elbow_angle > 160\n",
    "    upper_arm_vertical = abs(avg_shoulder_angle - 90) < 20  # Upper arm should stay close to vertical\n",
    "    torso_stable = avg_torso_angle < 15  # Torso should stay upright\n",
    "    wrists_proper = wrist_alignment_score > 70  # Wrists should stay aligned with forearms\n",
    "    head_stable = head_stability_score > 70  # Head should stay in stable position\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback = {\n",
    "        \"rep_count\": rep_count,\n",
    "        \"form_analysis\": {\n",
    "            \"exercise_type\": exercise_type,\n",
    "            \"active_arm\": active_arm if exercise_type == \"single\" else \"both\",\n",
    "            \"min_elbow_angle\": min_elbow_angle,    # Lower value means better range of motion\n",
    "            \"max_elbow_angle\": max_elbow_angle,    # Higher value means better extension\n",
    "            \"upper_arm_angle\": avg_shoulder_angle, # Should be close to 90° (vertical)\n",
    "            \"torso_angle\": avg_torso_angle,        # Should be close to 0° (upright)\n",
    "            \"wrist_alignment\": wrist_alignment_score,  # Higher is better (0-100)\n",
    "            \"head_stability\": head_stability_score,    # Higher is better (0-100)\n",
    "            \"full_range_of_motion\": full_range_of_motion,\n",
    "            \"upper_arm_vertical\": upper_arm_vertical,\n",
    "            \"torso_stable\": torso_stable,\n",
    "            \"wrists_proper\": wrists_proper,\n",
    "            \"head_stable\": head_stable,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    \n",
    "    # Add specific feedback based on measurements\n",
    "    # Check range of motion\n",
    "    if min_elbow_angle > 80:\n",
    "        feedback[\"feedback\"].append(\"Try to bend your elbows more at the bottom of the movement. You're not getting a full range of motion.\")\n",
    "    \n",
    "    if max_elbow_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Extend your arms more fully at the top of the movement to fully engage your triceps.\")\n",
    "    \n",
    "    # Check upper arm position\n",
    "    if not upper_arm_vertical:\n",
    "        if avg_shoulder_angle < 70:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far forward.\")\n",
    "        else:\n",
    "            feedback[\"feedback\"].append(\"Keep your upper arms more vertical. You're letting your elbows drift too far backward.\")\n",
    "    \n",
    "    # Check torso position\n",
    "    if not torso_stable:\n",
    "        feedback[\"feedback\"].append(\"Try to keep your torso more stable. Avoid leaning forward or arching your back during the extension.\")\n",
    "    \n",
    "    # Check wrist alignment\n",
    "    if not wrists_proper:\n",
    "        feedback[\"feedback\"].append(\"Keep your wrists straight and aligned with your forearms throughout the movement.\")\n",
    "    \n",
    "    # Check head position\n",
    "    if not head_stable:\n",
    "        feedback[\"feedback\"].append(\"Keep your head in a stable position. Avoid moving it forward or backward as you extend your arms.\")\n",
    "    \n",
    "    if not feedback[\"feedback\"]:\n",
    "        feedback[\"feedback\"].append(\"Great form! Your tricep extensions show good range of motion, stable upper arms, and proper extension.\")\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "# Example usage - Make sure you have the correct file path\n",
    "video_file = \"clips/TricepExtension3.MOV\"  # Update this to the correct path\n",
    "result = analyze_tricep_extension(video_file, \"clips/analyzed_triceps3.mp4\")\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(f\"Counted {result.get('rep_count', 0)} reps\")\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "elif \"form_analysis\" in result:\n",
    "    print(f\"Exercise type: {result['form_analysis']['exercise_type']}-arm tricep extension\")\n",
    "    print(f\"Active arm: {result['form_analysis']['active_arm']}\")\n",
    "    print(f\"Min elbow angle (lower is better): {result['form_analysis']['min_elbow_angle']:.1f}°\")\n",
    "    print(f\"Max elbow angle (higher is better): {result['form_analysis']['max_elbow_angle']:.1f}°\")\n",
    "    print(f\"Upper arm angle (should be ~90°): {result['form_analysis']['upper_arm_angle']:.1f}°\")\n",
    "    print(f\"Torso angle (lower is better): {result['form_analysis']['torso_angle']:.1f}°\")\n",
    "    print(f\"Wrist alignment score: {result['form_analysis']['wrist_alignment']:.1f}/100\")\n",
    "    print(f\"Head stability score: {result['form_analysis']['head_stability']:.1f}/100\")\n",
    "    print(f\"Full range of motion: {'Yes' if result['form_analysis']['full_range_of_motion'] else 'No'}\")\n",
    "    print(f\"Upper arms stayed vertical: {'Yes' if result['form_analysis']['upper_arm_vertical'] else 'No'}\")\n",
    "    print(f\"Torso stayed stable: {'Yes' if result['form_analysis']['torso_stable'] else 'No'}\")\n",
    "    print(f\"Wrists properly aligned: {'Yes' if result['form_analysis']['wrists_proper'] else 'No'}\")\n",
    "    print(f\"Head stayed stable: {'Yes' if result['form_analysis']['head_stable'] else 'No'}\")\n",
    "    print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in result[\"feedback\"]:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
