{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a588944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746473355.821809 4208201 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746473355.947468 4209802 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746473355.965735 4209802 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def analyze_burpee(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Burpee variables\n",
    "    burpee_count = 0\n",
    "    burpee_state = \"standing\"  # standing -> squat -> plank -> squat -> jump -> standing\n",
    "    state_start_time = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Track metrics for form feedback\n",
    "    jump_heights = []\n",
    "    plank_durations = []\n",
    "    squat_depths = []\n",
    "    \n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "\n",
    "    def calculate_angle(a, b, c):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        c = np.array(c)\n",
    "        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "        angle = np.abs(radians * 180.0 / np.pi)\n",
    "        if angle > 180.0:\n",
    "            angle = 360 - angle\n",
    "        return angle\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get key points\n",
    "            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # Calculate midpoints\n",
    "            mid_shoulder = [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2]\n",
    "            mid_hip = [(left_hip[0] + right_hip[0])/2, (left_hip[1] + right_hip[1])/2]\n",
    "            mid_ankle = [(left_ankle[0] + right_ankle[0])/2, (left_ankle[1] + right_ankle[1])/2]\n",
    "            \n",
    "            # Calculate metrics for positions\n",
    "            # 1. Body angle (vertical = standing, horizontal = plank)\n",
    "            vertical_angle = calculate_angle([mid_shoulder[0], 0], mid_shoulder, mid_hip)\n",
    "            \n",
    "            # 2. Knee angle (straight = standing/plank, bent = squat)\n",
    "            left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            knee_angle = (left_knee_angle + right_knee_angle) / 2\n",
    "            \n",
    "            # 3. Hip height (for squat depth and jump detection)\n",
    "            hip_height = mid_hip[1]\n",
    "            ankle_height = mid_ankle[1]\n",
    "            \n",
    "            # 4. Wrist position relative to shoulders (for plank detection)\n",
    "            wrist_shoulder_y_diff = ((left_wrist[1] + right_wrist[1])/2) - ((left_shoulder[1] + right_shoulder[1])/2)\n",
    "            \n",
    "            # Detect positions\n",
    "            is_standing = vertical_angle < 30 and knee_angle > 160 and hip_height < 0.7\n",
    "            is_squat = knee_angle < 120 and hip_height > 0.6\n",
    "            is_plank = vertical_angle > 60 and knee_angle > 160 and wrist_shoulder_y_diff < 0.15\n",
    "            is_jump = hip_height < 0.5 and ankle_height < 0.75  # Both hips and ankles are high (in the air)\n",
    "            \n",
    "            # Record metrics for feedback\n",
    "            if is_squat:\n",
    "                squat_depths.append(hip_height)\n",
    "            if is_jump:\n",
    "                jump_heights.append(1.0 - hip_height)  # Normalize so higher value = higher jump\n",
    "            \n",
    "            # State machine for burpee detection\n",
    "            if burpee_state == \"standing\":\n",
    "                if is_squat:\n",
    "                    burpee_state = \"squat_down\"\n",
    "                    state_start_time = frame_count\n",
    "            \n",
    "            elif burpee_state == \"squat_down\":\n",
    "                if is_plank:\n",
    "                    burpee_state = \"plank\"\n",
    "                    state_start_time = frame_count\n",
    "                elif is_standing:  # Reset if they stand back up without completing\n",
    "                    burpee_state = \"standing\"\n",
    "            \n",
    "            elif burpee_state == \"plank\":\n",
    "                plank_duration = frame_count - state_start_time\n",
    "                plank_durations.append(plank_duration)\n",
    "                \n",
    "                if is_squat:\n",
    "                    burpee_state = \"squat_up\"\n",
    "                    state_start_time = frame_count\n",
    "                elif is_standing:  # Skip squat and go straight to standing\n",
    "                    burpee_state = \"standing\"\n",
    "            \n",
    "            elif burpee_state == \"squat_up\":\n",
    "                if is_jump:\n",
    "                    burpee_state = \"jump\"\n",
    "                    state_start_time = frame_count\n",
    "                elif is_standing:  # Skip jump\n",
    "                    burpee_state = \"standing\"\n",
    "                    burpee_count += 1  # Still count as a rep, but will note in feedback\n",
    "            \n",
    "            elif burpee_state == \"jump\":\n",
    "                if is_standing:\n",
    "                    burpee_state = \"standing\"\n",
    "                    burpee_count += 1\n",
    "                    state_start_time = frame_count\n",
    "\n",
    "            # Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "            # Display metrics\n",
    "            cv2.putText(annotated_image, f\"Burpee Count: {burpee_count}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, f\"State: {burpee_state}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, f\"Vertical Angle: {vertical_angle:.1f}\", (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, f\"Knee Angle: {knee_angle:.1f}\", (10, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "\n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "\n",
    "    # Calculate averages and prepare feedback\n",
    "    if frame_count < 10:\n",
    "        return {\n",
    "            \"burpee_count\": 0,\n",
    "            \"error\": \"Not enough valid frames. Check video quality and positioning.\"\n",
    "        }\n",
    "\n",
    "    avg_squat_depth = sum(squat_depths) / len(squat_depths) if squat_depths else 0\n",
    "    avg_jump_height = sum(jump_heights) / len(jump_heights) if jump_heights else 0\n",
    "    avg_plank_duration = sum(plank_durations) / len(plank_durations) if plank_durations else 0\n",
    "    avg_plank_duration_seconds = avg_plank_duration / fps if fps > 0 else 0\n",
    "\n",
    "    feedback = {\n",
    "        \"burpee_count\": burpee_count,\n",
    "        \"form_analysis\": {\n",
    "            \"avg_squat_depth\": avg_squat_depth,\n",
    "            \"avg_jump_height\": avg_jump_height,\n",
    "            \"avg_plank_duration_seconds\": avg_plank_duration_seconds\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "\n",
    "    # Generate feedback\n",
    "    if avg_squat_depth < 0.65:\n",
    "        feedback[\"feedback\"].append(\"Deepen your squat for a full range of motion.\")\n",
    "    if avg_jump_height < 0.2:\n",
    "        feedback[\"feedback\"].append(\"Push through your heels for a more explosive jump.\")\n",
    "    if avg_plank_duration_seconds < 0.5:\n",
    "        feedback[\"feedback\"].append(\"Ensure a complete plank position in the middle of each burpee.\")\n",
    "    if burpee_count < 3:\n",
    "        feedback[\"feedback\"].append(\"Focus on completing the full sequence: squat, plank, squat, jump.\")\n",
    "\n",
    "    return feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d3011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
