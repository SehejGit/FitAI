{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab344558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735d330",
   "metadata": {},
   "source": [
    "# original plank code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746083487.481316 1978783 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3\n"
     ]
    }
   ],
   "source": [
    "# mp_pose = mp.solutions.pose\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "# def analyze_plank(video_path, output_video_path=None):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#     if output_video_path:\n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#         out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "#     plank_active = False\n",
    "#     start_time = None\n",
    "#     duration = 0\n",
    "#     frames_without_detection = 0\n",
    "#     good_frames = 0\n",
    "#     alignment_scores = []\n",
    "#     cooldown_frames = 0  # allows for brief loss of pose if user moves\n",
    "\n",
    "#     print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         success, image = cap.read()\n",
    "#         if not success:\n",
    "#             break\n",
    "\n",
    "#         image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         results = pose.process(image_rgb)\n",
    "#         annotated_image = image.copy()\n",
    "\n",
    "#         if results.pose_landmarks:\n",
    "#             good_frames += 1\n",
    "#             frames_without_detection = 0\n",
    "#             cooldown_frames = 0\n",
    "\n",
    "#             # Only draw body landmarks (not face)\n",
    "#             body_landmarks = [\n",
    "#                 mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "#                 mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "#                 mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "#             ]\n",
    "#             # Draw only body landmarks and connections\n",
    "#             mp_drawing.draw_landmarks(\n",
    "#                 annotated_image,\n",
    "#                 results.pose_landmarks,\n",
    "#                 mp_pose.POSE_CONNECTIONS,\n",
    "#                 mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "#                 mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "#             )\n",
    "\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "#             left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "#                              landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "#             right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "#                               landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "#             left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "#                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "#             right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "#                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "#             left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "#                           landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "#             right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "#                            landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "#             def calculate_angle(a, b, c):\n",
    "#                 a = np.array(a)\n",
    "#                 b = np.array(b)\n",
    "#                 c = np.array(c)\n",
    "#                 radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "#                 angle = np.abs(radians * 180.0 / np.pi)\n",
    "#                 if angle > 180.0:\n",
    "#                     angle = 360 - angle\n",
    "#                 return angle\n",
    "\n",
    "#             # Check body alignment (shoulder-hip-ankle angle should be close to 180)\n",
    "#             left_alignment_angle = calculate_angle(left_shoulder, left_hip, left_ankle)\n",
    "#             right_alignment_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "#             alignment_score = (180 - abs(left_alignment_angle - 180) + 180 - abs(right_alignment_angle - 180)) / 360\n",
    "#             alignment_scores.append(alignment_score)\n",
    "\n",
    "#             cv2.putText(annotated_image, f\"Alignment: {alignment_score * 100:.1f}%\", (10, 30),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#             # Determine if plank is active (shoulders above hips, ignore feet)\n",
    "#             if left_shoulder[1] < left_hip[1] and right_shoulder[1] < right_hip[1]:\n",
    "#                 if not plank_active:\n",
    "#                     plank_active = True\n",
    "#                     start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                 if start_time is not None:\n",
    "#                     current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                     duration = (current_time - start_time) / 1000  # seconds\n",
    "#             else:\n",
    "#                 # Instead of immediately resetting, allow a short cooldown\n",
    "#                 if plank_active and cooldown_frames < fps // 2:  # allow 0.5s grace\n",
    "#                     cooldown_frames += 1\n",
    "#                 else:\n",
    "#                     plank_active = False\n",
    "#                     start_time = None\n",
    "#                     duration = 0\n",
    "#         else:\n",
    "#             frames_without_detection += 1\n",
    "#             if frames_without_detection % 30 == 0:\n",
    "#                 print(f\"No pose detection for {frames_without_detection} frames\")\n",
    "#             # Allow brief detection loss\n",
    "#             if plank_active and cooldown_frames < fps // 2:\n",
    "#                 cooldown_frames += 1\n",
    "#             else:\n",
    "#                 plank_active = False\n",
    "#                 start_time = None\n",
    "#                 duration = 0\n",
    "\n",
    "#         cv2.putText(annotated_image, f'Duration: {duration:.1f}s', (10, 70),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#         if output_video_path:\n",
    "#             out.write(annotated_image)\n",
    "\n",
    "#     cap.release()\n",
    "#     if output_video_path:\n",
    "#         out.release()\n",
    "\n",
    "#     if good_frames < 10:\n",
    "#         return {\n",
    "#             \"duration\": 0,\n",
    "#             \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "#         }\n",
    "\n",
    "#     avg_alignment = sum(alignment_scores) / max(len(alignment_scores), 1)\n",
    "\n",
    "#     feedback = {\n",
    "#         \"duration\": duration,\n",
    "#         \"form_analysis\": {\n",
    "#             \"avg_body_alignment_score\": avg_alignment * 100,\n",
    "#             \"frames_analyzed\": good_frames\n",
    "#         },\n",
    "#         \"feedback\": []\n",
    "#     }\n",
    "\n",
    "#     if avg_alignment < 0.85:\n",
    "#         feedback[\"feedback\"].append(\"Maintain a straighter line from your shoulders to your ankles. Avoid sagging or arching your back.\")\n",
    "\n",
    "#     if not feedback[\"feedback\"]:\n",
    "#         feedback[\"feedback\"].append(\"Great plank form! You held a good straight line.\")\n",
    "\n",
    "#     return feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc871ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_file = 'planks/dom_plank.mp4'\n",
    "# output_file = 'planks/dom_output.mov'\n",
    "\n",
    "\n",
    "# analysis_results = analyze_plank(video_file, output_video_path=output_file)\n",
    "# print(\"\\n--- Plank Analysis Results ---\")\n",
    "\n",
    "\n",
    "# print(f\"Total Plank Duration: {analysis_results['duration']} seconds\")\n",
    "\n",
    "# print(\"\\nForm Analysis:\")\n",
    "# for key, value in analysis_results['form_analysis'].items():\n",
    "#     print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# print(\"\\nFeedback:\")\n",
    "# for msg in analysis_results['feedback']:\n",
    "#     print(f\"- {msg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df98d3",
   "metadata": {},
   "source": [
    "# altnerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a1ef90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746431192.197813 2213824 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746431192.326460 3988323 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746431192.346102 3988323 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def detect_orientation(lm):\n",
    "    \"\"\"\n",
    "    Determine whether subject is facing 'front', 'left', or 'right' based on nose and shoulder position.\n",
    "    This is adapted from the band pull-apart code.\n",
    "    \"\"\"\n",
    "    # Check if necessary landmarks are available\n",
    "    if (mp_pose.PoseLandmark.NOSE.value >= len(lm) or\n",
    "        mp_pose.PoseLandmark.LEFT_SHOULDER.value >= len(lm) or\n",
    "        mp_pose.PoseLandmark.RIGHT_SHOULDER.value >= len(lm)):\n",
    "        return \"unknown\" # Return unknown if landmarks are missing\n",
    "\n",
    "    nose = lm[mp_pose.PoseLandmark.NOSE.value]\n",
    "    ls = lm[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    rs = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "\n",
    "    # Check if landmark visibility is high enough\n",
    "    if nose.visibility < 0.5 or ls.visibility < 0.5 or rs.visibility < 0.5:\n",
    "         return \"unknown\" # Return unknown if visibility is low\n",
    "\n",
    "    mid_x = (ls.x + rs.x) / 2\n",
    "    delta = nose.x - mid_x\n",
    "\n",
    "    # Use a threshold to determine orientation\n",
    "    # These thresholds might need tuning based on typical video perspectives\n",
    "    if abs(delta) < 0.05: # Subject is likely facing forward\n",
    "        return \"front\"\n",
    "    # Subject is facing right if nose is to the left of the midpoint\n",
    "    return \"right\" if delta < 0 else \"left\" # Subject is facing left if nose is to the right\n",
    "\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    Calculates the angle in degrees between three points a, b, and c, with b being the vertex.\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    # Calculate the angle using arctan2\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    # Ensure the angle is between 0 and 180 degrees\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "\n",
    "def analyze_plank(video_path, output_video_path=None):\n",
    "    \"\"\"\n",
    "    Analyzes a video of a person performing a plank exercise,\n",
    "    calculating duration, overall body alignment, and providing feedback\n",
    "    based on detected pose and orientation.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return {\"duration\": 0, \"error\": \"Could not open video file.\"}\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    writer = None\n",
    "    if output_video_path:\n",
    "        # Define the codec and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can use 'XVID' or 'MJPG' if 'mp4v' doesn't work\n",
    "        try:\n",
    "            writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating video writer: {e}\")\n",
    "            writer = None # Ensure writer is None if creation fails\n",
    "\n",
    "\n",
    "    plank_active = False\n",
    "    start_time_msec = None # Store start time in milliseconds\n",
    "    duration = 0 # Duration in seconds\n",
    "    frames_without_detection = 0\n",
    "    good_frames = 0 # Frames with successful pose detection\n",
    "    alignment_scores = [] # List to store alignment scores per frame\n",
    "    orientations = [] # List to store detected orientations per frame\n",
    "    cooldown_frames = 0 # Allows for brief loss of pose if user moves\n",
    "\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break # End of video or error reading frame\n",
    "\n",
    "        # Convert the image to RGB for MediaPipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Process the image to find pose landmarks\n",
    "        results = pose_tracker.process(image_rgb)\n",
    "        # Create a copy of the original image to draw on\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            frames_without_detection = 0 # Reset counter on successful detection\n",
    "            cooldown_frames = 0 # Reset cooldown on successful detection\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Detect orientation for the current frame\n",
    "            orientations.append(detect_orientation(landmarks))\n",
    "\n",
    "\n",
    "            # Define key body landmarks for plank analysis\n",
    "            try:\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "                # Also get ear and nose for more specific feedback later if needed\n",
    "                left_ear = [landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].y]\n",
    "                right_ear = [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y]\n",
    "                nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error accessing landmarks: {e}\")\n",
    "                # Skip analysis for this frame if landmarks are missing or invalid\n",
    "                if writer:\n",
    "                    writer.write(annotated_image) # Still write the frame even without analysis\n",
    "                continue # Move to the next frame\n",
    "\n",
    "\n",
    "            # Check body alignment (shoulder-hip-ankle angle should be close to 180 for a straight line)\n",
    "            # Calculate angles for both sides and average them\n",
    "            left_alignment_angle = calculate_angle(left_shoulder, left_hip, left_ankle)\n",
    "            right_alignment_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "\n",
    "            # A simple score: 180 - deviation from 180, normalized. Higher is better.\n",
    "            # Max possible score for one side is 180 (perfectly straight). Averaging two sides.\n",
    "            alignment_score = ( (180 - abs(left_alignment_angle - 180)) + (180 - abs(right_alignment_angle - 180)) ) / 360.0\n",
    "            alignment_scores.append(alignment_score)\n",
    "\n",
    "            # Draw only body landmarks and connections on the annotated image\n",
    "            # You can customize the drawing spec colors and thickness\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), # Example color for points\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2) # Example color for connections\n",
    "            )\n",
    "\n",
    "            # Overlay alignment score on the video frame\n",
    "            cv2.putText(annotated_image, f\"Alignment: {alignment_score * 100:.1f}%\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Determine if plank is active\n",
    "            # Condition: Shoulders are generally above hips vertically.\n",
    "            # This is a simplified check and might need refinement based on camera angle.\n",
    "            # We ignore ankle position for activation check as feet can be higher/lower depending on plank type (forearm vs full)\n",
    "            # and camera angle.\n",
    "            is_shoulders_above_hips = left_shoulder[1] < left_hip[1] and right_shoulder[1] < right_hip[1]\n",
    "\n",
    "            if is_shoulders_above_hips:\n",
    "                if not plank_active:\n",
    "                    plank_active = True\n",
    "                    start_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC) # Record start time\n",
    "                if start_time_msec is not None:\n",
    "                    current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                    duration = (current_time_msec - start_time_msec) / 1000.0 # Calculate duration in seconds\n",
    "            else:\n",
    "                # If pose is not clearly a plank, start cooldown\n",
    "                if plank_active and cooldown_frames < fps // 2: # Allow 0.5s grace period\n",
    "                    cooldown_frames += 1\n",
    "                else:\n",
    "                    # If cooldown expires or plank wasn't active, reset\n",
    "                    plank_active = False\n",
    "                    start_time_msec = None\n",
    "                    duration = 0 # Reset duration if plank is no longer active\n",
    "\n",
    "        else:\n",
    "            # No pose detection in this frame\n",
    "            frames_without_detection += 1\n",
    "            if frames_without_detection % 30 == 0: # Print a message every second of no detection\n",
    "                print(f\"No pose detection for {frames_without_detection} frames\")\n",
    "\n",
    "            # If plank was active, allow a grace period for detection loss\n",
    "            if plank_active and cooldown_frames < fps // 2:\n",
    "                cooldown_frames += 1\n",
    "            else:\n",
    "                # If cooldown expires or plank wasn't active, reset\n",
    "                plank_active = False\n",
    "                start_time_msec = None\n",
    "                duration = 0\n",
    "\n",
    "\n",
    "        # Overlay duration on the video frame\n",
    "        cv2.putText(annotated_image, f'Duration: {duration:.1f}s', (10, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Write the annotated frame to the output video\n",
    "        if writer:\n",
    "            writer.write(annotated_image)\n",
    "\n",
    "    # Release video capture and writer objects\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "\n",
    "    # --- Analysis Summary and Feedback ---\n",
    "\n",
    "    if good_frames < fps * 2: # Require at least 2 seconds of good detection for analysis\n",
    "        return {\n",
    "            \"duration\": duration, # Return the final duration recorded\n",
    "            \"error\": \"Not enough valid pose detections for detailed analysis. Ensure subject is fully visible and lighting is good.\"\n",
    "        }\n",
    "\n",
    "    # Calculate average alignment score over all good frames\n",
    "    avg_alignment = sum(alignment_scores) / max(len(alignment_scores), 1)\n",
    "\n",
    "    # Determine the dominant view during the plank\n",
    "    # Filter out \"unknown\" orientations before finding the dominant one\n",
    "    valid_orientations = [o for o in orientations if o != \"unknown\"]\n",
    "    dominant_view = \"unknown\"\n",
    "    if valid_orientations:\n",
    "        dominant_view = max(set(valid_orientations), key=valid_orientations.count)\n",
    "\n",
    "\n",
    "    # Prepare the feedback dictionary\n",
    "    feedback_results = {\n",
    "        \"duration\": duration,\n",
    "        \"form_analysis\": {\n",
    "            \"avg_body_alignment_score\": avg_alignment * 100, # Convert to percentage\n",
    "            \"frames_analyzed\": good_frames,\n",
    "            \"dominant_view\": dominant_view\n",
    "        },\n",
    "        \"feedback\": [] # List to hold specific feedback messages\n",
    "    }\n",
    "\n",
    "    # Add general feedback based on average alignment\n",
    "    if avg_alignment < 0.70: # Lower threshold for poor alignment\n",
    "         feedback_results[\"feedback\"].append(\"Significant sagging or arching detected. Focus on maintaining a straight line from shoulders to ankles.\")\n",
    "    elif avg_alignment < 0.85: # Moderate threshold for improvement\n",
    "        feedback_results[\"feedback\"].append(\"Maintain a straighter line from your shoulders to your ankles. Avoid slight sagging or arching.\")\n",
    "    else:\n",
    "         feedback_results[\"feedback\"].append(\"Good overall body alignment!\")\n",
    "\n",
    "\n",
    "    # Add orientation-specific feedback\n",
    "    if dominant_view == \"front\":\n",
    "        feedback_results[\"feedback\"].append(\"Front view detected: Ensure shoulders are directly over elbows and hips are level.\")\n",
    "        # Could add checks for hip sway side-to-side if needed\n",
    "    elif dominant_view == \"left\":\n",
    "        feedback_results[\"feedback\"].append(\"Side view (left) detected: Focus on keeping your left hip from dropping and maintaining a straight line.\")\n",
    "        # Could add checks for hip height relative to shoulder/ankle\n",
    "    elif dominant_view == \"right\":\n",
    "        feedback_results[\"feedback\"].append(f\"Side view (right) detected: Focus on keeping your right hip from dropping and maintaining a straight line.\")\n",
    "        # Could add checks for hip height relative to shoulder/ankle\n",
    "    else: # dominant_view == \"unknown\"\n",
    "         feedback_results[\"feedback\"].append(\"Could not determine clear orientation. For best analysis, ensure your side or front is clearly visible to the camera.\")\n",
    "\n",
    "\n",
    "    # If no specific feedback was added, provide a positive message\n",
    "    if len(feedback_results[\"feedback\"]) == 3 and \"Good overall body alignment!\" in feedback_results[\"feedback\"]: # Only general and orientation feedback\n",
    "         feedback_results[\"feedback\"].append(\"Excellent plank form!\")\n",
    "    elif not feedback_results[\"feedback\"]: # Should not happen with general feedback, but as a fallback\n",
    "         feedback_results[\"feedback\"].append(\"Analysis complete. Reviewing your form.\")\n",
    "\n",
    "\n",
    "    return feedback_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35363d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1280x720, FPS: 30\n",
      "\n",
      "--- Plank Analysis Summary ---\n",
      "Plank Duration: 61.7 seconds\n",
      "Average Body Alignment Score: 96.5%\n",
      "Dominant View: left\n",
      "\n",
      "Feedback:\n",
      "- Good overall body alignment!\n",
      "- Side view (left) detected: Focus on keeping your left hip from dropping and maintaining a straight line.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have a video file named 'your_plank_video.mp4' in the same directory\n",
    "# Or provide the full path to your video file\n",
    "video_file = 'dom_plank.mp4'\n",
    "output_file = 'dom_output_2.mov' # Output video with annotations\n",
    "# Call the analysis function\n",
    "analysis_summary = analyze_plank(video_file, output_file)\n",
    "# Print the results\n",
    "print(\"\\n--- Plank Analysis Summary ---\")\n",
    "if \"error\" in analysis_summary:\n",
    "    print(f\"Error: {analysis_summary['error']}\")\n",
    "else:\n",
    "    print(f\"Plank Duration: {analysis_summary['duration']:.1f} seconds\")\n",
    "    print(f\"Average Body Alignment Score: {analysis_summary['form_analysis']['avg_body_alignment_score']:.1f}%\")\n",
    "    print(f\"Dominant View: {analysis_summary['form_analysis']['dominant_view']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in analysis_summary['feedback']:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac667b6",
   "metadata": {},
   "source": [
    "# the one being used in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e0ee880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746431687.016253 2213824 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746431687.138608 3992858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746431687.161028 3992857 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def detect_orientation(lm):\n",
    "    \"\"\"\n",
    "    Determine whether subject is facing 'front', 'left', or 'right'.\n",
    "    \"\"\"\n",
    "    nose = lm[mp_pose.PoseLandmark.NOSE.value]\n",
    "    ls = lm[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    rs = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    mid_x = (ls.x + rs.x) / 2\n",
    "    delta = nose.x - mid_x\n",
    "    if abs(delta) < 0.05:\n",
    "        return \"front\"\n",
    "    return \"right\" if delta < 0 else \"left\"\n",
    "\n",
    "def analyze_plank(video_path, output_video_path=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    plank_active = False\n",
    "    start_time = None\n",
    "    duration = 0\n",
    "    frames_without_detection = 0\n",
    "    good_frames = 0\n",
    "    cooldown_frames = 0  # allows for brief loss of pose if user moves\n",
    "    \n",
    "    # Metrics to track\n",
    "    alignment_scores = []\n",
    "    hip_drops = []\n",
    "    shoulder_heights = []\n",
    "    orientations = []\n",
    "    back_angles = []\n",
    "    neck_angles = []\n",
    "\n",
    "    print(f\"Video dimensions: {frame_width}x{frame_height}, FPS: {fps}\")\n",
    "\n",
    "    def calculate_angle(a, b, c):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        c = np.array(c)\n",
    "        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "        angle = np.abs(radians * 180.0 / np.pi)\n",
    "        if angle > 180.0:\n",
    "            angle = 360 - angle\n",
    "        return angle\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            good_frames += 1\n",
    "            frames_without_detection = 0\n",
    "            cooldown_frames = 0\n",
    "\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            orientations.append(detect_orientation(landmarks))\n",
    "\n",
    "            # Get key points\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            left_ear = [landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].x,\n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].y]\n",
    "            right_ear = [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y]\n",
    "\n",
    "            # Calculate metrics\n",
    "            # 1. Body alignment (shoulder-hip-ankle)\n",
    "            left_alignment_angle = calculate_angle(left_shoulder, left_hip, left_ankle)\n",
    "            right_alignment_angle = calculate_angle(right_shoulder, right_hip, right_ankle)\n",
    "            alignment_score = (180 - abs(left_alignment_angle - 180) + 180 - abs(right_alignment_angle - 180)) / 360\n",
    "            alignment_scores.append(alignment_score)\n",
    "\n",
    "            # 2. Hip drop (difference between shoulder and hip height)\n",
    "            avg_shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "            avg_hip_y = (left_hip[1] + right_hip[1]) / 2\n",
    "            hip_drop = (avg_hip_y - avg_shoulder_y) * frame_height  # in pixels\n",
    "            hip_drops.append(hip_drop)\n",
    "\n",
    "            # 3. Shoulder height difference (uneven shoulders)\n",
    "            shoulder_height_diff = abs(left_shoulder[1] - right_shoulder[1]) * frame_height\n",
    "            shoulder_heights.append(shoulder_height_diff)\n",
    "\n",
    "            # 4. Back angle (shoulder-hip-knee, for sagging detection)\n",
    "            left_back_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            right_back_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "            back_angles.append((left_back_angle + right_back_angle) / 2)\n",
    "\n",
    "            # 5. Neck angle (ear-nose-ear)\n",
    "            neck_angle = calculate_angle(left_ear, nose, right_ear)\n",
    "            neck_angles.append(neck_angle)\n",
    "\n",
    "            # Draw pose landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "            # Display metrics\n",
    "            cv2.putText(annotated_image, f\"Alignment: {alignment_score * 100:.1f}%\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, f\"Hip Drop: {hip_drop:.1f}px\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(annotated_image, f\"Back Angle: {back_angles[-1]:.1f}°\", (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Determine if plank is active (shoulders above hips)\n",
    "            if left_shoulder[1] < left_hip[1] and right_shoulder[1] < right_hip[1]:\n",
    "                if not plank_active:\n",
    "                    plank_active = True\n",
    "                    start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                if start_time is not None:\n",
    "                    current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                    duration = (current_time - start_time) / 1000  # seconds\n",
    "            else:\n",
    "                if plank_active and cooldown_frames < fps // 2:  # allow 0.5s grace\n",
    "                    cooldown_frames += 1\n",
    "                else:\n",
    "                    plank_active = False\n",
    "                    start_time = None\n",
    "                    duration = 0\n",
    "        else:\n",
    "            frames_without_detection += 1\n",
    "            if frames_without_detection % 30 == 0:\n",
    "                print(f\"No pose detection for {frames_without_detection} frames\")\n",
    "            if plank_active and cooldown_frames < fps // 2:\n",
    "                cooldown_frames += 1\n",
    "            else:\n",
    "                plank_active = False\n",
    "                start_time = None\n",
    "                duration = 0\n",
    "\n",
    "        cv2.putText(annotated_image, f'Duration: {duration:.1f}s', (10, frame_height - 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        if output_video_path:\n",
    "            out.write(annotated_image)\n",
    "\n",
    "    cap.release()\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "\n",
    "    if good_frames < 10:\n",
    "        return {\n",
    "            \"duration\": 0,\n",
    "            \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "        }\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_alignment = sum(alignment_scores) / len(alignment_scores)\n",
    "    avg_hip_drop = sum(hip_drops) / len(hip_drops)\n",
    "    avg_shoulder_diff = sum(shoulder_heights) / len(shoulder_heights)\n",
    "    avg_back_angle = sum(back_angles) / len(back_angles)\n",
    "    avg_neck_angle = sum(neck_angles) / len(neck_angles)\n",
    "    dominant_view = max(set(orientations), key=orientations.count) if orientations else \"unknown\"\n",
    "\n",
    "    # Prepare feedback\n",
    "    feedback = {\n",
    "        \"duration\": duration,\n",
    "        \"form_analysis\": {\n",
    "            \"avg_body_alignment_score\": avg_alignment * 100,\n",
    "            \"avg_hip_drop_px\": avg_hip_drop,\n",
    "            \"avg_shoulder_height_diff_px\": avg_shoulder_diff,\n",
    "            \"avg_back_angle\": avg_back_angle,\n",
    "            \"avg_neck_angle\": avg_neck_angle,\n",
    "            \"dominant_view\": dominant_view,\n",
    "            \"frames_analyzed\": good_frames\n",
    "        },\n",
    "        \"feedback\": []\n",
    "    }\n",
    "\n",
    "    # General feedback\n",
    "    if avg_alignment < 0.85:\n",
    "        feedback[\"feedback\"].append(\"Maintain a straighter line from shoulders to ankles. Avoid sagging or arching your back.\")\n",
    "    if avg_hip_drop > 0.1 * frame_height:  # More than 10% of frame height\n",
    "        feedback[\"feedback\"].append(\"Engage your core to prevent your hips from sagging.\")\n",
    "    if avg_shoulder_diff > 0.05 * frame_height:\n",
    "        feedback[\"feedback\"].append(\"Keep your shoulders level - one side appears higher than the other.\")\n",
    "    if avg_back_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Keep your back straighter - you may be rounding your shoulders or arching your lower back.\")\n",
    "    if avg_neck_angle < 160:\n",
    "        feedback[\"feedback\"].append(\"Keep your neck in line with your spine - avoid looking forward, dropping your head, or any movements.\")\n",
    "\n",
    "    # View-specific feedback\n",
    "    if dominant_view == \"front\":\n",
    "        feedback[\"feedback\"].append(\"Front view: Ensure your hands are shoulder-width apart and body is straight.\")\n",
    "    elif dominant_view == \"left\":\n",
    "        feedback[\"feedback\"].append(\"Left side view: Check that your hips aren't sagging and your shoulders are directly above your elbows.\")\n",
    "    elif dominant_view == \"right\":\n",
    "        feedback[\"feedback\"].append(\"Right side view: Check that your hips aren't sagging and your shoulders are directly above your elbows.\")\n",
    "\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dac3ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1280x720, FPS: 30\n",
      "\n",
      "--- Plank Analysis Summary ---\n",
      "Plank Duration: 61.7 seconds\n",
      "Average Body Alignment Score: 96.5%\n",
      "Dominant View: left\n",
      "\n",
      "Feedback:\n",
      "- Keep your neck in line with your spine - avoid looking forward, dropping your head, or any movements.\n",
      "- Left side view: Check that your hips aren't sagging and your shoulders are directly above your elbows.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have a video file named 'your_plank_video.mp4' in the same directory\n",
    "# Or provide the full path to your video file\n",
    "video_file = 'dom_plank.mp4'\n",
    "output_file = 'dom_output_2.mov' # Output video with annotations\n",
    "# Call the analysis function\n",
    "analysis_summary = analyze_plank(video_file, output_file)\n",
    "# Print the results\n",
    "print(\"\\n--- Plank Analysis Summary ---\")\n",
    "if \"error\" in analysis_summary:\n",
    "    print(f\"Error: {analysis_summary['error']}\")\n",
    "else:\n",
    "    print(f\"Plank Duration: {analysis_summary['duration']:.1f} seconds\")\n",
    "    print(f\"Average Body Alignment Score: {analysis_summary['form_analysis']['avg_body_alignment_score']:.1f}%\")\n",
    "    print(f\"Dominant View: {analysis_summary['form_analysis']['dominant_view']}\")\n",
    "    print(\"\\nFeedback:\")\n",
    "    for item in analysis_summary['feedback']:\n",
    "        print(f\"- {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70987b2e",
   "metadata": {},
   "source": [
    "# another alternative 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de4a1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746431800.531777 2213824 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1746431800.690111 3994212 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746431800.709336 3994214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# import mediapipe as mp\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# mp_pose = mp.solutions.pose\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "# def detect_orientation(lm):\n",
    "#     \"\"\"Determine subject orientation: 'front', 'left', or 'right'.\"\"\"\n",
    "#     nose = lm[mp_pose.PoseLandmark.NOSE.value]\n",
    "#     ls   = lm[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "#     rs   = lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "#     mid_x = (ls.x + rs.x) / 2\n",
    "#     delta = nose.x - mid_x\n",
    "#     if abs(delta) < 0.05:\n",
    "#         return \"front\"\n",
    "#     return \"right\" if delta < 0 else \"left\"\n",
    "\n",
    "# def calc_angle(a, b, c):\n",
    "#     \"\"\"Calculate angle (in degrees) at point b given three points.\"\"\"\n",
    "#     a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "#     ang = abs(np.degrees(\n",
    "#         np.arctan2(c[1]-b[1], c[0]-b[0]) -\n",
    "#         np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "#     ))\n",
    "#     return 360 - ang if ang > 180 else ang\n",
    "\n",
    "# def analyze_plank(video_path, output_video_path=None):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     writer = None\n",
    "#     if output_video_path:\n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#         writer = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n",
    "\n",
    "#     print(f\"Video dimensions: {w}x{h}, FPS: {fps}\")\n",
    "\n",
    "#     plank_active = False\n",
    "#     start_time = None\n",
    "#     duration = 0\n",
    "#     frames_without_detection = 0\n",
    "#     good_frames = 0\n",
    "#     cooldown_frames = 0\n",
    "\n",
    "#     align_scores = []\n",
    "#     hip_angles = []\n",
    "#     neck_angles = []\n",
    "#     shoulder_heights = []\n",
    "#     orientations = []\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         res = pose_tracker.process(img_rgb)\n",
    "#         out = frame.copy()\n",
    "\n",
    "#         if res.pose_landmarks:\n",
    "#             good_frames += 1\n",
    "#             frames_without_detection = 0\n",
    "#             cooldown_frames = 0\n",
    "#             lm = res.pose_landmarks.landmark\n",
    "\n",
    "#             # Orientation\n",
    "#             orientation = detect_orientation(lm)\n",
    "#             orientations.append(orientation)\n",
    "\n",
    "#             # helpers\n",
    "#             def nc(idx): return [lm[idx].x, lm[idx].y]\n",
    "#             def px(idx): return (int(lm[idx].x * w), int(lm[idx].y * h))\n",
    "\n",
    "#             # key points\n",
    "#             ls, rs = nc(mp_pose.PoseLandmark.LEFT_SHOULDER.value), nc(mp_pose.PoseLandmark.RIGHT_SHOULDER.value)\n",
    "#             lh, rh = nc(mp_pose.PoseLandmark.LEFT_HIP.value), nc(mp_pose.PoseLandmark.RIGHT_HIP.value)\n",
    "#             la, ra = nc(mp_pose.PoseLandmark.LEFT_ANKLE.value), nc(mp_pose.PoseLandmark.RIGHT_ANKLE.value)\n",
    "#             le, re = nc(mp_pose.PoseLandmark.LEFT_ELBOW.value), nc(mp_pose.PoseLandmark.RIGHT_ELBOW.value)\n",
    "#             lw, rw = nc(mp_pose.PoseLandmark.LEFT_WRIST.value), nc(mp_pose.PoseLandmark.RIGHT_WRIST.value)\n",
    "#             nose   = nc(mp_pose.PoseLandmark.NOSE.value)\n",
    "#             leye   = nc(mp_pose.PoseLandmark.LEFT_EYE.value)\n",
    "#             reye   = nc(mp_pose.PoseLandmark.RIGHT_EYE.value)\n",
    "\n",
    "#             # Alignment: shoulder-hip-ankle angle both sides\n",
    "#             left_align  = calc_angle(ls, lh, la)\n",
    "#             right_align = calc_angle(rs, rh, ra)\n",
    "#             align_score = (180 - abs(left_align - 180) + 180 - abs(right_align - 180)) / 360\n",
    "#             align_scores.append(align_score)\n",
    "\n",
    "#             # Hip angle: shoulder-hip-ankle\n",
    "#             avg_hip_angle = (left_align + right_align) / 2\n",
    "#             hip_angles.append(avg_hip_angle)\n",
    "\n",
    "#             # Neck angle (shoulder-shoulder-nose)\n",
    "#             neck_angle = calc_angle(ls, nose, rs)\n",
    "#             neck_angles.append(neck_angle)\n",
    "\n",
    "#             # Shoulder height diff (sag or tilt)\n",
    "#             shoulder_heights.append(abs((ls[1] - rs[1]) * h))\n",
    "\n",
    "#             # Draw pose\n",
    "#             mp_drawing.draw_landmarks(out, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "#             # Overlays\n",
    "#             cv2.putText(out, f\"Align: {align_score*100:.1f}%\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "#             cv2.putText(out, f\"Hip: {avg_hip_angle:.1f}°\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "#             cv2.putText(out, f\"Neck: {neck_angle:.1f}°\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,0), 2)\n",
    "#             cv2.putText(out, f\"View: {orientation}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,255), 2)\n",
    "\n",
    "#             # Plank active logic (shoulders above hips)\n",
    "#             if ls[1] < lh[1] and rs[1] < rh[1]:\n",
    "#                 if not plank_active:\n",
    "#                     plank_active = True\n",
    "#                     start_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                 if start_time is not None:\n",
    "#                     current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                     duration = (current_time - start_time) / 1000  # seconds\n",
    "#             else:\n",
    "#                 if plank_active and cooldown_frames < fps // 2:\n",
    "#                     cooldown_frames += 1\n",
    "#                 else:\n",
    "#                     plank_active = False\n",
    "#                     start_time = None\n",
    "#                     duration = 0\n",
    "#         else:\n",
    "#             frames_without_detection += 1\n",
    "#             if frames_without_detection % 30 == 0:\n",
    "#                 print(f\"No pose detection for {frames_without_detection} frames\")\n",
    "#             if plank_active and cooldown_frames < fps // 2:\n",
    "#                 cooldown_frames += 1\n",
    "#             else:\n",
    "#                 plank_active = False\n",
    "#                 start_time = None\n",
    "#                 duration = 0\n",
    "\n",
    "#         cv2.putText(out, f'Duration: {duration:.1f}s', (10, h-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "#         if writer:\n",
    "#             writer.write(out)\n",
    "\n",
    "#     cap.release()\n",
    "#     if writer:\n",
    "#         writer.release()\n",
    "\n",
    "#     if good_frames < 10:\n",
    "#         return {\n",
    "#             \"duration\": 0,\n",
    "#             \"error\": \"Not enough valid pose detections. Check video quality and positioning.\"\n",
    "#         }\n",
    "\n",
    "#     avg_align = sum(align_scores) / max(len(align_scores), 1)\n",
    "#     avg_hip = sum(hip_angles) / max(len(hip_angles), 1)\n",
    "#     avg_neck = sum(neck_angles) / max(len(neck_angles), 1)\n",
    "#     avg_shoulder_dy = sum(shoulder_heights) / max(len(shoulder_heights), 1)\n",
    "#     dominant_view = max(set(orientations), key=orientations.count)\n",
    "\n",
    "#     feedback = []\n",
    "#     # Alignment feedback\n",
    "#     if avg_align < 0.85:\n",
    "#         feedback.append(\"Keep your body in a straight line from shoulders to ankles-avoid sagging or arching your back.\")\n",
    "#     # Hip angle feedback\n",
    "#     if avg_hip < 165:\n",
    "#         feedback.append(\"Raise your hips slightly to avoid sagging.\")\n",
    "#     elif avg_hip > 195:\n",
    "#         feedback.append(\"Lower your hips to avoid piking up.\")\n",
    "#     # Neck feedback\n",
    "#     if avg_neck < 165:\n",
    "#         feedback.append(\"Keep your neck neutral-look straight down, not forward.\")\n",
    "#     # Shoulder feedback\n",
    "#     if avg_shoulder_dy > 0.05 * h:\n",
    "#         feedback.append(\"Keep your shoulders level-avoid tilting or twisting.\")\n",
    "#     # Orientation feedback\n",
    "#     if dominant_view == \"front\":\n",
    "#         feedback.append(\"Front view: ensure hips and shoulders are level and avoid twisting.\")\n",
    "#     elif dominant_view == \"left\":\n",
    "#         feedback.append(\"Side view (left): check for straight line from head to heels and neutral neck.\")\n",
    "#     else:\n",
    "#         feedback.append(\"Side view (right): check for straight line from head to heels and neutral neck.\")\n",
    "#     if not feedback:\n",
    "#         feedback.append(\"Excellent plank form! You held a strong, straight line.\")\n",
    "\n",
    "#     return {\n",
    "#         \"duration\": duration,\n",
    "#         \"form_analysis\": {\n",
    "#             \"avg_body_alignment_score\": avg_align * 100,\n",
    "#             \"avg_hip_angle\": avg_hip,\n",
    "#             \"avg_neck_angle\": avg_neck,\n",
    "#             \"avg_shoulder_height_diff_px\": avg_shoulder_dy,\n",
    "#             \"dominant_view\": dominant_view,\n",
    "#             \"frames_analyzed\": good_frames\n",
    "#         },\n",
    "#         \"feedback\": feedback\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e78367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1280x720, FPS: 30.01234596324414\n",
      "\n",
      "=== PLANK ANALYSIS RESULTS ===\n",
      "Duration held: 61.7 seconds\n",
      "Average alignment: 96.5%\n",
      "Dominant view: left\n",
      "Frames analyzed: 1854\n",
      "\n",
      "Feedback:\n",
      "- Keep your neck neutral-look straight down, not forward.\n",
      "- Side view (left): check for straight line from head to heels and neutral neck.\n"
     ]
    }
   ],
   "source": [
    "# result = analyze_plank(\"dom_plank.mp4\", \"annotated_plank.mp4\")\n",
    "\n",
    "# print(f\"\\n=== PLANK ANALYSIS RESULTS ===\")\n",
    "# if \"error\" in result:\n",
    "#     print(f\"Error: {result['error']}\")\n",
    "# else:\n",
    "#     print(f\"Duration held: {result['duration']:.1f} seconds\")\n",
    "#     print(f\"Average alignment: {result['form_analysis']['avg_body_alignment_score']:.1f}%\")\n",
    "#     print(f\"Dominant view: {result['form_analysis']['dominant_view']}\")\n",
    "#     print(f\"Frames analyzed: {result['form_analysis']['frames_analyzed']}\")\n",
    "#     print(\"\\nFeedback:\")\n",
    "#     for item in result[\"feedback\"]:\n",
    "#         print(f\"- {item}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
